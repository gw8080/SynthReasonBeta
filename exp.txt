philosophy from greek: φιλοσοφία philosophia love of wisdom is the study of general and fundamental questions about existence knowledge values reason mind and language. such questions are often posed as problems to be studied or resolved. the term was probably coined by pythagoras c.  –  bce. philosophical methods include questioning critical discussion rational argument and systematic presentation.iclassic philosophical questions include: is it possible to know anything and to prove it and what is most real philosophers also pose more practical and concrete questions such as: is there a best way to live is it better to be just or unjust if one can get away with it do humans have free willhistorically philosophy encompassed all bodies of knowledge. from the time of ancient greek philosopher aristotle to the th century natural philosophy encompassed astronomy medicine and physics. for example newtons  mathematical principles of natural philosophy later became classified as a book of physics.in the th century the growth of modern research universities led academic philosophy and other disciplines to professionalize and specialize. in the modern era some investigations that were traditionally part of philosophy became separate academic disciplines including psychology sociology linguistics and economics. other investigations closely related to art science politics or other pursuits remained part of philosophy. for example is beauty objective or subjective are there many scientific methods or just one is political utopia a hopeful dream or hopeless fantasymajor sub-fields of academic philosophy include: metaphysics which is concerned with the fundamental nature of reality and being; and epistemology which is about nature and grounds of knowledge and…its limits and validity; as well as ethics aesthetics political philosophy logic and philosophy of science.initially the term philosophy referred to any body of knowledge. in this sense philosophy is closely related to religion mathematics natural science education and politics. though as of the s it has been classified as a book of physics newtons mathematical principles of natural philosophy  uses the term natural philosophy as it was understood at the time to encompass disciplines such as astronomy medicine and physics that later became associated with sciences.in the first part of his academica  cicero introduced the division of philosophy into logic physics and ethics emulating epicurus division of his doctrine into canon physics and ethics.in section thirteen of his lives and opinions of the eminent philosophers  diogenes laërtius rd century the first historian of philosophy established the traditional division of philosophical inquiry into three parts:natural philosophy i.e. physics from greek: ta physika lit. things having to do with physis nature was the study of the constitution and processes of transformation in the physical world;moral philosophy i.e. ethics from êthika having to do with character disposition manners was the study of goodness right and wrong justice and virtue; andmetaphysical philosophy i.e. logic from logikós of or pertaining to reason or speech was the study of existence causation god logic forms and other abstract objects meta ta physika after the physics.this division is not obsolete but has changed: natural philosophy has split into the various natural sciences especially physics astronomy chemistry biology and cosmology; moral philosophy has birthed the social sciences while still including value theory e.g. ethics aesthetics political philosophy etc.; and metaphysical philosophy has given way to formal sciences such as logic mathematics and philosophy of science while still including epistemology cosmology etc.many philosophical debates that began in ancient times are still debated today. mcginn  and others claim that no philosophical progress has occurred during that interval. chalmers  and others by contrast see progress in philosophy similar to that in science while brewer  argued that progress is the wrong standard by which to judge philosophical activity.in one general sense philosophy is associated with wisdom intellectual culture and a search for knowledge. in this sense all cultures and literate societies ask philosophical questions such as how are we to live and what is the nature of reality. a broad and impartial conception of philosophy then finds a reasoned inquiry into such matters as reality morality and life in all world civilizations.statue of aristotle in the aristotlepark of stagirawestern philosophy is the philosophical tradition of the western world dating back to pre-socratic thinkers who were active in th-century greece bce such as thales c.  –  bce and pythagoras c.  –  bce who practiced a love of wisdom latin: philosophia and were also termed students of nature physiologoi.western philosophy can be divided into three eras:while our knowledge of the ancient era begins with thales in the th century bce comparatively little is known about the philosophers who came before socrates commonly known as the pre-socratics. the ancient era was dominated by greek philosophical schools which were significantly influenced by socrates teachings. most notable among these were plato who founded the platonic academy and his student aristotle who founded the peripatetic school. other ancient philosophical traditions included cynicism stoicism skepticism and epicureanism. important topics covered by the greeks included metaphysics with competing theories such as atomism and monism cosmology the nature of the well-lived life eudaimonia the possibility of knowledge and the nature of reason logos. with the rise of the roman empire greek philosophy was also increasingly discussed in latin by romans such as cicero and seneca see roman philosophy.medieval philosophy th–th centuries is the period following the fall of the western roman empire and was dominated by the rise of christianity and hence reflects judeo-christian theological concerns as well as retaining a continuity with greco-roman thought. problems such as the existence and nature of god the nature of faith and reason metaphysics the problem of evil were discussed in this period. some key medieval thinkers include st. augustine thomas aquinas boethius anselm and roger bacon. philosophy for these thinkers was viewed as an aid to theology ancilla theologiae and hence they sought to align their philosophy with their interpretation of sacred scripture. this period saw the development of scholasticism a text critical method developed in medieval universities based on close reading and disputation on key texts. the renaissance period saw increasing focus on classic greco-roman thought and on a robust humanism.early modern philosophy in the western world begins with thinkers such as thomas hobbes and rené descartes –. following the rise of natural science modern philosophy was concerned with developing a secular and rational foundation for knowledge and moved away from traditional structures of authority such as religion scholastic thought and the church. major modern philosophers include spinoza leibniz locke berkeley hume and kant.iiiiiivth-century philosophy sometimes called late modern philosophy was influenced by the wider th-century movement termed the enlightenment and includes figures such as hegel a key figure in german idealism kierkegaard who developed the foundations for existentialism nietzsche a famed anti-christian john stuart mill who promoted utilitarianism karl marx who developed the foundations for communism and the american william james. the th century saw the split between analytic philosophy and continental philosophy as well as philosophical trends such as phenomenology existentialism logical positivism pragmatism and the linguistic turn see contemporary philosophy.an iranian portrait of avicenna on a silver vase. he was one of the most influential philosophers of the islamic golden age.see also: islamic philosophy and middle eastern philosophythe regions of the fertile crescent iran and arabia are home to the earliest known philosophical wisdom literature and is today mostly dominated by islamic culture. early wisdom literature from the fertile crescent was a genre which sought to instruct people on ethical action practical living and virtue through stories and proverbs. in ancient egypt these texts were known as sebayt teachings and they are central to our understandings of ancient egyptian philosophy. babylonian astronomy also included much philosophical speculations about cosmology which may have influenced the ancient greeks. jewish philosophy and christian philosophy are religio-philosophical traditions that developed both in the middle east and in europe which both share certain early judaic texts mainly the tanakh and monotheistic beliefs. jewish thinkers such as the geonim of the talmudic academies in babylonia and maimonides engaged with greek and islamic philosophy. later jewish philosophy came under strong western intellectual influences and includes the works of moses mendelssohn who ushered in the haskalah the jewish enlightenment jewish existentialism and reform judaism.pre-islamic iranian philosophy begins with the work of zoroaster one of the first promoters of monotheism and of the dualism between good and evil. this dualistic cosmogony influenced later iranian developments such as manichaeism mazdakism and zurvanism.after the muslim conquests early islamic philosophy developed the greek philosophical traditions in new innovative directions. this islamic golden age influenced european intellectual developments. the two main currents of early islamic thought are kalam which focuses on islamic theology and falsafa which was based on aristotelianism and neoplatonism. the work of aristotle was very influential among the falsafa such as al-kindi th century avicenna  – june  and averroes th century. others such as al-ghazali were highly critical of the methods of the aristotelian falsafa. islamic thinkers also developed a scientific method experimental medicine a theory of optics and a legal philosophy. ibn khaldun was an influential thinker in philosophy of history.in iran several schools of islamic philosophy continued to flourish after the golden age and include currents such as illuminationist philosophy sufi philosophy and transcendent theosophy. the th- and th-century arab world saw the nahda awakening; aka the arab renaissance movement which influenced contemporary islamic philosophy.indian philosophy sanskrit: darśana lit. point of view perspective refers to the diverse philosophical traditions that emerged since the ancient times on the indian subcontinent. jainism and buddhism originated at the end of the vedic period while hinduism emerged after the period as a fusion of diverse traditions.hindus generally classify these traditions as either orthodox āstika or heterodox nāstika depending on whether they accept the authority of the vedas and the theories of brahman eternal conscious irreducible and ātman soul self breathe therein. the orthodox schools include the hindu traditions of thought while the heterodox schools include the buddhist and the jain traditions.v other schools include the ajñana ājīvika and cārvāka which became extinct over their history.important indian philosophical concepts shared by the indian philosophies and virtues include:akalanka an th century jain monk and philosopher who wrote influential works on indian logicmain article: jain philosophyjain philosophy accepts the concept of a permanent soul jiva as one of the five astikayas eternal infinite categories that make up the substance of existence. the other four being dhárma adharma ākāśa space and pudgala matter.the jain thought separates matter from the soul completely with two major subtraditions: digambara sky dressed naked and śvētāmbara white dressed along with several more minor traditions such as terapanthi.asceticism is a major monastic virtue in jainism. jain texts such as the tattvartha sutra state that right faith right knowledge and right conduct is the path to liberation. the jain thought holds that all existence is cyclic eternal and uncreated. the tattvartha sutra is the earliest known most comprehensive and authoritative compilation of jain philosophy.monks debating at sera monastery tibet . according to jan westerhoff public debates constituted the most important and most visible forms of philosophical exchange in ancient indian intellectual life.buddhist philosophy begins with the thought of gautama buddha fl. between th and th century bce and is preserved in the early buddhist texts. it originated in india and later spread to east asia tibet central asia and southeast asia developing various traditions in these regions. mahayana forms are the dominant buddhist philosophical traditions in east asian regions such as china korea and japan. the theravada forms are dominant in southeast asian countries such as sri lanka burma and thailand.because ignorance to the true nature of things is considered one of the roots of suffering dukkha buddhist philosophy is concerned with epistemology metaphysics ethics and psychology. buddhist philosophical texts must also be understood within the context of meditative practices which are supposed to bring about certain cognitive shifts.: key innovative concepts include the four noble truths as an analysis of dukkha anicca impermanence and anatta non-self.viafter the death of the buddha various groups began to systematize his main teachings eventually developing comprehensive philosophical systems termed abhidharma.: following the abhidharma schools mahayana philosophers such as nagarjuna and vasubandhu developed the theories of śūnyatā emptiness of all phenomena and vijñapti-matra appearance only a form of phenomenology or transcendental idealism. the dignāga school of pramāṇa means of knowledge promoted a sophisticated form of buddhist logico-epistemology.there were numerous schools sub-schools and traditions of buddhist philosophy in india. according to oxford professor of buddhist philosophy jan westerhoff the major indian schools from  bce to  ce were::xxivafter the disappearance of buddhism from india some of these philosophical traditions continued to develop in the tibetan buddhist east asian buddhist and theravada buddhist traditions.citation neededadi shankara is one of the much studied hindu philosophers.main article: hindu philosophythe vedas-based orthodox schools are a part of the hindu traditions and they are traditionally classified into six darśanas: nyaya vaisheshika samkhya yoga mīmāṃsā and vedanta.vii the vedas as a knowledge source were interpreted differently by these six schools of hindu philosophy with varying degrees of overlap. they represent a collection of philosophical views that share a textual connection according to chadha . they also reflect a tolerance for a diversity of philosophical interpretations within hinduism while sharing the same foundation.viiisome of the earliest surviving hindu mystical and philosophical texts are the upanishads of the later vedic period – bce. hindu philosophers of the six schools developed systems of epistemology pramana and investigated topics such as metaphysics ethics psychology guṇa hermeneutics and soteriology within the framework of the vedic knowledge while presenting a diverse collection of interpretations. these schools of philosophy accepted the vedas and the vedic concept of ātman and brahmanvii differed from the following indian religions that rejected the authority of the vedas:cārvāka a materialism school that accepted the existence of free will.ājīvika a materialism school that denied the existence of free will.buddhism a philosophy that denies the existence of ātman unchanging soul selfixx and is based on the teachings and enlightenment of gautama buddha.xijainism a philosophy that accepts the existence of the ātman but is based on the teachings of twenty-four ascetic teachers known as tirthankaras with rishabha as the first and mahavira as the twenty-fourth.the commonly named six orthodox schools over time led to what has been called the hindu synthesis as exemplified by its scripture the bhagavad gita.kitarō nishida professor of philosophy at kyoto university and founder of the kyoto school.main articles: chinese philosophy korean philosophy japanese philosophy vietnamese philosophy and eastern philosophyeast asian philosophical thought began in ancient china and chinese philosophy begins during the western zhou dynasty and the following periods after its fall when the hundred schools of thought flourished th century to  bce. this period was characterized by significant intellectual and cultural developments and saw the rise of the major philosophical schools of china confucianism legalism and daoism as well as numerous other less influential schools. these philosophical traditions developed metaphysical political and ethical theories such tao yin and yang ren and li which along with chinese buddhism directly influenced korean philosophy vietnamese philosophy and japanese philosophy which also includes the native shinto tradition. buddhism began arriving in china during the han dynasty  bce –  ce through a gradual silk road transmission and through native influences developed distinct chinese forms such as chan/zen which spread throughout the east asian cultural sphere. during later chinese dynasties like the ming dynasty – as well as in the korean joseon dynasty – a resurgent neo-confucianism led by thinkers such as wang yangming – became the dominant school of thought and was promoted by the imperial state.in the modern era chinese thinkers incorporated ideas from western philosophy. chinese marxist philosophy developed under the influence of mao zedong while a chinese pragmatism under hu shih and new confucianisms rise was influenced by xiong shili. modern japanese thought meanwhile developed under strong western influences such as the study of western sciences rangaku and the modernist meirokusha intellectual society which drew from european enlightenment thought. the th century saw the rise of state shinto and also japanese nationalism. the kyoto school an influential and unique japanese philosophical school developed from western phenomenology and medieval japanese buddhist philosophy such as that of dogen.african philosophy is philosophy produced by african people philosophy that presents african worldviews ideas and themes or philosophy that uses distinct african philosophical methods. modern african thought has been occupied with ethnophilosophy with defining the very meaning of african philosophy and its unique characteristics and what it means to be african. during the th century ethiopian philosophy developed a robust literary tradition as exemplified by zera yacob. another early african philosopher was anton wilhelm amo c. – who became a respected philosopher in germany. distinct african philosophical ideas include ujamaa the bantu idea of force négritude pan-africanism and ubuntu. contemporary african thought has also seen the development of professional philosophy and of africana philosophy the philosophical literature of the african diaspora which includes currents such as black existentialism by african-americans. some modern african thinkers have been influenced by marxism african-american literature critical theory critical race theory postcolonialism and feminism.a tlamatini aztec philosopher observing the stars from the codex mendoza.indigenous-american philosophical thought consists of a wide variety of beliefs and traditions among different american cultures. among some of u.s. native american communities there is a belief in a metaphysical principle called the great spirit siouan: wakȟáŋ tȟáŋka; algonquian: gitche manitou. another widely shared concept was that of orenda spiritual power. according to whiteley  for the native americans mind is critically informed by transcendental experience dreams visions and so on as well as by reason. the practices to access these transcendental experiences are termed shamanism. another feature of the indigenous american worldviews was their extension of ethics to non-human animals and plants.in mesoamerica aztec philosophy was an intellectual tradition developed by individuals called tlamatini those who know something and its ideas are preserved in various aztec codices. the aztec worldview posited the concept of an ultimate universal energy or force called ōmeteōtl dual cosmic energy which sought a way to live in balance with a constantly changing slippery world.the theory of teotl can be seen as a form of pantheism. aztec philosophers developed theories of metaphysics epistemology values and aesthetics. aztec ethics was focused on seeking tlamatiliztli knowledge wisdom which was based on moderation and balance in all actions as in the nahua proverb the middle good is necessary.the inca civilization also had an elite class of philosopher-scholars termed the amawtakuna who were important in the inca education system as teachers of religion tradition history and ethics. key concepts of andean thought are yanantin and masintin which involve a theory of “complementary opposites” that sees polarities such as male/female dark/light as interdependent parts of a harmonious whole.although men have generally dominated philosophical discourse women philosophers have engaged in the discipline throughout history. ancient examples include hipparchia of maroneia active c.  bce and arete of cyrene active th–th centuries bce. some women philosophers were accepted during the medieval and modern eras but none became part of the western canon until the th and st century when many suggest that g.e.m. anscombe hannah arendt simone de beauvoir and susanne langer entered the canon.in the early s some colleges and universities in the uk and us began admitting women producing more female academics. nevertheless u.s. department of education reports from the s indicate that few women ended up in philosophy and that philosophy is one of the least gender-proportionate fields in the humanities with women making up somewhere between % and % of philosophy faculty according to some studies.philosophical questions can be grouped into various branches. these groupings allow philosophers to focus on a set of similar topics and interact with other thinkers who are interested in the same questions. the groupings also make philosophy easier for students to approach. students can learn the basic principles involved in one aspect of the field without being overwhelmed with the entire set of philosophical theories.various sources present different categorical schemes. the categories adopted in this article aim for breadth and simplicity.these five major branches can be separated into sub-branches and each sub-branch contains many specific fields of study:these divisions are neither exhaustive nor mutually exclusive. a philosopher might specialize in kantian epistemology or platonic aesthetics or modern political philosophy. furthermore these philosophical inquiries sometimes overlap with each other and with other inquiries such as science religion or mathematics.dignaga founded a school of buddhist epistemology and logic.epistemology is the branch of philosophy that studies knowledge. epistemologists examine putative sources of knowledge including perceptual experience reason memory and testimony. they also investigate questions about the nature of truth belief justification and rationality.one of the most notable epistemological debates in the early modern period was between empiricism and rationalism. empiricism places emphasis on observational evidence via sensory experience as the source of knowledge. empiricism is associated with a posteriori knowledge which is obtained through experience such as scientific knowledge. rationalism places emphasis on reason as a source of knowledge. rationalism is associated with a priori knowledge which is independent of experience such as logic and mathematics.philosophical skepticism which raises doubts some or all claims to knowledge has been a topic of interest throughout the history of philosophy. philosophical skepticism dates back thousands of years to ancient philosophers like pyrrho and features prominently in the works of modern philosophers rené descartes and david hume. skepticism has remained a central topic in contemporary epistemological debates.one central debate in contemporary epistemology is about the conditions required for a belief to constitute knowledge which might include truth and justification. this debate was largely the result of attempts to solve the gettier problem. another common subject of contemporary debates is the regress problem which occurs when trying to offer proof or justification for any belief statement or proposition. the problem is that whatever the source of justification may be that source must either be without justification in which case it must be treated as an arbitrary foundation for belief or it must have some further justification in which case justification must either be the result of circular reasoning as in coherentism or the result of an infinite regress as in infinitism.metaphysics is the study of the most general features of reality such as existence time objects and their properties wholes and their parts events processes and causation and the relationship between mind and body. metaphysics includes cosmology the study of the world in its entirety and ontology the study of being.a major point of debate is between realism which holds that there are entities that exist independently of their mental perception and idealism which holds that reality is mentally constructed or otherwise immaterial. metaphysics deals with the topic of identity. essence is the set of attributes that make an object what it fundamentally is and without which it loses its identity while accident is a property that the object has without which the object can still retain its identity. particulars are objects that are said to exist in space and time as opposed to abstract objects such as numbers and universals which are properties held by multiple particulars such as redness or a gender. the type of existence if any of universals and abstract objects is an issue of debate.several subfields of philosophy are closely related to epistemology and metaphysics most notably philosophy of mind and philosophy of language. all of these are sometimes grouped together as core fields in philosophy although this terminology is now considered outdated. philosophy of language explores the nature origins and use of language. philosophy of mind explores the nature of the mind and its relationship to the body as typified by disputes between materialism and dualism. in recent years this branch has become related to cognitive science.value theory or axiology is the major branch of philosophy that addresses topics such as goodness beauty and justice. value theory includes ethics aesthetics political philosophy feminist philosophy philosophy of law and more.citation neededthe beijing imperial college was an intellectual center for confucian ethics and classics during the yuan ming and qing dynasties.ethics also known as moral philosophy studies what constitutes good and bad conduct right and wrong values and good and evil. its primary investigations include how to live a good life and identifying standards of morality. it also includes investigating whether or not there is a best way to live or a universal moral standard and if so how we come to learn about it. the main branches of ethics are normative ethics meta-ethics and applied ethics.the three main views in ethics about what constitute moral actions are:consequentialism which judges actions based on their consequences. one such view is utilitarianism which judges actions based on the net happiness or pleasure and/or lack of suffering or pain that they produce.deontology which judges actions based on whether or not they are in accordance with ones moral duty. in the standard form defended by immanuel kant deontology is concerned with whether or not a choice respects the moral agency of other people regardless of its consequences.virtue ethics which judges actions based on the moral character of the agent who performs them and whether they conform to what an ideally virtuous agent would do.aestheticsmain article: aestheticsaesthetics is the critical reflection on art culture and nature. it addresses the nature of art beauty and taste enjoyment emotional values perception and with the creation and appreciation of beauty. it is more precisely defined as the study of sensory or sensori-emotional values sometimes called judgments of sentiment and taste. its major divisions are art theory literary theory film theory and music theory. an example from art theory is to discern the set of principles underlying the work of a particular artist or artistic movement such as the cubist aesthetic. the philosophy of film analyzes films and filmmakers for their philosophical content and explores film images cinema etc. as a medium for philosophical reflection and expression.citation neededthomas hobbes best known for his leviathan which expounded an influential formulation of social contract theory.political philosophy is the study of government and the relationship of individuals or families and clans to communities including the state.citation needed it includes questions about justice law property and the rights and obligations of the citizen. politics and ethics are traditionally linked subjects as both discuss the question of how people should live together.citation neededphilosophy of law aka jurisprudence: explores the varying theories explaining the nature and interpretation of laws.philosophy of education: analyzes the definition and content of education as well as the goals and challenges of educators.feminist philosophy: explores questions surrounding gender sexuality and the body including the nature of feminism itself as a social and philosophical movement.logic science and mathematicsthis article may not properly summarize its corresponding main article. please help improve it by rewriting it in an encyclopedic style. june  learn how and when to remove this template messagethe topics of philosophy of science are numbers symbols and the formal methods of reasoning as employed in the social sciences and natural sciences.citation neededlogic is the study of reasoning and argument. an argument is a connected series of statements intended to establish a proposition.citation needed the connected series of statements are premises and the proposition is the conclusion. for example:all humans are mortal. premisesocrates is a human. premisetherefore socrates is mortal. conclusiondeductive reasoning is when given certain premises conclusions are unavoidably implied. rules of inference are used to infer conclusions such as modus ponens where given “a” and “if a then b” then “b” must be concluded.because sound reasoning is an essential element of all sciences social sciences and humanities disciplines logic became a formal science. sub-fields include mathematical logic philosophical logic modal logic computational logic and non-classical logics. a major question in the philosophy of mathematics is whether mathematical entities are objective and discovered called mathematical realism or invented called mathematical antirealism.this branch explores the foundations methods history implications and purpose of science. many of its sub-divisions correspond to a specific branch of science. for example philosophy of biology deals specifically with the metaphysical epistemological and ethical issues in the biomedical and life sciences. the philosophy of mathematics studies the philosophical assumptions foundations and implications of mathematics.citation neededsome contemporary philosophers specialize in studying one or more historical periods. the history of philosophy study of a specific period individual or school should not be confused with the philosophy of history a minor subfield most commonly associated with historicism as first defended in hegels lectures on the philosophy of history.citation neededphilosophy of religion deals with questions that involve religion and religious ideas from a philosophically neutral perspective as opposed to theology which begins from religious convictions. traditionally religious questions were not seen as a separate field from philosophy proper the idea of a separate field only arose in the th century.xiiissues include the existence of god the relationship between reason and faith questions of religious epistemology the relationship between religion and science how to interpret religious experiences questions about the possibility of an afterlife the problem of religious language and the existence of souls and responses to religious pluralism and diversity.metaphilosophy explores the aims of philosophy its boundaries and its methods.a variety of other academic and non-academic approaches have been explored. the ideas conceived by a society have profound repercussions on what actions the society performs. weaver argued that ideas have consequences.philosophy yields applications such as those in ethics—applied ethics in particular—and political philosophy. the political and economic philosophies of confucius sun tzu chanakya ibn khaldun ibn rushd ibn taymiyyah machiavelli leibniz hobbes locke rousseau adam smith john stuart mill marx tolstoy gandhi and martin luther king jr. have been used to shape and justify governments and their actions. progressive education as championed by dewey had a profound impact on th-century us educational practices. descendants of this movement include efforts in philosophy for children which are part of philosophy education. clausewitzs political philosophy of war has had a profound effect on statecraft international politics and military strategy in the th century especially around world war ii. logic is important in mathematics linguistics psychology computer science and computer engineering.other important applications can be found in epistemology which aid in understanding the requisites for knowledge sound evidence and justified belief important in law economics decision theory and a number of other disciplines. the philosophy of science discusses the underpinnings of the scientific method and has affected the nature of scientific investigation and argumentation. philosophy thus has fundamental implications for science as a whole. for example the strictly empirical approach of b.f. skinners behaviorism affected for decades the approach of the american psychological establishment. deep ecology and animal rights examine the moral situation of humans as occupants of a world that has non-human occupants to consider also. aesthetics can help to interpret discussions of music literature the plastic arts and the whole artistic dimension of life. in general the various philosophies strive to provide practical activities with a deeper understanding of the theoretical or conceptual underpinnings of their fields.the relationship between x and the philosophy of x is often intensely debated. richard feynman argued that the philosophy of a topic is irrelevant to its primary study saying that philosophy of science is as useful to scientists as ornithology is to birds.citation needed curtis white  by contrast argued that philosophical tools are essential to humanities sciences and social sciences.main article: contemporary philosophy § outside the professionmany inquiries outside of academia are philosophical in the broad sense. novelists playwrights filmmakers and musicians as well as scientists and others engage in recognizably philosophical activity.some of those who study philosophy become professional philosophers typically by working as professors who teach research and write in academic institutions. however most students of academic philosophy later contribute to law journalism religion sciences politics business or various arts. for example public figures who have degrees in philosophy include comedians steve martin and ricky gervais filmmaker terrence malick pope john paul ii wikipedia co-founder larry sanger technology entrepreneur peter thiel supreme court justice stephen bryer and vice presidential candidate carly fiorina.recent efforts to avail the general public to the work and relevance of philosophers include the million-dollar berggruen prize first awarded to charles taylor in .germany was the first country to professionalize philosophy. the doctorate of philosophy phd developed in germany as the terminal teachers credential in the mid th century. at the end of  georg wilhelm friedrich hegel was the first philosopher to be appointed professor by the state namely by the prussian minister of education as an effect of napoleonic reform in prussia. in the united states the professionalization grew out of reforms to the american higher-education system largely based on the german model.within the last century philosophy has increasingly become a professional discipline practiced within universities like other academic disciplines. accordingly it has become less general and more specialized. in the view of one prominent recent historian: philosophy has become a highly organized discipline done by specialists primarily for other specialists. the number of philosophers has exploded the volume of publication has swelled and the subfields of serious philosophical investigation have multiplied. not only is the broad field of philosophy today far too vast to be embraced by one mind something similar is true even of many highly specialized subfields. some philosophers argue that this professionalization has negatively affected the discipline.the end result of professionalization for philosophy has meant that work being done in the field is now almost exclusively done by university professors holding a doctorate in the field publishing in highly technical peer-reviewed journals. while it remains common among the population at large for a person to have a set of religious political or philosophical views that they consider their philosophy these views are rarely informed by or connected to the work being done in professional philosophy today. furthermore unlike many of the sciences for which there has come to be a healthy industry of books magazines and television shows meant to popularize science and communicate the technical results of a scientific field to the general populace works by professional philosophers directed at an audience outside the profession remain rare. philosopher michael sandels book justice: whats the right thing to do and harry frankfurts on bullshit are examples of works that hold the uncommon distinction of having been written by professional philosophers but directed at and ultimately popular among a broader audience of non-philosophers. both works became new york times best sellers.this article is about the usage of premise in discourse and logic. for other uses see premise disambiguation.a premise or premissa is a statement that an argument claims will induce or justify a conclusion. it is an assumption that something is true.in logic an argument requires a set of at least two declarative sentences or propositions known as the premises or premisses along with another declarative sentence or proposition known as the conclusion. this structure of two premises and one conclusion forms the basic argumentative structure. more complex arguments can use a sequence of rules to connect several premises to one conclusion or to derive a number of conclusions from the original premises which then act as premises for additional conclusions. an example of this is the use of the rules of inference found within symbolic logic.aristotle held that any logical argument could be reduced to two premises and a conclusion. premises are sometimes left unstated in which case they are called missing premises for example:socrates is mortal because all men are mortal.it is evident that a tacitly understood claim is that socrates is a man. the fully expressed reasoning is thus:because all men are mortal and socrates is a man socrates is mortal.in this example the independent clauses preceding the comma namely all men are mortal and socrates is a man are the premises while socrates is mortal is the conclusion.the proof of a conclusion depends on both the truth of the premises and the validity of the argument. also additional information is required over and above the meaning of the premise to determine if the full meaning of the conclusion coincides with what is.for euclid premises constitute two of the three propositions in a syllogism with the other being the conclusion. these categorical propositions contain three terms: subject and predicate of the conclusion and the middle term. the subject of the conclusion is called the minor term while the predicate is the major term. the premise that contains the middle term and major term is called the major premise while the premise that contains the middle term and minor term is called the minor premise.a premise can also be an indicator word if statements have been combined into a logical argument and such word functions to mark the role of one or more of the statements. it indicates that the statement it is attached to is a premise. in general usage the spelling premise is most common; however in the field of logic the spelling premiss is often used especially among british writers.references audi robert ed. . the cambridge dictionary of philosophy nd ed.. cambridge: cambridge university press. p. . isbn ---x. argument: a sequence of statements such that some of them the premises purport to give reasons to accept another of them the conclusion gullberg jan . mathematics : from the birth of numbers. new york: w. w. norton & company. p. . isbn ---x. byrne patrick hugh . analysis and science in aristotle. new york: state university of new york press. p. . isbn . ryan john . studies in philosophy and the history of philosophy volume . washington d.c.: cua press. p. . isbn . potts robert . euclids elements of geometry book . london: longman green longman roberts & green. p. . luckhardt c. grant; bechtel william . how to do things with logic. hillsdale nj: lawrence erlbaum associates publishers. p. . isbn .the hubble extreme deep field xdf was completed in september  and shows the farthest galaxies ever photographed. except for the few stars in the foreground which are bright and easily recognizable because only they have diffraction spikes every speck of light in the photo is an individual galaxy some of them as old as . billion years; the observable universe is estimated to contain more than  trillion galaxies.cosmology from the greek κόσμος kosmos world and -λογία -logia study of is a branch of astronomy concerned with the studies of the origin and evolution of the universe from the big bang to today and on into the future. it is the scientific study of the origin evolution and eventual fate of the universe. physical cosmology is the scientific study of the universes origin its large-scale structures and dynamics and its ultimate fate as well as the laws of science that govern these areas.the term cosmology was first used in english in  in thomas blounts glossographia and in  taken up in latin by german philosopher christian wolff in cosmologia generalis.religious or mythological cosmology is a body of beliefs based on mythological religious and esoteric literature and traditions of creation myths and eschatology.physical cosmology is studied by scientists such as astronomers and physicists as well as philosophers such as metaphysicians philosophers of physics and philosophers of space and time. because of this shared scope with philosophy theories in physical cosmology may include both scientific and non-scientific propositions and may depend upon assumptions that cannot be tested. cosmology differs from astronomy in that the former is concerned with the universe as a whole while the latter deals with individual celestial objects. modern physical cosmology is dominated by the big bang theory which attempts to bring together observational astronomy and particle physics; more specifically a standard parameterization of the big bang with dark matter and dark energy known as the lambda-cdm model.theoretical astrophysicist david n. spergel has described cosmology as a historical science because when we look out in space we look back in time due to the finite nature of the speed of light.the image above contains clickable linkssee also: human timeline and life timeline.physics and astrophysics have played a central role in shaping the understanding of the universe through scientific observation and experiment. physical cosmology was shaped through both mathematics and observation in an analysis of the whole universe. the universe is generally understood to have begun with the big bang followed almost instantaneously by cosmic inflation; an expansion of space from which the universe is thought to have emerged . ± . billion years ago. cosmogony studies the origin of the universe and cosmography maps the features of the universe.in diderots encyclopédie cosmology is broken down into uranology the science of the heavens aerology the science of the air geology the science of the continents and hydrology the science of waters.metaphysical cosmology has also been described as the placing of humans in the universe in relationship to all other entities. this is exemplified by marcus aureliuss observation that a mans place in that relationship: he who does not know what the world is does not know where he is and he who does not know for what purpose the world exists does not know who he is nor what the world is.physical cosmology is the branch of physics and astrophysics that deals with the study of the physical origins and evolution of the universe. it also includes the study of the nature of the universe on a large scale. in its earliest form it was what is now known as celestial mechanics the study of the heavens. greek philosophers aristarchus of samos aristotle and ptolemy proposed different cosmological theories. the geocentric ptolemaic system was the prevailing theory until the th century when nicolaus copernicus and subsequently johannes kepler and galileo galilei proposed a heliocentric system. this is one of the most famous examples of epistemological rupture in physical cosmology.evidence of gravitational waves in the infant universe may have been uncovered by the microscopic examination of the focal plane of the bicep radio telescope.isaac newtons principia mathematica published in  was the first description of the law of universal gravitation. it provided a physical mechanism for keplers laws and also allowed the anomalies in previous systems caused by gravitational interaction between the planets to be resolved. a fundamental difference between newtons cosmology and those preceding it was the copernican principle—that the bodies on earth obey the same physical laws as all the celestial bodies. this was a crucial philosophical advance in physical cosmology.modern scientific cosmology is usually considered to have begun in  with albert einsteins publication of his final modification of general relativity in the paper cosmological considerations of the general theory of relativity although this paper was not widely available outside of germany until the end of world war i. general relativity prompted cosmogonists such as willem de sitter karl schwarzschild and arthur eddington to explore its astronomical ramifications which enhanced the ability of astronomers to study very distant objects. physicists began changing the assumption that the universe was static and unchanging. in  alexander friedmann introduced the idea of an expanding universe that contained moving matter. around the same time  to  the great debate took place with early cosmologists such as heber curtis and ernst öpik determining that some nebulae seen in telescopes were separate galaxies far distant from our own.in parallel to this dynamic approach to cosmology one long-standing debate about the structure of the cosmos was coming to a climax. mount wilson astronomer harlow shapley championed the model of a cosmos made up of the milky way star system only; while heber d. curtis argued for the idea that spiral nebulae were star systems in their own right as island universes. this difference of ideas came to a climax with the organization of the great debate on  april  at the meeting of the u.s. national academy of sciences in washington d.c. the debate was resolved when edwin hubble detected cepheid variables in the andromeda galaxy in  and . their distance established spiral nebulae well beyond the edge of the milky way.subsequent modelling of the universe explored the possibility that the cosmological constant introduced by einstein in his  paper may result in an expanding universe depending on its value. thus the big bang model was proposed by the belgian priest georges lemaître in  which was subsequently corroborated by edwin hubbles discovery of the redshift in  and later by the discovery of the cosmic microwave background radiation by arno penzias and robert woodrow wilson in . these findings were a first step to rule out some of many alternative cosmologies.since around  several dramatic advances in observational cosmology have transformed cosmology from a largely speculative science into a predictive science with precise agreement between theory and observation. these advances include observations of the microwave background from the cobe wmap and planck satellites large new galaxy redshift surveys including dfgrs and sdss and observations of distant supernovae and gravitational lensing. these observations matched the predictions of the cosmic inflation theory a modified big bang theory and the specific version known as the lambda-cdm model. this has led many to refer to modern times as the golden age of cosmology.on  march  astronomers at the harvard-smithsonian center for astrophysics announced the detection of gravitational waves providing strong evidence for inflation and the big bang. however on  june  lowered confidence in confirming the cosmic inflation findings was reported.on  december  at the planck  meeting in ferrara italy astronomers reported that the universe is . billion years old and is composed of .% atomic matter .% dark matter and .% dark energy.religious or mythological cosmology is a body of beliefs based on mythological religious and esoteric literature and traditions of creation and eschatology.cosmology deals with the world as the totality of space time and all phenomena. historically it has had quite a broad scope and in many cases was founded in religion. in modern use metaphysical cosmology addresses questions about the universe which are beyond the scope of science. it is distinguished from religious cosmology in that it approaches these questions using philosophical methods like dialectics. modern metaphysical cosmology tries to address questions such as:what is the origin of the universe what is its first cause is its existence necessary see monism pantheism emanationism and creationismwhat are the ultimate material components of the universe see mechanism dynamism hylomorphism atomismwhat is the ultimate reason for the existence of the universe does the cosmos have a purpose see teleologydoes the existence of consciousness have a purpose how do we know what we know about the totality of the cosmos does cosmological reasoning reveal metaphysical truths see epistemologyhistorical cosmologiesfurther information: timeline of cosmological theories and nicolaus copernicus § copernican systemkinematic expansion without space expansion	rejects general relativity and the expanding space paradigm. gravity not included as initial assumption. obeys cosmological principle and special relativity; consists of a finite spherical cloud of particles or galaxies that expands within an infinite and otherwise empty flat space. it has a center and a cosmic edge surface of the particle cloud that expands at light speed. explanation of gravity was elaborate and unconvincing.friedmann–lemaître–robertson–walker class of models	howard robertson arthur walker 	uniformly expanding	class of universes that are homogeneous and isotropic. spacetime separates into uniformly curved space and cosmic time common to all co-moving observers. the formulation system is now known as the flrw or robertson–walker metrics of cosmic time and curved space.steady-state	hermann bondi thomas gold 	expanding steady state infinite	matter creation rate maintains constant density. continuous creation out of nothing from nowhere. exponential expansion. deceleration term q = −.steady-state	fred hoyle 	expanding steady state; but unstable	matter creation rate maintains constant density. but since matter creation rate must be exactly balanced with the space expansion rate the system is unstable.ambiplasma	hannes alfvén  oskar klein	cellular universe expanding by means of matter–antimatter annihilation	based on the concept of plasma cosmology. the universe is viewed as meta-galaxies divided by double layers and thus a bubble-like nature. other universes are formed from other bubbles. ongoing cosmic matter-antimatter annihilations keep the bubbles separated and moving apart preventing them from interacting.brans–dicke theory	carl h. brans robert h. dicke	expanding	based on machs principle. g varies with time as universe expands. but nobody is quite sure what machs principle actually means.citation neededcosmic inflation	alan guth 	big bang modified to solve horizon and flatness problems	based on the concept of hot inflation. the universe is viewed as a multiple quantum flux – hence its bubble-like nature. other universes are formed from other bubbles. ongoing cosmic expansion kept the bubbles separated and moving apart.eternal inflation a multiple universe model	andreï linde 	big bang with cosmic inflation	multiverse based on the concept of cold inflation in which inflationary events occur at random each with independent initial conditions; some expand into bubble universes supposedly like our entire cosmos. bubbles nucleate in a spacetime foam.cyclic model	paul steinhardt; neil turok 	expanding and contracting in cycles; m-theory.	two parallel orbifold planes or m-branes collide periodically in a higher-dimensional space. with quintessence or dark energy.cyclic model	lauris baum; paul frampton 	solution of tolmans entropy problem	phantom dark energy fragments universe into large number of disconnected patches. our patch contracts containing only dark energy with zero entropy.table notes: the term static simply means not expanding and not contracting. symbol g represents newtons gravitational constant; λ lambda is the cosmological constant.in metaphysics a universal is what particular things have in common namely characteristics or qualities. in other words universals are repeatable or recurrent entities that can be instantiated or exemplified by many particular things. for example suppose there are two chairs in a room each of which is green. these two chairs both share the quality of chairness as well as greenness or the quality of being green; in other words they share a universal. there are three major kinds of qualities or characteristics: types or kinds e.g. mammal properties e.g. short strong and relations e.g. father of next to. these are all different types of universals.paradigmatically universals are abstract e.g. humanity whereas particulars are concrete e.g. the personhood of socrates. however universals are not necessarily abstract and particulars are not necessarily concrete. for example one might hold that numbers are particular yet abstract objects. likewise some philosophers such as d. m. armstrong consider universals to be concrete.most do not consider classes to be universals although some prominent philosophers do as john bigelow.the history of any creation went through a process of qualifications meeting dependancies of that type thing including all parts put together to make it an accepted thing of its particular type. a chair must first exist upon a surface with the force of gravity upon it. the chair must be upon something solid and it must provide a platform for something to sit upon. any other universals for “chairness” must qualify the particular dependencies set forth by authority. the first chair qualified itself as a chair from it’s propriety. universals exist in every created thing but only in the individual subparts themselves not in the whole thing itself. universals can be thought of as an evolution of a creation’s life constantly on a journey towards perfection.the problem of universals is an ancient problem in metaphysics about whether universals exist. the problem arises from attempts to account for the phenomenon of similarity or attribute agreement among things. for example grass and granny smith apples are similar or agree in attribute namely in having the attribute of greenness. the issue is how to account for this sort of agreement in attribute among things.there are many philosophical positions regarding universals. taking beauty as an example three positions are:idealism or conceptualism: beauty is a property constructed in the mind so it exists only in descriptions of things.platonic realism: beauty is a property that exists in an ideal form independently of any mind or thing.aristotelian realism: beauty is a property that only exists when beautiful things exist.taking a broader view the main positions are generally considered classifiable as: realism nominalism and idealism sometimes simply named anti-realism with regard to universals. realists posit the existence of independent abstract universals to account for attribute agreement. nominalists deny that universals exist claiming that they are not necessary to explain attribute agreement. conceptualists posit that universals exist only in the mind or when conceptualized denying the independent existence of universals. complications which arise include the implications of language use and the complexity of relating language to ontology.a universal may have instances known as its particulars. for example the type dog or doghood is a universal as are the property red or redness and the relation betweenness or being between. any particular dog red thing or object that is between other things is not a universal however but is an instance of a universal. that is a universal type doghood property redness or relation betweenness inheres in a particular object a specific dog red thing or object between other things.platonic realism holds universals to be the referents of general terms such as the abstract nonphysical non-mental entities to which words such as sameness circularity and beauty refer. particulars are the referents of proper names such as phaedo or of definite descriptions that identify single objects such as the phrase that bed over there. other metaphysical theories may use the terminology of universals to describe physical entities.platos examples of what we might today call universals included mathematical and geometrical ideas such as a circle and natural numbers as universals. platos views on universals did however vary across several different discussions. in some cases plato spoke as if the perfect circle functioned as the form or blueprint for all copies and for the word definition of circle. in other discussions plato describes particulars as participating in the associated universal.contemporary realists agree with the thesis that universals are multiply-exemplifiable entities. examples include by d. m. armstrong nicholas wolterstorff reinhardt grossmann michael loux.nominalists hold that universals are not real mind-independent entities but either merely concepts sometimes called conceptualism or merely names. nominalists typically argue that properties are abstract particulars like tropes rather than universals. jp moreland distinguishes between extreme and moderate nominalism. examples of nominalists include the medieval philosophers roscelin of compiègne and william of ockham and contemporary philosophers w. v. o. quine wilfred sellars d. c. williams and keith campbell.the ness-ity-hood principle is used mainly by english-speaking philosophers to generate convenient concise names for universals or properties. according to the ness-ity-hood principle a name for any universal may be formed that is distinctive of left-handers may be formed by taking the predicate left-handed and adding ness which yields the name left-handedness. the principle is most helpful in cases where there is not an established or standard name of the universal in ordinary english usage: what is the name of the universal distinctive of chairs chair in english is used not only as a subject as in the chair is broken but also as a predicate as in that is a chair. so to generate a name for the universal distinctive of chairs take the predicate chair and add ness which yields chairness.memory is the faculty of the brain by which data or information is encoded stored and retrieved when needed. it is the retention of information over time for the purpose of influencing future action. if past events could not be remembered it would be impossible for language relationships or personal identity to develop. memory loss is usually described as forgetfulness or amnesia.memory is often understood as an informational processing system with explicit and implicit functioning that is made up of a sensory processor short-term or working memory and long-term memory. this can be related to the neuron. the sensory processor allows information from the outside world to be sensed in the form of chemical and physical stimuli and attended to various levels of focus and intent. working memory serves as an encoding and retrieval processor. information in the form of stimuli is encoded in accordance with explicit or implicit functions by the working memory processor. the working memory also retrieves information from previously stored material. finally the function of long-term memory is to store data through various categorical models or systems.declarative or explicit memory is the conscious storage and recollection of data. under declarative memory resides semantic and episodic memory. semantic memory refers to memory that is encoded with specific meaning while episodic memory refers to information that is encoded along a spatial and temporal plane. declarative memory is usually the primary process thought of when referencing memory. non-declarative or implicit memory is the unconscious storage and recollection of information. an example of a non-declarative process would be the unconscious learning or retrieval of information by way of procedural memory or a priming phenomenon. priming is the process of subliminally arousing specific responses from memory and shows that not all memory is consciously activated whereas procedural memory is the slow and gradual learning of skills that often occurs without conscious attention to learning.memory is not a perfect processor and is affected by many factors. the ways by which information is encoded stored and retrieved can all be corrupted. the amount of attention given new stimuli can diminish the amount of information that becomes encoded for storage. also the storage process can become corrupted by physical damage to areas of the brain that are associated with memory storage such as the hippocampus. finally the retrieval of information from long-term memory can be disrupted because of decay within long-term memory. normal functioning decay over time and brain damage all affect the accuracy and capacity of the memory.sensory memory holds information derived from the senses less than one second after an item is perceived. the ability to look at an item and remember what it looked like with just a split second of observation or memorization is the example of sensory memory. it is out of cognitive control and is an automatic response. with very short presentations participants often report that they seem to see more than they can actually report. the first experiments exploring this form of sensory memory were precisely conducted by george sperling  using the partial report paradigm. subjects were presented with a grid of  letters arranged into three rows of four. after a brief presentation subjects were then played either a high medium or low tone cuing them which of the rows to report. based on these partial report experiments sperling was able to show that the capacity of sensory memory was approximately  items but that it degraded very quickly within a few hundred milliseconds. because this form of memory degrades so quickly participants would see the display but be unable to report all of the items  in the whole report procedure before they decayed. this type of memory cannot be prolonged via rehearsal.three types of sensory memories exist. iconic memory is a fast decaying store of visual information a type of sensory memory that briefly stores an image that has been perceived for a small duration. echoic memory is a fast decaying store of auditory information also a sensory memory that briefly stores sounds that have been perceived for short durations. haptic memory is a type of sensory memory that represents a database for touch stimuli.short-term memory is also known as working memory. short-term memory allows recall for a period of several seconds to a minute without rehearsal. its capacity however is very limited. in  george a. miller - when working at bell laboratories conducted experiments showing that the store of short-term memory was ± items. hence the title of his famous paper the magical number ±. modern estimates of the capacity of short-term memory are lower typically of the order of – items; however memory capacity can be increased through a process called chunking. for example in recalling a ten-digit telephone number a person could chunk the digits into three groups: first the area code such as  then a three-digit chunk  and last a four-digit chunk . this method of remembering telephone numbers is far more effective than attempting to remember a string of  digits; this is because we are able to chunk the information into meaningful groups of numbers. this is reflected in some countries tendencies to display telephone numbers as several chunks of two to four numbers.short-term memory is believed to rely mostly on an acoustic code for storing information and to a lesser extent on a visual code. conrad  found that test subjects had more difficulty recalling collections of letters that were acoustically similar e.g. e p d. confusion with recalling acoustically similar letters rather than visually similar letters implies that the letters were encoded acoustically. conrads  study however deals with the encoding of written text; thus while memory of written language may rely on acoustic components generalizations to all forms of memory cannot be made.olin levi warner memory . library of congress thomas jefferson building washington d.c.the storage in sensory memory and short-term memory generally has a strictly limited capacity and duration which means that information is not retained indefinitely. by contrast long-term memory can store much larger quantities of information for potentially unlimited duration sometimes a whole life span. its capacity is immeasurable. for example given a random seven-digit number one may remember it for only a few seconds before forgetting suggesting it was stored in short-term memory. on the other hand one can remember telephone numbers for many years through repetition; this information is said to be stored in long-term memory.while short-term memory encodes information acoustically long-term memory encodes it semantically: baddeley  discovered that after  minutes test subjects had the most difficulty recalling a collection of words that had similar meanings e.g. big large great huge long-term. another part of long-term memory is episodic memory which attempts to capture information such as what when and where. with episodic memory individuals are able to recall specific events such as birthday parties and weddings.short-term memory is supported by transient patterns of neuronal communication dependent on regions of the frontal lobe especially dorsolateral prefrontal cortex and the parietal lobe. long-term memory on the other hand is maintained by more stable and permanent changes in neural connections widely spread throughout the brain. the hippocampus is essential for learning new information to the consolidation of information from short-term to long-term memory although it does not seem to store information itself. it was thought that without the hippocampus new memories were unable to be stored into long-term memory and that there would be a very short attention span as first gleaned from patient henry molaison after what was thought to be the full removal of both his hippocampi. more recent examination of his brain post-mortem shows that the hippocampus was more intact than first thought throwing theories drawn from the initial data into question. the hippocampus may be involved in changing neural connections for a period of three months or more after the initial learning.research has suggested that long-term memory storage in humans may be maintained by dna methylation and the prion gene.the multi-store model also known as atkinson–shiffrin memory model was first described in  by atkinson and shiffrin.the multi-store model has been criticised for being too simplistic. for instance long-term memory is believed to be actually made up of multiple subcomponents such as episodic and procedural memory. it also proposes that rehearsal is the only mechanism by which information eventually reaches long-term storage but evidence shows us capable of remembering things without rehearsal.the model also shows all the memory stores as being a single unit whereas research into this shows differently. for example short-term memory can be broken up into different units such as visual information and acoustic information. in a study by zlonoga and gerber  patient kf demonstrated certain deviations from the atkinson–shiffrin model. patient kf was brain damaged displaying difficulties regarding short-term memory. recognition of sounds such as spoken numbers letters words and easily identifiable noises such as doorbells and cats meowing were all impacted. visual short-term memory was unaffected suggesting a dichotomy between visual and audial memory.in  baddeley and hitch proposed a working memory model that replaced the general concept of short-term memory with an active maintenance of information in the short-term storage. in this model working memory consists of three basic stores: the central executive the phonological loop and the visuo-spatial sketchpad. in  this model was expanded with the multimodal episodic buffer baddeleys model of working memory.the central executive essentially acts as an attention sensory store. it channels information to the three component processes: the phonological loop the visuo-spatial sketchpad and the episodic buffer.the phonological loop stores auditory information by silently rehearsing sounds or words in a continuous loop: the articulatory process for example the repetition of a telephone number over and over again. a short list of data is easier to remember.the visuospatial sketchpad stores visual and spatial information. it is engaged when performing spatial tasks such as judging distances or visual ones such as counting the windows on a house or imagining images.the episodic buffer is dedicated to linking information across domains to form integrated units of visual spatial and verbal information and chronological ordering e.g. the memory of a story or a movie scene. the episodic buffer is also assumed to have links to long-term memory and semantical meaning.the working memory model explains many practical observations such as why it is easier to do two different tasks one verbal and one visual than two similar tasks e.g. two visual and the aforementioned word-length effect. working memory is also the premise for what allows us to do everyday activities involving thought. it is the section of memory where we carry out thought processes and use them to learn and reason about topics.researchers distinguish between recognition and recall memory. recognition memory tasks require individuals to indicate whether they have encountered a stimulus such as a picture or a word before. recall memory tasks require participants to retrieve previously learned information. for example individuals might be asked to produce a series of actions they have seen before or to say a list of words they have heard before.topographic memory involves the ability to orient oneself in space to recognize and follow an itinerary or to recognize familiar places. getting lost when traveling alone is an example of the failure of topographic memory.flashbulb memories are clear episodic memories of unique and highly emotional events. people remembering where they were or what they were doing when they first heard the news of president kennedys assassination the sydney siege or of / are examples of flashbulb memories.anderson  divides long-term memory into declarative explicit and procedural implicit memories.declarative memory requires conscious recall in that some conscious process must call back the information. it is sometimes called explicit memory since it consists of information that is explicitly stored and retrieved.declarative memory can be further sub-divided into semantic memory concerning principles and facts taken independent of context; and episodic memory concerning information specific to a particular context such as a time and place. semantic memory allows the encoding of abstract knowledge about the world such as paris is the capital of france. episodic memory on the other hand is used for more personal memories such as the sensations emotions and personal associations of a particular place or time. episodic memories often reflect the firsts in life such as a first kiss first day of school or first time winning a championship. these are key events in ones life that can be remembered clearly. research suggests that declarative memory is supported by several functions of the medial temporal lobe system which includes the hippocampus. autobiographical memory – memory for particular events within ones own life – is generally viewed as either equivalent to or a subset of episodic memory. visual memory is part of memory preserving some characteristics of our senses pertaining to visual experience. one is able to place in memory information that resembles objects places animals or people in sort of a mental image. visual memory can result in priming and it is assumed some kind of perceptual representational system underlies this phenomenon.in contrast procedural memory or implicit memory is not based on the conscious recall of information but on implicit learning. it can best be summarized as remembering how to do something. procedural memory is primarily used in learning motor skills and can be considered a subset of implicit memory. it is revealed when one does better in a given task due only to repetition – no new explicit memories have been formed but one is unconsciously accessing aspects of those previous experiences. procedural memory involved in motor learning depends on the cerebellum and basal ganglia.a characteristic of procedural memory is that the things remembered are automatically translated into actions and thus sometimes difficult to describe. some examples of procedural memory include the ability to ride a bike or tie shoelaces.another major way to distinguish different memory functions is whether the content to be remembered is in the past retrospective memory or in the future prospective memory. thus retrospective memory as a category includes semantic episodic and autobiographical memory. in contrast prospective memory is memory for future intentions or remembering to remember winograd . prospective memory can be further broken down into event- and time-based prospective remembering. time-based prospective memories are triggered by a time-cue such as going to the doctor action at pm cue. event-based prospective memories are intentions triggered by cues such as remembering to post a letter action after seeing a mailbox cue. cues do not need to be related to the action as the mailbox/letter example and lists sticky-notes knotted handkerchiefs or string around the finger all exemplify cues that people use as strategies to enhance prospective memory.infants do not have the language ability to report on their memories and so verbal reports cannot be used to assess very young childrens memory. throughout the years however researchers have adapted and developed a number of measures for assessing both infants recognition memory and their recall memory. habituation and operant conditioning techniques have been used to assess infants recognition memory and the deferred and elicited imitation techniques have been used to assess infants recall memory.techniques used to assess infants recognition memory include the following:visual paired comparison procedure relies on habituation: infants are first presented with pairs of visual stimuli such as two black-and-white photos of human faces for a fixed amount of time; then after being familiarized with the two photos they are presented with the familiar photo and a new photo. the time spent looking at each photo is recorded. looking longer at the new photo indicates that they remember the familiar one. studies using this procedure have found that - to -month-olds can retain information for as long as fourteen days.operant conditioning technique: infants are placed in a crib and a ribbon that is connected to a mobile overhead is tied to one of their feet. infants notice that when they kick their foot the mobile moves – the rate of kicking increases dramatically within minutes. studies using this technique have revealed that infants memory substantially improves over the first -months. whereas - to -month-olds can retain an operant response such as activating the mobile by kicking their foot for a week -month-olds can retain it for two weeks and -month-olds can retain a similar operant response for as long as  weeks.techniques used to assess infants recall memory include the following:deferred imitation technique: an experimenter shows infants a unique sequence of actions such as using a stick to push a button on a box and then after a delay asks the infants to imitate the actions. studies using deferred imitation have shown that -month-olds memories for the sequence of actions can last for as long as four months.elicited imitation technique: is very similar to the deferred imitation technique; the difference is that infants are allowed to imitate the actions before the delay. studies using the elicited imitation technique have shown that -month-olds can recall the action sequences twelve months later.to assess children and older adultsresearchers use a variety of tasks to assess older children and adults memory. some examples are:paired associate learning – when one learns to associate one specific word with another. for example when given a word such as safe one must learn to say another specific word such as green. this is stimulus and response.free recall – during this task a subject would be asked to study a list of words and then later they will be asked to recall or write down as many words that they can remember similar to free response questions. earlier items are affected by retroactive interference ri which means the longer the list the greater the interference and the less likelihood that they are recalled. on the other hand items that have been presented lastly suffer little ri but suffer a great deal from proactive interference pi which means the longer the delay in recall the more likely that the items will be lost.cued recall – one is given a significant hints to help retrieve information that has been previously encoded into the persons memory; typically this can involve a word relating to the information being asked to remember. this is similar to fill in the blank assessments used in classrooms.recognition – subjects are asked to remember a list of words or pictures after which point they are asked to identify the previously presented words or pictures from among a list of alternatives that were not presented in the original list. this is similar to multiple choice assessments.detection paradigm – individuals are shown a number of objects and color samples during a certain period of time. they are then tested on their visual ability to remember as much as they can by looking at testers and pointing out whether the testers are similar to the sample or if any change is present.savings method – compares the speed of originally learning to the speed of relearning it. the amount of time saved measures memory.implicit-memory tasks – information is drawn from memory without conscious realization.failurestransience – memories degrade with the passing of time. this occurs in the storage stage of memory after the information has been stored and before it is retrieved. this can happen in sensory short-term and long-term storage. it follows a general pattern where the information is rapidly forgotten during the first couple of days or years followed by small losses in later days or years.absent-mindedness – memory failure due to the lack of attention. attention plays a key role in storing information into long-term memory; without proper attention the information might not be stored making it impossible to be retrieved later.brain areas involved in the neuroanatomy of memory such as the hippocampus the amygdala the striatum or the mammillary bodies are thought to be involved in specific types of memory. for example the hippocampus is believed to be involved in spatial learning and declarative learning while the amygdala is thought to be involved in emotional memory.damage to certain areas in patients and animal models and subsequent memory deficits is a primary source of information. however rather than implicating a specific area it could be that damage to adjacent areas or to a pathway traveling through the area is actually responsible for the observed deficit. further it is not sufficient to describe memory and its counterpart learning as solely dependent on specific brain regions. learning and memory are usually attributed to changes in neuronal synapses thought to be mediated by long-term potentiation and long-term depression. however this has been questioned on computational as well as neurophysiological grounds by the cognitive scientist charles r. gallistel and others.in general the more emotionally charged an event or experience is the better it is remembered; this phenomenon is known as the memory enhancement effect. patients with amygdala damage however do not show a memory enhancement effect.hebb distinguished between short-term and long-term memory. he postulated that any memory that stayed in short-term storage for a long enough time would be consolidated into a long-term memory. later research showed this to be false. research has shown that direct injections of cortisol or epinephrine help the storage of recent experiences. this is also true for stimulation of the amygdala. this proves that excitement enhances memory by the stimulation of hormones that affect the amygdala. excessive or prolonged stress with prolonged cortisol may hurt memory storage. patients with amygdalar damage are no more likely to remember emotionally charged words than nonemotionally charged ones. the hippocampus is important for explicit memory. the hippocampus is also important for memory consolidation. the hippocampus receives input from different parts of the cortex and sends its output out to different parts of the brain also. the input comes from secondary and tertiary sensory areas that have processed the information a lot already. hippocampal damage may also cause memory loss and problems with memory storage. this memory loss includes retrograde amnesia which is the loss of memory for events that occurred shortly before the time of brain damage.cognitive neuroscientists consider memory as the retention reactivation and reconstruction of the experience-independent internal representation. the term of internal representation implies that such a definition of memory contains two components: the expression of memory at the behavioral or conscious level and the underpinning physical neural changes dudai . the latter component is also called engram or memory traces semon . some neuroscientists and psychologists mistakenly equate the concept of engram and memory broadly conceiving all persisting after-effects of experiences as memory; others argue against this notion that memory does not exist until it is revealed in behavior or thought moscovitch .one question that is crucial in cognitive neuroscience is how information and mental experiences are coded and represented in the brain. scientists have gained much knowledge about the neuronal codes from the studies of plasticity but most of such research has been focused on simple learning in simple neuronal circuits; it is considerably less clear about the neuronal changes involved in more complex examples of memory particularly declarative memory that requires the storage of facts and events byrne . convergence-divergence zones might be the neural networks where memories are stored and retrieved. considering that there are several kinds of memory depending on types of represented knowledge underlying mechanisms processes functions and modes of acquisition it is likely that different brain areas support different memory systems and that they are in mutual relationships in neuronal networks: components of memory representation are distributed widely across different parts of the brain as mediated by multiple neocortical circuits.encoding. encoding of working memory involves the spiking of individual neurons induced by sensory input which persists even after the sensory input disappears jensen and lisman ; fransen et al. . encoding of episodic memory involves persistent changes in molecular structures that alter synaptic transmission between neurons. examples of such structural changes include long-term potentiation ltp or spike-timing-dependent plasticity stdp. the persistent spiking in working memory can enhance the synaptic and cellular changes in the encoding of episodic memory jensen and lisman .working memory. recent functional imaging studies detected working memory signals in both medial temporal lobe mtl a brain area strongly associated with long-term memory and prefrontal cortex ranganath et al.  suggesting a strong relationship between working memory and long-term memory. however the substantially more working memory signals seen in the prefrontal lobe suggest that this area play a more important role in working memory than mtl suzuki .consolidation and reconsolidation. short-term memory stm is temporary and subject to disruption while long-term memory ltm once consolidated is persistent and stable. consolidation of stm into ltm at the molecular level presumably involves two processes: synaptic consolidation and system consolidation. the former involves a protein synthesis process in the medial temporal lobe mtl whereas the latter transforms the mtl-dependent memory into an mtl-independent memory over months to years ledoux . in recent years such traditional consolidation dogma has been re-evaluated as a result of the studies on reconsolidation. these studies showed that prevention after retrieval affects subsequent retrieval of the memory sara . new studies have shown that post-retrieval treatment with protein synthesis inhibitors and many other compounds can lead to an amnestic state nadel et al. b; alberini ; dudai . these findings on reconsolidation fit with the behavioral evidence that retrieved memory is not a carbon copy of the initial experiences and memories are updated during retrieval.study of the genetics of human memory is in its infancy though many genes have been investigated for their association to memory in humans and non-human animals. a notable initial success was the association of apoe with memory dysfunction in alzheimers disease. the search for genes associated with normally varying memory continues. one of the first candidates for normal variation in memory is the protein kibra which appears to be associated with the rate at which material is forgotten over a delay period. there has been some evidence that memories are stored in the nucleus of neurons.non-primary source neededseveral genes proteins and enzymes have been extensively researched for their association with memory. long-term memory unlike short-term memory is dependent upon the synthesis of new proteins. this occurs within the cellular body and concerns the particular transmitters receptors and new synapse pathways that reinforce the communicative strength between neurons. the production of new proteins devoted to synapse reinforcement is triggered after the release of certain signaling substances such as calcium within hippocampal neurons in the cell. in the case of hippocampal cells this release is dependent upon the expulsion of magnesium a binding molecule that is expelled after significant and repetitive synaptic signaling. the temporary expulsion of magnesium frees nmda receptors to release calcium in the cell a signal that leads to gene transcription and the construction of reinforcing proteins. for more information see long-term potentiation ltp.one of the newly synthesized proteins in ltp is also critical for maintaining long-term memory. this protein is an autonomously active form of the enzyme protein kinase c pkc known as pkmζ. pkmζ maintains the activity-dependent enhancement of synaptic strength and inhibiting pkmζ erases established long-term memories without affecting short-term memory or once the inhibitor is eliminated the ability to encode and store new long-term memories is restored. also bdnf is important for the persistence of long-term memories.the long-term stabilization of synaptic changes is also determined by a parallel increase of pre- and postsynaptic structures such as axonal bouton dendritic spine and postsynaptic density. on the molecular level an increase of the postsynaptic scaffolding proteins psd- and homerc has been shown to correlate with the stabilization of synaptic enlargement. the camp response element-binding protein creb is a transcription factor which is believed to be important in consolidating short-term to long-term memories and which is believed to be downregulated in alzheimers disease.rats exposed to an intense learning event may retain a life-long memory of the event even after a single training session. the long-term memory of such an event appears to be initially stored in the hippocampus but this storage is transient. much of the long-term storage of the memory seems to take place in the anterior cingulate cortex. when such an exposure was experimentally applied more than  differently methylated dna regions appeared in the hippocampus neuronal genome of the rats at one and at  hours after training. these alterations in methylation pattern occurred at many genes that were down-regulated often due to the formation of new -methylcytosine sites in cpg rich regions of the genome. furthermore many other genes were upregulated likely often due to hypomethylation. hypomethylation often results from the removal of methyl groups from previously existing -methylcytosines in dna. demethylation is carried out by several proteins acting in concert including the tet enzymes as well as enzymes of the dna base excision repair pathway see epigenetics in learning and memory. the pattern of induced and repressed genes in brain neurons subsequent to an intense learning event likely provides the molecular basis for a long-term memory of the event.main article: epigenetics in learning and memorystudies of the molecular basis for memory formation indicate that epigenetic mechanisms operating in brain neurons play a central role in determining this capability. key epigenetic mechanisms involved in memory include the methylation and demethylation of neuronal dna as well as modifications of histone proteins including methylations acetylations and deacetylations.stimulation of brain activity in memory formation is often accompanied by the generation of damage in neuronal dna that is followed by repair associated with persistent epigenetic alterations. in particular the dna repair processes of non-homologous end joining and base excision repair are employed in memory formation.citation neededfor the inability of adults to retrieve early memories see childhood amnesia.up until the mid-s it was assumed that infants could not encode retain and retrieve information. a growing body of research now indicates that infants as young as -months can recall information after a -hour delay. furthermore research has revealed that as infants grow older they can store information for longer periods of time; -month-olds can recall information after a -hour period -month-olds after up to five weeks and -month-olds after as long as twelve months. in addition studies have shown that with age infants can store information faster. whereas -month-olds can recall a three-step sequence after being exposed to it once -month-olds need approximately six exposures in order to be able to remember it.although -month-olds can recall information over the short-term they have difficulty recalling the temporal order of information. it is only by  months of age that infants can recall the actions of a two-step sequence in the correct temporal order – that is recalling step  and then step . in other words when asked to imitate a two-step action sequence such as putting a toy car in the base and pushing in the plunger to make the toy roll to the other end -month-olds tend to imitate the actions of the sequence in the correct order step  and then step . younger infants -month-olds can only recall one step of a two-step sequence. researchers have suggested that these age differences are probably due to the fact that the dentate gyrus of the hippocampus and the frontal components of the neural network are not fully developed at the age of -months.in fact the term infantile amnesia refers to the phenomenon of accelerated forgetting during infancy. importantly infantile amnesia is not unique to humans and preclinical research using rodent models provides insight into the precise neurobiology of this phenomenon. a review of the literature from behavioral neuroscientist dr jee hyun kim suggests that accelerated forgetting during early life is at least partly due to rapid growth of the brain during this period.one of the key concerns of older adults is the experience of memory loss especially as it is one of the hallmark symptoms of alzheimers disease. however memory loss is qualitatively different in normal aging from the kind of memory loss associated with a diagnosis of alzheimers budson & price . research has revealed that individuals performance on memory tasks that rely on frontal regions declines with age. older adults tend to exhibit deficits on tasks that involve knowing the temporal order in which they learned information; source memory tasks that require them to remember the specific circumstances or context in which they learned information; and prospective memory tasks that involve remembering to perform an act at a future time. older adults can manage their problems with prospective memory by using appointment books for example.gene transcription profiles were determined for the human frontal cortex of individuals from age  to  years. numerous genes were identified with reduced expression after age  and especially after age . genes that play central roles in memory and learning were among those showing the most significant reduction with age. there was also a marked increase in dna damage likely oxidative damage in the promoters of those genes with reduced expression. it was suggested that dna damage may reduce the expression of selectively vulnerable genes involved in memory and learning.much of the current knowledge of memory has come from studying memory disorders particularly amnesia. loss of memory is known as amnesia. amnesia can result from extensive damage to: a the regions of the medial temporal lobe such as the hippocampus dentate gyrus subiculum amygdala the parahippocampal entorhinal and perirhinal cortices or the b midline diencephalic region specifically the dorsomedial nucleus of the thalamus and the mammillary bodies of the hypothalamus. there are many sorts of amnesia and by studying their different forms it has become possible to observe apparent defects in individual sub-systems of the brains memory systems and thus hypothesize their function in the normally working brain. other neurological disorders such as alzheimers disease and parkinsons disease can also affect memory and cognition. hyperthymesia or hyperthymesic syndrome is a disorder that affects an individuals autobiographical memory essentially meaning that they cannot forget small details that otherwise would not be stored. korsakoffs syndrome also known as korsakoffs psychosis amnesic-confabulatory syndrome is an organic brain disease that adversely affects memory by widespread loss or shrinkage of neurons within the prefrontal cortex.while not a disorder a common temporary failure of word retrieval from memory is the tip-of-the-tongue phenomenon. sufferers of anomic aphasia also called nominal aphasia or anomia however do experience the tip-of-the-tongue phenomenon on an ongoing basis due to damage to the frontal and parietal lobes of the brain.interference can hamper memorization and retrieval. there is retroactive interference when learning new information makes it harder to recall old information and proactive interference where prior learning disrupts recall of new information. although interference can lead to forgetting it is important to keep in mind that there are situations when old information can facilitate learning of new information. knowing latin for instance can help an individual learn a related language such as french – this phenomenon is known as positive transfer.stress has a significant effect on memory formation and learning. in response to stressful situations the brain releases hormones and neurotransmitters ex. glucocorticoids and catecholamines which affect memory encoding processes in the hippocampus. behavioural research on animals shows that chronic stress produces adrenal hormones which impact the hippocampal structure in the brains of rats. an experimental study by german cognitive psychologists l. schwabe and o. wolf demonstrates how learning under stress also decreases memory recall in humans. in this study  healthy female and male university students participated in either a stress test or a control group. those randomly assigned to the stress test group had a hand immersed in ice cold water the reputable secpt or socially evaluated cold pressor test for up to three minutes while being monitored and videotaped. both the stress and control groups were then presented with  words to memorize. twenty-four hours later both groups were tested to see how many words they could remember free recall as well as how many they could recognize from a larger list of words recognition performance. the results showed a clear impairment of memory performance in the stress test group who recalled % fewer words than the control group. the researchers suggest that stress experienced during learning distracts people by diverting their attention during the memory encoding process.however memory performance can be enhanced when material is linked to the learning context even when learning occurs under stress. a separate study by cognitive psychologists schwabe and wolf shows that when retention testing is done in a context similar to or congruent with the original learning task i.e. in the same room memory impairment and the detrimental effects of stress on learning can be attenuated. seventy-two healthy female and male university students randomly assigned to the secpt stress test or to a control group were asked to remember the locations of  pairs of picture cards – a computerized version of the card game concentration or memory. the room in which the experiment took place was infused with the scent of vanilla as odour is a strong cue for memory. retention testing took place the following day either in the same room with the vanilla scent again present or in a different room without the fragrance. the memory performance of subjects who experienced stress during the object-location task decreased significantly when they were tested in an unfamiliar room without the vanilla scent an incongruent context; however the memory performance of stressed subjects showed no impairment when they were tested in the original room with the vanilla scent a congruent context. all participants in the experiment both stressed and unstressed performed faster when the learning and retrieval contexts were similar.this research on the effects of stress on memory may have practical implications for education for eyewitness testimony and for psychotherapy: students may perform better when tested in their regular classroom rather than an exam room eyewitnesses may recall details better at the scene of an event than in a courtroom and persons suffering from post-traumatic stress may improve when helped to situate their memories of a traumatic event in an appropriate context.stressful life experiences may be a cause of memory loss as a person ages. glucocorticoids that are released during stress damage neurons that are located in the hippocampal region of the brain. therefore the more stressful situations that someone encounters the more susceptible they are to memory loss later on. the ca neurons found in the hippocampus are destroyed due to glucocorticoids decreasing the release of glucose and the reuptake of glutamate. this high level of extracellular glutamate allows calcium to enter nmda receptors which in return kills neurons. stressful life experiences can also cause repression of memories where a person moves an unbearable memory to the unconscious mind. this directly relates to traumatic events in ones past such as kidnappings being prisoners of war or sexual abuse as a child.the more long term the exposure to stress is the more impact it may have. however short term exposure to stress also causes impairment in memory by interfering with the function of the hippocampus. research shows that subjects placed in a stressful situation for a short amount of time still have blood glucocorticoid levels that have increased drastically when measured after the exposure is completed. when subjects are asked to complete a learning task after short term exposure they often have difficulties. prenatal stress also hinders the ability to learn and memorize by disrupting the development of the hippocampus and can lead to unestablished long term potentiation in the offspring of severely stressed parents. although the stress is applied prenatally the offspring show increased levels of glucocorticoids when they are subjected to stress later on in life.making memories occurs through a three-step process which can be enhanced by sleep. the three steps are as follows:acquisition which is the process of storage and retrieval of new information in memorysleep affects memory consolidation. during sleep the neural connections in the brain are strengthened. this enhances the brains abilities to stabilize and retain memories. there have been several studies which show that sleep improves the retention of memory as memories are enhanced through active consolidation. system consolidation takes place during slow-wave sleep sws. this process implicates that memories are reactivated during sleep but that the process doesnt enhance every memory. it also implicates that qualitative changes are made to the memories when they are transferred to long-term store during sleep. during sleep the hippocampus replays the events of the day for the neocortex. the neocortex then reviews and processes memories which moves them into long-term memory. when one does not get enough sleep it makes it more difficult to learn as these neural connections are not as strong resulting in a lower retention rate of memories. sleep deprivation makes it harder to focus resulting in inefficient learning. furthermore some studies have shown that sleep deprivation can lead to false memories as the memories are not properly transferred to long-term memory. one of the primary functions of sleep is thought to be the improvement of the consolidation of information as several studies have demonstrated that memory depends on getting sufficient sleep between training and test. additionally data obtained from neuroimaging studies have shown activation patterns in the sleeping brain that mirror those recorded during the learning of tasks from the previous day suggesting that new memories may be solidified through such rehearsal.although people often think that memory operates like recording equipment this is not the case. the molecular mechanisms underlying the induction and maintenance of memory are very dynamic and comprise distinct phases covering a time window from seconds to even a lifetime. in fact research has revealed that our memories are constructed: current hypotheses suggest that constructive processes allow individuals to simulate and imagine future episodes happenings and scenarios. since the future is not an exact repetition of the past simulation of future episodes requires a complex system that can draw on the past in a manner that flexibly extracts and recombines elements of previous experiences – a constructive rather than a reproductive system. people can construct their memories when they encode them and/or when they recall them. to illustrate consider a classic study conducted by elizabeth loftus and john palmer  in which people were instructed to watch a film of a traffic accident and then asked about what they saw. the researchers found that the people who were asked how fast were the cars going when they smashed into each other gave higher estimates than those who were asked how fast were the cars going when they hit each other furthermore when asked a week later whether they had seen broken glass in the film those who had been asked the question with smashed were twice more likely to report that they had seen broken glass than those who had been asked the question with hit. there was no broken glass depicted in the film. thus the wording of the questions distorted viewers memories of the event. importantly the wording of the question led people to construct different memories of the event – those who were asked the question with smashed recalled a more serious car accident than they had actually seen. the findings of this experiment were replicated around the world and researchers consistently demonstrated that when people were provided with misleading information they tended to misremember a phenomenon known as the misinformation effect.research has revealed that asking individuals to repeatedly imagine actions that they have never performed or events that they have never experienced could result in false memories. for instance goff and roediger  asked participants to imagine that they performed an act e.g. break a toothpick and then later asked them whether they had done such a thing. findings revealed that those participants who repeatedly imagined performing such an act were more likely to think that they had actually performed that act during the first session of the experiment. similarly garry and her colleagues  asked college students to report how certain they were that they experienced a number of events as children e.g. broke a window with their hand and then two weeks later asked them to imagine four of those events. the researchers found that one-fourth of the students asked to imagine the four events reported that they had actually experienced such events as children. that is when asked to imagine the events they were more confident that they experienced the events.research reported in  revealed that it is possible to artificially stimulate prior memories and artificially implant false memories in mice. using optogenetics a team of riken-mit scientists caused the mice to incorrectly associate a benign environment with a prior unpleasant experience from different surroundings. some scientists believe that the study may have implications in studying false memory formation in humans and in treating ptsd and schizophrenia.memory reconsolidation is when previously consolidated memories are recalled or retrieved from long-term memory to your active consciousness. during this process memories can be further strengthened and added to but there is also risk of manipulation involved. we like to think of our memories as something stable and constant when they are stored in long-term memory but this isnt the case. there are a large number of studies that found that consolidation of memories is not a singular event but are put through the process again known as reconsolidation. this is when a memory is recalled or retrieved and placed back into your working memory. the memory is now open to manipulation from outside sources and the misinformation effect which could be due to misattributing the source of the inconsistent information with or without an intact original memory trace lindsay and johnson . one thing that can be sure is that memory is malleable.this new research into the concept of reconsolidation has opened the door to methods to help those with unpleasant memories or those that struggle with memories. an example of this is if you had a truly frightening experience and recall that memory in a less arousing environment the memory will be weaken the next time it is retrieved. some studies suggest that over-trained or strongly reinforced memories do not undergo reconsolidation if reactivated the first few days after training but do become sensitive to reconsolidation interference with time. this however does not mean that all memory is susceptible to reconsolidation. there is evidence to suggest that memory that has undergone strong training and whether or not is it intentional is less likely to undergo reconsolidation. there was further testing done with rats and mazes that showed that reactivated memories were more susceptible to manipulation in both good and bad ways than newly formed memories. it is still not known whether or not these are new memories formed and its an inability to retrieve the proper one for the situation or if its a reconsolidated memory. because the study of reconsolidation is still a newer concept there is still debate on whether it should be considered scientifically sound.a ucla research study published in the june  issue of the american journal of geriatric psychiatry found that people can improve cognitive function and brain efficiency through simple lifestyle changes such as incorporating memory exercises healthy eating physical fitness and stress reduction into their daily lives. this study examined  subjects average age  with normal memory performance. eight subjects were asked to follow a brain healthy diet relaxation physical and mental exercise brain teasers and verbal memory training techniques. after  days they showed greater word fluency not memory compared to their baseline performance. no long-term follow-up was conducted; it is therefore unclear if this intervention has lasting effects on memory.there are a loosely associated group of mnemonic principles and techniques that can be used to vastly improve memory known as the art of memory.the international longevity center released in  a report which includes in pages – recommendations for keeping the mind in good functionality until advanced age. some of the recommendations are to stay intellectually active through learning training or reading to keep physically active so to promote blood circulation to the brain to socialize to reduce stress to keep sleep time regular to avoid depression or emotional instability and to observe good nutrition.memorization is a method of learning that allows an individual to recall information verbatim. rote learning is the method most often used. methods of memorizing things have been the subject of much discussion over the years with some writers such as cosmos rossellius using visual alphabets. the spacing effect shows that an individual is more likely to remember a list of items when rehearsal is spaced over an extended period of time. in contrast to this is cramming: an intensive memorization in a short period of time. the spacing effect is exploited to improve memory in spaced repetition flashcard training. also relevant is the zeigarnik effect which states that people remember uncompleted or interrupted tasks better than completed ones. the so-called method of loci uses spatial memory to memorize non-spatial information.plants lack a specialized organ devoted to memory retention and so plant memory has been a controversial topic in recent years. new advances in the field have identified the presence of neurotransmitters in plants adding to the hypothesis that plants are capable of remembering. action potentials a physiological response characteristic of neurons have been shown to have an influence on plants as well including in wound responses and photosynthesis. in addition to these homologous features of memory systems in both plants and animals plants have also been observed to encode store and retrieve basic short-term memories.one of the most well-studied plants to show rudimentary memory is the venus flytrap. native to the subtropical wetlands of the eastern united states venus fly traps have evolved the ability to obtain meat for sustenance likely due to the lack of nitrogen in the soil. this is done by two trap-forming leaf tips that snap shut once triggered by a potential prey. on each lobe three triggers hairs await stimulation. in order to maximize the benefit to cost ratio the plant enables a rudimentary form of memory in which two trigger hairs must be stimulated within  seconds in order to result in trap closure. this system ensures that the trap only closes when potential prey is within grasp.the time lapse between trigger hair stimulations suggests that the plant can remember an initial stimulus long enough for a second stimulus to initiate trap closure. this memory isnt encoded in a brain as plants lack this specialized organ. rather information is stored in the form of cytoplasmic calcium levels. the first trigger causes a subthreshold cytoplasmic calcium influx. this initial trigger isnt enough to activate trap closure and so a subsequent stimulus allows for a secondary influx of calcium. the latter calcium rise superimposes on the initial one creating an action potential that passes threshold resulting in trap closure. researchers to prove that an electrical threshold must be met to stimulate trap closure excited a single trigger hair with a constant mechanical stimulus using ag/agcl electrodes. the trap closed after only a few seconds. this experiment gave evidence to demonstrate that the electrical threshold not necessarily the number of trigger hair stimulations was the contributing factor in venus fly trap memory. it has been shown that trap closure can be blocked using uncouplers and inhibitors of voltage-gated channels. after trap closure these electrical signals stimulate glandular production of jasmonic acid and hydrolases allowing for digestion of the prey.the field of plant neurobiology has gained a large amount of interest over the past decade leading to an influx of research regarding plant memory. although the venus flytrap is one of the more highly studied many other plants exhibit the capacity to remember including the mimosa pudica through an experiment conducted by monica gagliano and colleagues in . to study the mimosa pudica gagliano designed an appartus with which potted mimosa plants could be repeatedly dropped the same distance and at the same speed. it was observed that the plants defensive response of curling up its leaves decreased over the  times the experiment was repeated per plant. to confirm that this was a mechanism of memory rather than exhaustion some of the plants were shaken post experiment and displayed normal defensive responses of leaf curling. this experiment also demonstrated long term memory in the plants as it was repeated a month later and the plants were observed to remain unfazed by the dropping. as the field expands it is likely that we will learn more about the capacity of a plant to remember.metaphysics is the branch of philosophy that examines the fundamental nature of reality including the relationship between mind and matter between substance and attribute and between potentiality and actuality. the word metaphysics comes from two greek words that together literally mean after or behind or among the study of the natural. it has been suggested that the term might have been coined by a first century ad editor who assembled various small selections of aristotle’s works into the treatise we now know by the name metaphysics ta meta ta phusika after the physics  another of aristotles works.metaphysics studies questions related to what it is for something to exist and what types of existence there are. metaphysics seeks to answer in an abstract and fully general manner the questions:what is therewhat is it liketopics of metaphysical investigation include existence objects and their properties space and time cause and effect and possibility.metaphysical study is conducted using deduction from that which is known a priori. like foundational mathematics which is sometimes considered a special case of metaphysics applied to the existence of number it tries to give a coherent account of the structure of the world capable of explaining our everyday and scientific perception of the world and being free from contradictions. in mathematics there are many different ways to define numbers; similarly in metaphysics there are many different ways to define objects properties concepts and other entities which are claimed to make up the world. while metaphysics may as a special case study the entities postulated by fundamental science such as atoms and superstrings its core topic is the set of categories such as object property and causality which those scientific theories assume. for example: claiming that electrons have charge is a scientific theory; while exploring what it means for electrons to be or at least to be perceived as objects charge to be a property and for both to exist in a topological entity called space is the task of metaphysics.there are two broad stances about what is the world studied by metaphysics. the strong classical view assumes that the objects studied by metaphysics exist independently of any observer so that the subject is the most fundamental of all sciences. the weak modern view assumes that the objects studied by metaphysics exist inside the mind of an observer so the subject becomes a form of introspection and conceptual analysis. some philosophers notably kant discuss both of these worlds and what can be inferred about each one. some such as the logical positivists and many scientists reject the strong view of metaphysics as meaningless and unverifiable. others reply that this criticism also applies to any type of knowledge including hard science which claims to describe anything other than the contents of human perception and thus that the world of perception is the objective world in some sense. metaphysics itself usually assumes that some stance has been taken on these questions and that it may proceed independently of the choice—the question of which stance to take belongs instead to another branch of philosophy epistemology.ontology is the philosophical study of the nature of being becoming existence or reality as well as the basic categories of being and their relations.failed verification traditionally listedby whom as the core of metaphysics ontology often deals with questions concerning what entities exist and how such entities may be grouped related within a hierarchy and subdivided according to similarities and differences.see also: identity philosophy and philosophy of space and timeidentity is a fundamental metaphysical concern. metaphysicians investigating identity are tasked with the question of what exactly it means for something to be identical to itself or – more controversially – to something else. issues of identity arise in the context of time: what does it mean for something to be itself across two moments in time how do we account for this another question of identity arises when we ask what our criteria ought to be for determining identity and how the reality of identity interfaces with linguistic expressions.the metaphysical positions one takes on identity have far-reaching implications on issues such as the mind–body problem personal identity ethics and law.a few ancient greeks took extreme positions on the nature of change. parmenides denied change altogether while heraclitus argued that change was ubiquitous: no man ever steps in the same river twice.identity sometimes called numerical identity is the relation that a thing bears to itself and which no thing bears to anything other than itself cf. sameness.a modern philosopher who made a lasting impact on the philosophy of identity was leibniz whose law of the indiscernibility of identicals is still widely accepted today. it states that if some object x is identical to some object y then any property that x has y will have as well.put formally it states{\displaystyle \forall x\;\forall y\;x=y\rightarrow \forall p\;px\leftrightarrow py}{\displaystyle \forall x\;\forall y\;x=y\rightarrow \forall p\;px\leftrightarrow py}however it does seem that objects can change over time. if one were to look at a tree one day and the tree later lost a leaf it would seem that one could still be looking at that same tree. two rival theories to account for the relationship between change and identity are perdurantism which treats the tree as a series of tree-stages and endurantism which maintains that the organism—the same tree—is present at every stage in its history.by appealing to intrinsic and extrinsic properties endurantism finds a way to harmonize identity with change. endurantists believe that objects persist by being strictly numerically identical over time. however if leibnizs law of the indiscernibility of identicals is utilized to define numerical identity here it seems that objects must be completely unchanged in order to persist. discriminating between intrinsic properties and extrinsic properties endurantists state that numerical identity means that if some object x is identical to some object y then any intrinsic property that x has y will have as well. thus if an object persists intrinsic properties of it are unchanged but extrinsic properties can change over time. besides the object itself environments and other objects can change over time; properties that relate to other objects would change even if this object does not change.perdurantism can harmonize identity with change in another way. in four-dimensionalism a version of perdurantism what persists is a four-dimensional object which does not change although three-dimensional slices of the object may differ.see also: philosophy of space and timeobjects appear to us in space and time while abstract entities such as classes properties and relations do not. how do space and time serve this function as a ground for objects are space and time entities themselves of some form must they exist prior to objects how exactly can they be defined how is time related to change; must there always be something changing in order for time to existclassical philosophy recognized a number of causes including teleological future causes. in special relativity and quantum field theory the notions of space time and causality become tangled together with temporal orders of causations becoming dependent on who is observing them.citation needed the laws of physics are symmetrical in time so could equally well be used to describe time as running backwards. why then do we perceive it as flowing in one direction the arrow of time and as containing causation flowing in the same directionfor that matter can an effect precede its cause this was the title of a  paper by michael dummett which sparked a discussion that continues today. earlier in  c. s. lewis had argued that one can meaningfully pray concerning the outcome of e.g. a medical test while recognizing that the outcome is determined by past events: my free act contributes to the cosmic shape. likewise some interpretations of quantum mechanics dating to  involve backward-in-time causal influences.causality is linked by many philosophers to the concept of counterfactuals. to say that a caused b means that if a had not happened then b would not have happened. this view was advanced by david lewis in his  paper causation. his subsequent papers further develop his theory of causation.causality is usually required as a foundation for philosophy of science if science aims to understand causes and effects and make predictions about them.metaphysicians investigate questions about the ways the world could have been. david lewis in on the plurality of worlds endorsed a view called concrete modal realism according to which facts about how things could have been are made true by other concrete worlds in which things are different. other philosophers including gottfried leibniz have dealt with the idea of possible worlds as well. a necessary fact is true across all possible worlds. a possible fact is true in some possible world even if not in the actual world. for example it is possible that cats could have had two tails or that any particular apple could have not existed. by contrast certain propositions seem necessarily true such as analytic propositions e.g. all bachelors are unmarried. the view that any analytic truth is necessary is not universally held among philosophers. a less controversial view is that self-identity is necessary as it seems fundamentally incoherent to claim that any x is not identical to itself; this is known as the law of identity a putative first principle. similarly aristotle describes the principle of non-contradiction:it is impossible that the same quality should both belong and not belong to the same thing ... this is the most certain of all principles ... wherefore they who demonstrate refer to this as an ultimate opinion. for it is by nature the source of all the other axioms.peripheral questionswhat is central and peripheral to metaphysics has varied over time and schools; however contemporary analytic philosophy as taught in usa and uk universities generally regards the above as central and the following as applications or peripheral topics; or in some cases as distinct subjects which have grown out of and depend upon metaphysics:citation neededmetaphysical cosmology is the branch of metaphysics that deals with the world as the totality of all phenomena in space and time. historically it formed a major part of the subject alongside ontology though its role is more peripheral in contemporary philosophy. it has had a broad scope and in many cases was founded in religion. the ancient greeks drew no distinction between this use and their model for the cosmos. however in modern times it addresses questions about the universe which are beyond the scope of the physical sciences. it is distinguished from religious cosmology in that it approaches these questions using philosophical methods e.g. dialectics.cosmogony deals specifically with the origin of the universe. modern metaphysical cosmology and cosmogony try to address questions such as:what is the origin of the universe what is its first cause is its existence necessary see monism pantheism emanationism and creationismwhat are the ultimate material components of the universe see mechanism dynamism hylomorphism atomismwhat is the ultimate reason for the existence of the universe does the cosmos have a purpose see teleologydifferent approaches toward resolving the mind–body problemaccounting for the existence of mind in a world largely composed of matter is a metaphysical problem which is so large and important as to have become a specialized subject of study in its own right philosophy of mind.substance dualism is a classical theory in which mind and body are essentially different with the mind having some of the attributes traditionally assigned to the soul and which creates an immediate conceptual puzzle about how the two interact. this form of substance dualism differs from the dualism of some eastern philosophical traditions like nyāya which also posit a soul; for the soul under their view is ontologically distinct from the mind. idealism postulates that material objects do not exist unless perceived and only as perceptions. adherents of panpsychism a kind of property dualism hold that everything has a mental aspect but not that everything exists in a mind. neutral monism postulates that existence consists of a single substance that in itself is neither mental nor physical but is capable of mental and physical aspects or attributes – thus it implies a dual-aspect theory. for the last century the dominant theories have been science-inspired including materialistic monism type identity theory token identity theory functionalism reductive physicalism nonreductive physicalism eliminative materialism anomalous monism property dualism epiphenomenalism and emergence.determinism is the philosophical proposition that every event including human cognition decision and action is causally determined by an unbroken chain of prior occurrences. it holds that nothing happens that has not already been determined. the principal consequence of the deterministic claim is that it poses a challenge to the existence of free will.the problem of free will is the problem of whether rational agents exercise control over their own actions and decisions. addressing this problem requires understanding the relation between freedom and causation and determining whether the laws of nature are causally deterministic. some philosophers known as incompatibilists view determinism and free will as mutually exclusive. if they believe in determinism they will therefore believe free will to be an illusion a position known as hard determinism. proponents range from baruch spinoza to ted honderich. henri bergson defended free will in his dissertation time and free will from .others labeled compatibilists or soft determinists believe that the two ideas can be reconciled coherently. adherents of this view include thomas hobbes and many modern philosophers such as john martin fischer gary watson harry frankfurt and the like.incompatibilists who accept free will but reject determinism are called libertarians a term not to be confused with the political sense. robert kane and alvin plantinga are modern defenders of this theory.the earliest type of classification of social construction traces back to plato in his dialogue phaedrus where he claims that the biological classification system seems to carve nature at the joints. in contrast later philosophers such as michel foucault and jorge luis borges have challenged the capacity of natural and social classification. in his essay the analytical language of john wilkins borges makes us imagine a certain encyclopedia where the animals are divided into a those that belong to the emperor; b embalmed ones; c those that are trained;... and so forth in order to bring forward the ambiguity of natural and social kinds. according to metaphysics author alyssa ney: the reason all this is interesting is that there seems to be a metaphysical difference between the borgesian system and platos. the difference is not obvious but one classification attempts to carve entities up according to objective distinction while the other does not. according to quine this notion is closely related to the notion of similarity.there are different ways to set up the notion of number in metaphysics theories. platonist theories postulate number as a fundamental category itself. others consider it to be a property of an entity called a group comprising other entities; or to be a relation held between several groups of entities such as the number four is the set of all sets of four things. many of the debates around universals are applied to the study of number and are of particular importance due to its status as a foundation for the philosophy of mathematics and for mathematics itself.although metaphysics as a philosophical enterprise is highly hypothetical it also has practical application in most other branches of philosophy science and now also information technology. such areas generally assume some basic ontology such as a system of objects properties classes and space time as well as other metaphysical stances on topics such as causality and agency then build their own particular theories upon these.in science for example some theories are based on the ontological assumption of objects with properties such as electrons having charge while others may reject objects completely such as quantum field theories where spread-out electronness becomes a property of space time rather than an object.social branches of philosophy such as philosophy of morality aesthetics and philosophy of religion which in turn give rise to practical subjects such as ethics politics law and art all require metaphysical foundations which may be considered as branches or applications of metaphysics. for example they may postulate the existence of basic entities such as value beauty and god. then they use these postulates to make their own arguments about consequences resulting from them. when philosophers in these subjects make their foundations they are doing applied metaphysics and may draw upon its core topics and methods to guide them including ontology and other core and peripheral topics. as in science the foundations chosen will in turn depend on the underlying ontology used so philosophers in these subjects may have to dig right down to the ontological layer of metaphysics to find what is possible for their theories. for example a contradiction obtained in a theory of god or beauty might be due to an assumption that it is an object rather than some other kind of ontological entity.prior to the modern history of science scientific questions were addressed as a part of natural philosophy. originally the term science latin: scientia simply meant knowledge. the scientific method however transformed natural philosophy into an empirical activity deriving from experiment unlike the rest of philosophy. by the end of the th century it had begun to be called science to distinguish it from other branches of philosophy. science and philosophy have been considered separated disciplines ever since. thereafter metaphysics denoted philosophical enquiry of a non-empirical character into the nature of existence.metaphysics continues asking why where science leaves off. for example any theory of fundamental physics is based on some set of axioms which may postulate the existence of entities such as atoms particles forces charges mass or fields. stating such postulates is considered to be the end of a science theory. metaphysics takes these postulates and explores what they mean as human concepts. for example do all theories of physics require the existence of space and time objects and properties or can they be expressed using only objects or only properties do the objects have to retain their identity over time or can they change if they change then are they still the same object can theories be reformulated by converting properties or predicates such as red into entities such as redness or redness fields or processes there is some redding happening over there appears in some human languages in place of the use of properties. is the distinction between objects and properties fundamental to the physical world or to our perception of itmuch recent work has been devoted to analyzing the role of metaphysics in scientific theorizing. alexandre koyré led this movement declaring in his book metaphysics and measurement it is not by following experiment but by outstripping experiment that the scientific mind makes progress. that metaphysical propositions can influence scientific theorizing is john watkins most lasting contribution to philosophy. since  he showed the ways in which some un-testable and hence according to popperian ideas non-empirical propositions can nevertheless be influential in the development of properly testable and hence scientific theories. these profound results in applied elementary logic...represented an important corrective to positivist teachings about the meaninglessness of metaphysics and of normative claims. imre lakatos maintained that all scientific theories have a metaphysical hard core essential for the generation of hypotheses and theoretical assumptions. thus according to lakatos scientific changes are connected with vast cataclysmic metaphysical revolutions.an example from biology of lakatos thesis: david hull has argued that changes in the ontological status of the species concept have been central in the development of biological thought from aristotle through cuvier lamarck and darwin. darwins ignorance of metaphysics made it more difficult for him to respond to his critics because he could not readily grasp the ways in which their underlying metaphysical views differed from his own.in physics new metaphysical ideas have arisen in connection with quantum mechanics where subatomic particles arguably do not have the same sort of individuality as the particulars with which philosophy has traditionally been concerned. also adherence to a deterministic metaphysics in the face of the challenge posed by the quantum-mechanical uncertainty principle led physicists such as albert einstein to propose alternative theories that retained determinism. a.n. whitehead is famous for creating a process philosophy metaphysics inspired by electromagnetism and special relativity.in chemistry gilbert newton lewis addressed the nature of motion arguing that an electron should not be said to move when it has none of the properties of motion.katherine hawley notes that the metaphysics even of a widely accepted scientific theory may be challenged if it can be argued that the metaphysical presuppositions of the theory make no contribution to its predictive success.metametaphysics is the branch of philosophy that is concerned with the foundations of metaphysics. a number of individuals have suggested that much or all of metaphysics should be rejected a metametaphysical position known as metaphysical deflationisma or ontological deflationism.in the th century francis bacon rejected scholastic metaphysics and argued strongly for what is now called empiricism being seen later as the father of modern empirical science. in the th century david hume took a strong position arguing that all genuine knowledge involves either mathematics or matters of fact and that metaphysics which goes beyond these is worthless. he concludes his enquiry concerning human understanding with the statement:if we take in our hand any volume; of divinity or school metaphysics for instance; let us ask does it contain any abstract reasoning concerning quantity or number no. does it contain any experimental reasoning concerning matter of fact and existence no. commit it then to the flames: for it can contain nothing but sophistry and illusion.thirty-three years after humes enquiry appeared immanuel kant published his critique of pure reason. although he followed hume in rejecting much of previous metaphysics he argued that there was still room for some synthetic a priori knowledge concerned with matters of fact yet obtainable independent of experience. these included fundamental structures of space time and causality. he also argued for the freedom of the will and the existence of things in themselves the ultimate but unknowable objects of experience.wittgenstein introduced the concept that metaphysics could be influenced by theories of aesthetics via logic vis. a world composed of atomical facts.in the s a.j. ayer and rudolf carnap endorsed humes position; carnap quoted the passage above. they argued that metaphysical statements are neither true nor false but meaningless since according to their verifiability theory of meaning a statement is meaningful only if there can be empirical evidence for or against it. thus while ayer rejected the monism of spinoza he avoided a commitment to pluralism the contrary position by holding both views to be without meaning. carnap took a similar line with the controversy over the reality of the external world. while the logical positivism movement is now considered dead with ayer a major proponent admitting in a  tv interview that nearly all of it was false it has continued to influence philosophy development.arguing against such rejections the scholastic philosopher edward feser held that humes critique of metaphysics and specifically humes fork is notoriously self-refuting. feser argues that humes fork itself is not a conceptual truth and is not empirically testable.some living philosophers such as amie thomasson have argued that many metaphysical questions can be dissolved just by looking at the way we use words; others such as ted sider have argued that metaphysical questions are substantive and that we can make progress toward answering them by comparing theories according to a range of theoretical virtues inspired by the sciences such as simplicity and explanatory power.etymologythe word metaphysics derives from the greek words μετά metá after and φυσικά physiká physics. it was first used as the title for several of aristotles works because they were usually anthologized after the works on physics in complete editions. the prefix meta- after indicates that these works come after the chapters on physics. however aristotle himself did not call the subject of these books metaphysics: he referred to it as first philosophy greek: πρώτη φιλοσοφία; latin: philosophia prima. the editor of aristotles works andronicus of rhodes is thought to have placed the books on first philosophy right after another work physics and called them τὰ μετὰ τὰ φυσικὰ βιβλία tà metà tà physikà biblía or the books that come after the books on physics.however once the name was given the commentators sought to find other reasons for its appropriateness. for instance thomas aquinas understood it to refer to the chronological or pedagogical order among our philosophical studies so that the metaphysical sciences would mean those that we study after having mastered the sciences that deal with the physical world.the term was misread by other medieval commentators who thought it meant the science of what is beyond the physical. following this tradition the prefix meta- has more recently been prefixed to the names of sciences to designate higher sciences dealing with ulterior and more fundamental problems: hence metamathematics metaphysiology etc.a person who creates or develops metaphysical theories is called a metaphysician.common parlance also uses the word metaphysics for a different referent from that of the present article namely for beliefs in arbitrary non-physical or magical entities. for example metaphysical healing to refer to healing by means of remedies that are magical rather than scientific. this usage stemmed from the various historical schools of speculative metaphysics which operated by postulating all manner of physical mental and spiritual entities as bases for particular metaphysical systems. metaphysics as a subject does not preclude beliefs in such magical entities but neither does it promote them. rather it is the subject which provides the vocabulary and logic with which such beliefs might be analyzed and studied for example to search for inconsistencies both within themselves and with other accepted systems such as science.cognitive archeology such as analysis of cave paintings and other pre-historic art and customs suggests that a form of perennial philosophy or shamanic metaphysics may stretch back to the birth of behavioral modernity all around the world. similar beliefs are found in present-day stone age cultures such as australian aboriginals. perennial philosophy postulates the existence of a spirit or concept world alongside the day-to-day world and interactions between these worlds during dreaming and ritual or on special days or at special places. it has been argued that perennial philosophy formed the basis for platonism with plato articulating rather than creating much older widespread beliefs.bronze age cultures such as ancient mesopotamia and ancient egypt along with similarly structured but chronologically later cultures such as mayans and aztecs developed belief systems based on mythology anthropomorphic gods mind–body dualism and a spirit world to explain causes and cosmology. these cultures appear to have been interested in astronomy and may have associated or identified the stars with some of these entities. in ancient egypt the ontological distinction between order maat and chaos isfet seems to have been important.the circled dot was used by the pythagoreans and later greeks to represent the first metaphysical being the monad or the absolute.the first named greek philosopher according to aristotle is thales of miletus early th century bce. he made use of purely physical explanations to explain the phenomena of the world rather than the mythological and divine explanations of tradition. he is thought to have posited water as the single underlying principle or arche in later aristotelian terminology of the material world. his fellow but younger miletians anaximander and anaximenes also posited monistic underlying principles namely apeiron the indefinite or boundless and air respectively.another school was the eleatics in southern italy. the group was founded in the early fifth century bce by parmenides and included zeno of elea and melissus of samos. methodologically the eleatics were broadly rationalist and took logical standards of clarity and necessity to be the criteria of truth. parmenides chief doctrine was that reality is a single unchanging and universal being. zeno used reductio ad absurdum to demonstrate the illusory nature of change and time in his paradoxes.heraclitus of ephesus in contrast made change central teaching that all things flow. his philosophy expressed in brief aphorisms is quite cryptic. for instance he also taught the unity of opposites.democritus and his teacher leucippus are known for formulating an atomic theory for the cosmos. they are considered forerunners of the scientific method.the modern yin and yang symbol taijitumetaphysics in chinese philosophy can be traced back to the earliest chinese philosophical concepts from the zhou dynasty such as tian heaven and yin and yang. the fourth century bce saw a turn towards cosmogony with the rise of taoism in the daodejing and zhuangzi and sees the natural world as dynamic and constantly changing processes which spontaneously arise from a single immanent metaphysical source or principle tao. another philosophical school which arose around this time was the school of naturalists which saw the ultimate metaphysical principle as the taiji the supreme polarity composed of the forces of yin and yang which were always in a state of change seeking balance. another concern of chinese metaphysics especially taoism is the relationship and nature of being and non-being you 有 and wu 無. the taoists held that the ultimate the tao was also non-being or no-presence. other important concepts were those of spontaneous generation or natural vitality ziran and correlative resonance ganying.after the fall of the han dynasty  ce china saw the rise of the neo-taoist xuanxue school. this school was very influential in developing the concepts of later chinese metaphysics. buddhist philosophy entered china c. st century and was influenced by the native chinese metaphysical concepts to develop new theories. the native tiantai and huayen schools of philosophy maintained and reinterpreted the indian theories of shunyata emptiness kong 空 and buddha-nature fo xing 佛性 into the theory of interpenetration of phenomena. neo-confucians like zhang zai under the influence of other schools developed the concepts of principle li and vital energy qi.socrates is known for his dialectic or questioning approach to philosophy rather than a positive metaphysical doctrine.his pupil plato is famous for his theory of forms which he places in the mouth of socrates in his dialogues. platonic realism also considered a form of idealism is considered to be a solution to the problem of universals; i.e. what particular objects have in common is that they share a specific form which is universal to all others of their respective kind.the theory has a number of other aspects:epistemological: knowledge of the forms is more certain than mere sensory data.ethical: the form of the good sets an objective standard for morality.time and change: the world of the forms is eternal and unchanging. time and change belong only to the lower sensory world. time is a moving image of eternity.abstract objects and mathematics: numbers geometrical figures etc. exist mind-independently in the world of forms.platonism developed into neoplatonism a philosophy with a monotheistic and mystical flavour that survived well into the early christian era.platos pupil aristotle wrote widely on almost every subject including metaphysics. his solution to the problem of universals contrasts with platos. whereas platonic forms are existentially apparent in the visible world aristotelian essences dwell in particulars.potentiality and actuality are principles of a dichotomy which aristotle used throughout his philosophical works to analyze motion causality and other issues.the aristotelian theory of change and causality stretches to four causes: the material formal efficient and final. the efficient cause corresponds to what is now known as a cause simplicity. final causes are explicitly teleological a concept now regarded as controversial in science. the matter/form dichotomy was to become highly influential in later philosophy as the substance/essence distinction.the opening arguments in aristotles metaphysics book i revolve around the senses knowledge experience theory and wisdom. the first main focus in the metaphysics is attempting to determine how intellect advances from sensation through memory experience and art to theoretical knowledge. aristotle claims that eyesight provides us with the capability to recognize and remember experiences while sound allows us to learn.sāṃkhya is an ancient system of indian philosophy based on a dualism involving the ultimate principles of consciousness and matter. it is described as the rationalist school of indian philosophy. it is most related to the yoga school of hinduism and its method was most influential on the development of early buddhism.the sāmkhya is an enumerationist philosophy whose epistemology accepts three of six pramanas proofs as the only reliable means of gaining knowledge. these include pratyakṣa perception anumāṇa inference and śabda āptavacana word/testimony of reliable sources.samkhya is strongly dualist. sāmkhya philosophy regards the universe as consisting of two realities; puruṣa consciousness and prakṛti matter. jiva a living being is that state in which puruṣa is bonded to prakṛti in some form. this fusion state the samkhya scholars led to the emergence of buddhi spiritual awareness and ahaṅkāra ego consciousness. the universe is described by this school as one created by purusa-prakṛti entities infused with various permutations and combinations of variously enumerated elements senses feelings activity and mind. during the state of imbalance one of more constituents overwhelm the others creating a form of bondage particularly of the mind. the end of this imbalance bondage is called liberation or moksha by the samkhya school.the existence of god or supreme being is not directly asserted nor considered relevant by the samkhya philosophers. sāṃkhya denies the final cause of ishvara god. while the samkhya school considers the vedas as a reliable source of knowledge it is an atheistic philosophy according to paul deussen and other scholars. a key difference between samkhya and yoga schools state scholars is that yoga school accepts a personal yet essentially inactive deity or personal god.samkhya is known for its theory of guṇas qualities innate tendencies. guṇa it states are of three types: sattva being good compassionate illuminating positive and constructive; rajas is one of activity chaotic passion impulsive potentially good or bad; and tamas being the quality of darkness ignorance destructive lethargic negative. everything all life forms and human beings state samkhya scholars have these three guṇas but in different proportions. the interplay of these guṇas defines the character of someone or something of nature and determines the progress of life. the samkhya theory of guṇas was widely discussed developed and refined by various schools of indian philosophies including buddhism. samkhyas philosophical treatises also influenced the development of various theories of hindu ethics.realization of the nature of self-identity is the principal object of the vedanta system of indian metaphysics. in the upanishads self-consciousness is not the first-person indexical self-awareness or the self-awareness which is self-reference without identification and also not the self-consciousness which as a kind of desire is satisfied by another self-consciousness. it is self-realisation; the realisation of the self consisting of consciousness that leads all else.the word self-consciousness in the upanishads means the knowledge about the existence and nature of brahman. it means the consciousness of our own real being the primary reality. self-consciousness means self-knowledge the knowledge of prajna i.e. of prana which is brahman. according to the upanishads the atman or paramatman is phenomenally unknowable; it is the object of realisation. the atman is unknowable in its essential nature; it is unknowable in its essential nature because it is the eternal subject who knows about everything including itself. the atman is the knower and also the known.metaphysicians regard the self either to be distinct from the absolute or entirely identical with the absolute. they have given form to three schools of thought – a the dualistic school b the quasi-dualistic school and c the monistic school as the result of their varying mystical experiences. prakrti and atman when treated as two separate and distinct aspects form the basis of the dualism of the shvetashvatara upanishad. quasi-dualism is reflected in the vaishnavite-monotheism of ramanuja and the absolute monism in the teachings of adi shankara.self-consciousness is the fourth state of consciousness or turiya the first three being vaisvanara taijasa and prajna. these are the four states of individual consciousness.there are three distinct stages leading to self-realisation. the first stage is in mystically apprehending the glory of the self within us as though we were distinct from it. the second stage is in identifying the i-within with the self that we are in essential nature entirely identical with the pure self. the third stage is in realising that the atman is brahman that there is no difference between the self and the absolute. the fourth stage is in realising i am the absolute – aham brahman asmi. the fifth stage is in realising that brahman is the all that exists as also that which does not exist.in buddhist philosophy there are various metaphysical traditions that have proposed different questions about the nature of reality based on the teachings of the buddha in the early buddhist texts. the buddha of the early texts does not focus on metaphysical questions but on ethical and spiritual training and in some cases he dismisses certain metaphysical questions as unhelpful and indeterminate avyakta which he recommends should be set aside. the development of systematic metaphysics arose after the buddhas death with the rise of the abhidharma traditions. the buddhist abhidharma schools developed their analysis of reality based on the concept of dharmas which are the ultimate physical and mental events that make up experience and their relations to each other. noa ronkin has called their approach phenomenological.later philosophical traditions include the madhyamika school of nagarjuna which further developed the theory of the emptiness shunyata of all phenomena or dharmas which rejects any kind of substance. this has been interpreted as a form of anti-foundationalism and anti-realism which sees reality as having no ultimate essence or ground. the yogacara school meanwhile promoted a theory called awareness only vijnapti-matra which has been interpreted as a form of idealism or phenomenology and denies the split between awareness itself and the objects of awareness.major ideas in sufi metaphysics have surrounded the concept of weḥdah وحدة meaning unity or in arabic توحيد tawhid. waḥdat al-wujūd literally means the unity of existence or unity of being. the phrase has been translated pantheism. wujud i.e. existence or presence here refers to allahs wujud compare tawhid. on the other hand waḥdat ash-shuhūd meaning apparentism or monotheism of witness holds that god and his creation are entirely separate.between about  and  philosophy as a discipline took place as part of the catholic churchs teaching system known as scholasticism. scholastic philosophy took place within an established framework blending christian theology with aristotelian teachings. although fundamental orthodoxies were not commonly challenged there were nonetheless deep metaphysical disagreements particularly over the problem of universals which engaged duns scotus and pierre abelard. william of ockham is remembered for his principle of ontological parsimony.in the early modern period th and th centuries the system-building scope of philosophy is often linked to the rationalist method of philosophy that is the technique of deducing the nature of the world by pure reason. the scholastic concepts of substance and accident were employed.leibniz proposed in his monadology a plurality of non-interacting substances.descartes is famous for his dualism of material and mental substances.spinoza believed reality was a single substance of god-or-nature.wolffchristian wolff had theoretical philosophy divided into an ontology or philosophia prima as a general metaphysics which arises as a preliminary to the distinction of the three special metaphysics on the soul world and god: rational psychology rational cosmology and rational theology. the three disciplines are called empirical and rational because they are independent of revelation. this scheme which is the counterpart of religious tripartition in creature creation and creator is best known to philosophical students by kants treatment of it in the critique of pure reason. in the preface of the nd edition of kants book wolff is defined the greatest of all dogmatic philosophers.british empiricism marked something of a reaction to rationalist and system-building metaphysics or speculative metaphysics as it was pejoratively termed. the skeptic david hume famously declared that most metaphysics should be consigned to the flames see below. hume was notorious among his contemporaries as one of the first philosophers to openly doubt religion but is better known now for his critique of causality. john stuart mill thomas reid and john locke were less skeptical embracing a more cautious style of metaphysics based on realism common sense and science. other philosophers notably george berkeley were led from empiricism to idealistic metaphysics.immanuel kant attempted a grand synthesis and revision of the trends already mentioned: scholastic philosophy systematic metaphysics and skeptical empiricism not to forget the burgeoning science of his day. as did the systems builders he had an overarching framework in which all questions were to be addressed. like hume who famously woke him from his dogmatic slumbers he was suspicious of metaphysical speculation and also places much emphasis on the limitations of the human mind. kant described his shift in metaphysics away from making claims about an objective noumenal world towards exploring the subjective phenomenal world as a copernican revolution by analogy to though opposite in direction to copernicus shift from man the subject to the sun an object at the center of the universe.kant saw rationalist philosophers as aiming for a kind of metaphysical knowledge he defined as the synthetic apriori—that is knowledge that does not come from the senses it is a priori but is nonetheless about reality synthetic. inasmuch as it is about reality it differs from abstract mathematical propositions which he terms analytical apriori and being apriori it is distinct from empirical scientific knowledge which he terms synthetic aposteriori. the only synthetic apriori knowledge we can have is of how our minds organise the data of the senses; that organising framework is space and time which for kant have no mind-independent existence but nonetheless operate uniformly in all humans. apriori knowledge of space and time is all that remains of metaphysics as traditionally conceived. there is a reality beyond sensory data or phenomena which he calls the realm of noumena; however we cannot know it as it is in itself but only as it appears to us. he allows himself to speculate that the origins of phenomenal god morality and free will might exist in the noumenal realm but these possibilities have to be set against its basic unknowability for humans. although he saw himself as having disposed of metaphysics in a sense he has generally been regarded in retrospect as having a metaphysics of his own and as beginning the modern analytical conception of the subject.nineteenth century philosophy was overwhelmingly influenced by kant and his successors. schopenhauer schelling fichte and hegel all purveyed their own panoramic versions of german idealism kants own caution about metaphysical speculation and refutation of idealism having fallen by the wayside. the idealistic impulse continued into the early twentieth century with british idealists such as f.h. bradley and j.m.e. mctaggart. followers of karl marx took hegels dialectic view of history and re-fashioned it as materialism.early analytic philosophy and positivismduring the period when idealism was dominant in philosophy science had been making great advances. the arrival of a new generation of scientifically minded philosophers led to a sharp decline in the popularity of idealism during the s.analytic philosophy was spearheaded by bertrand russell and g.e. moore. russell and william james tried to compromise between idealism and materialism with the theory of neutral monism.the early to mid twentieth century philosophy saw a trend to reject metaphysical questions as meaningless. the driving force behind this tendency was the philosophy of logical positivism as espoused by the vienna circle which argued that the meaning of a statement was its prediction of observable results of an experiment and thus that there is no need to postulate the existence of any objects other than these perceptual observations.at around the same time the american pragmatists were steering a middle course between materialism and idealism. system-building metaphysics with a fresh inspiration from science was revived by a.n. whitehead and charles hartshorne.the forces that shaped analytic philosophy—the break with idealism and the influence of science—were much less significant outside the english speaking world although there was a shared turn toward language. continental philosophy continued in a trajectory from post kantianism.the phenomenology of husserl and others was intended as a collaborative project for the investigation of the features and structure of consciousness common to all humans in line with kants basing his synthetic apriori on the uniform operation of consciousness. it was officially neutral with regards to ontology but was nonetheless to spawn a number of metaphysical systems. brentanos concept of intentionality would become widely influential including on analytic philosophy.heidegger author of being and time saw himself as re-focusing on being-qua-being introducing the novel concept of dasein in the process. classing himself an existentialist sartre wrote an extensive study of being and nothingness.the speculative realism movement marks a return to full blooded realism.there are two fundamental aspects of everyday experience: change and persistence. until recently the western philosophical tradition has arguably championed substance and persistence with some notable exceptions however. according to process thinkers novelty flux and accident do matter and sometimes they constitute the ultimate reality.in a broad sense process metaphysics is as old as western philosophy with figures such as heraclitus plotinus duns scotus leibniz david hume georg wilhelm friedrich hegel friedrich wilhelm joseph von schelling gustav theodor fechner friedrich adolf trendelenburg charles renouvier karl marx ernst mach friedrich wilhelm nietzsche émile boutroux henri bergson samuel alexander and nicolas berdyaev. it seemingly remains an open question whether major continental figures such as the late martin heidegger maurice merleau-ponty gilles deleuze michel foucault or jacques derrida should be included.in a strict sense process metaphysics may be limited to the works of a few founding fathers: g.w.f. hegel charles sanders peirce william james henri bergson a.n. whitehead and john dewey. from a european perspective there was a very significant and early whiteheadian influence on the works of outstanding scholars such as émile meyerson – louis couturat – jean wahl – robin george collingwood – philippe devaux – hans jonas – dorothy m. emmett – maurice merleau ponty – enzo paci – charlie dunbar broad – wolfe mays – ilya prigogine – jules vuillemin – jean ladrière – gilles deleuze – wolfhart pannenberg – and reiner wiehl –.while early analytic philosophy tended to reject metaphysical theorizing under the influence of logical positivism it was revived in the second half of the twentieth century. philosophers such as david k. lewis and david armstrong developed elaborate theories on a range of topics such as universals causation possibility and necessity and abstract objects. however the focus of analytic philosophy generally is away from the construction of all-encompassing systems and toward close analysis of individual ideas.among the developments that led to the revival of metaphysical theorizing were quines attack on the analytic–synthetic distinction which was generally taken to undermine carnaps distinction between existence questions internal to a framework and those external to it.the philosophy of fiction the problem of empty names and the debate over existences status as a property have all come of relative obscurity into the limelight while perennial issues such as free will possible worlds and the philosophy of time have had new life breathed into them.the analytic view is of metaphysics as studying phenomenal human concepts rather than making claims about the noumenal world so its style often blurs into philosophy of language and introspective psychology. compared to system-building it can seem very dry stylistically similar to computer programming mathematics or even accountancy as a common stated goal is to account for entities in the world.citation neededmodern philosophy is philosophy developed in the modern era and associated with modernity. it is not a specific doctrine or school and thus should not be confused with modernism although there are certain assumptions common to much of it which helps to distinguish it from earlier philosophy.the th and early th centuries roughly mark the beginning and the end of modern philosophy. how much of the renaissance should be included is a matter for dispute; likewise modernity may or may not have ended in the twentieth century and been replaced by postmodernity. how one decides these questions will determine the scope of ones use of the term modern philosophy.how much of renaissance intellectual history is part of modern philosophy is disputed: the early renaissance is often considered less modern and more medieval compared to the later high renaissance. by the th and th centuries the major figures in philosophy of mind epistemology and metaphysics were roughly divided into two main groups. the rationalists mostly in france and germany argued all knowledge must begin from certain innate ideas in the mind. major rationalists were descartes baruch spinoza gottfried leibniz and nicolas malebranche. the empiricists by contrast held that knowledge must begin with sensory experience. major figures in this line of thought are john locke george berkeley and david hume these are retrospective categories for which kant is largely responsible. ethics and political philosophy are usually not subsumed under these categories though all these philosophers worked in ethics in their own distinctive styles. other important figures in political philosophy include thomas hobbes and jean-jacques rousseau.in the late eighteenth century immanuel kant set forth a groundbreaking philosophical system which claimed to bring unity to rationalism and empiricism. whether or not he was right he did not entirely succeed in ending philosophical dispute. kant sparked a storm of philosophical work in germany in the early nineteenth century beginning with german idealism. the characteristic theme of idealism was that the world and the mind equally must be understood according to the same categories; it culminated in the work of georg wilhelm friedrich hegel who among many other things said that the real is rational; the rational is real.hegels work was carried in many directions by his followers and critics. karl marx appropriated both hegels philosophy of history and the empirical ethics dominant in britain transforming hegels ideas into a strictly materialist form setting the grounds for the development of a science of society. søren kierkegaard in contrast dismissed all systematic philosophy as an inadequate guide to life and meaning. for kierkegaard life is meant to be lived not a mystery to be solved. arthur schopenhauer took idealism to the conclusion that the world was nothing but the futile endless interplay of images and desires and advocated atheism and pessimism. schopenhauers ideas were taken up and transformed by nietzsche who seized upon their various dismissals of the world to proclaim god is dead and to reject all systematic philosophy and all striving for a fixed truth transcending the individual. nietzsche found in this not grounds for pessimism but the possibility of a new kind of freedom.th-century british philosophy came increasingly to be dominated by strands of neo-hegelian thought and as a reaction against this figures such as bertrand russell and george edward moore began moving in the direction of analytic philosophy which was essentially an updating of traditional empiricism to accommodate the new developments in logic of the german mathematician gottlob frege.renaissance humanism emphasized the value of human beings see oration on the dignity of man and opposed dogma and scholasticism. this new interest in human activities led to the development of political science with the prince of niccolò machiavelli. humanists differed from medieval scholars also because they saw the natural world as mathematically ordered and pluralistic instead of thinking of it in terms of purposes and goals. renaissance philosophy is perhaps best explained by two propositions made by leonardo da vinci in his notebooks:all of our knowledge has its origins in our perceptionsthere is no certainty where one can neither apply any of the mathematical sciences nor any of those which are based upon the mathematical sciences.in a similar way galileo galilei based his scientific method on experiments but also developed mathematical methods for application to problems in physics. these two ways to conceive human knowledge formed the background for the principle of empiricism and rationalism respectively.modern philosophy traditionally begins with rené descartes and his dictum i think therefore i am. in the early seventeenth century the bulk of philosophy was dominated by scholasticism written by theologians and drawing upon plato aristotle and early church writings. descartes argued that many predominant scholastic metaphysical doctrines were meaningless or false. in short he proposed to begin philosophy from scratch. in his most important work meditations on first philosophy he attempts just this over six brief essays. he tries to set aside as much as he possibly can of all his beliefs to determine what if anything he knows for certain. he finds that he can doubt nearly everything: the reality of physical objects god his memories history science even mathematics but he cannot doubt that he is in fact doubting. he knows what he is thinking about even if it is not true and he knows that he is there thinking about it. from this basis he builds his knowledge back up again. he finds that some of the ideas he has could not have originated from him alone but only from god; he proves that god exists. he then demonstrates that god would not allow him to be systematically deceived about everything; in essence he vindicates ordinary methods of science and reasoning as fallible but not false.empiricism is a theory of knowledge which opposes other theories of knowledge such as rationalism idealism and historicism. empiricism asserts that knowledge comes only or primarily via sensory experience as opposed to rationalism which asserts that knowledge comes also from pure thinking. both empiricism and rationalism are individualist theories of knowledge whereas historicism is a social epistemology. while historicism also acknowledges the role of experience it differs from empiricism by assuming that sensory data cannot be understood without considering the historical and cultural circumstances in which observations are made. empiricism should not be mixed up with empirical research because different epistemologies should be considered competing views on how best to do studies and there is near consensus among researchers that studies should be empirical. today empiricism should therefore be understood as one among competing ideals of getting knowledge or how to do studies. as such empiricism is first and foremost characterized by the ideal to let observational data speak for themselves while the competing views are opposed to this ideal. the term empiricism should thus not just be understood in relation to how this term has been used in the history of philosophy. it should also be constructed in a way which makes it possible to distinguish empiricism among other epistemological positions in contemporary science and scholarship. in other words: empiricism as a concept has to be constructed along with other concepts which together make it possible to make important discriminations between different ideals underlying contemporary science.empiricism is one of several competing views that predominate in the study of human knowledge known as epistemology. empiricism emphasizes the role of experience and evidence especially sensory perception in the formation of ideas over the notion of innate ideas or tradition in contrast to for example rationalism which relies upon reason and can incorporate innate knowledge.political philosophy is the study of such topics as politics liberty justice property rights law and the enforcement of a legal code by authority: what they are why or even if they are needed what if anything makes a government legitimate what rights and freedoms it should protect and why what form it should take and why what the law is and what duties citizens owe to a legitimate government if any and when it may be legitimately overthrown—if ever. in a vernacular sense the term political philosophy often refers to a general view or specific ethic political belief or attitude about politics that does not necessarily belong to the technical discipline of philosophy.idealism refers to the group of philosophies which assert that reality or reality as we can know it is fundamentally a construct of the mind or otherwise immaterial. epistemologically idealism manifests as a skepticism about the possibility of knowing any mind-independent thing. in a sociological sense idealism emphasizes how human ideas—especially beliefs and values—shape society. as an ontological doctrine idealism goes further asserting that all entities are composed of mind or spirit. idealism thus rejects physicalist and dualist theories that fail to ascribe priority to the mind. an extreme version of this idealism can exist in the philosophical notion of solipsism.existentialism is generally considered to be the philosophical and cultural movement which holds that the starting point of philosophical thinking must be the individual and the experiences of the individual. building on that existentialists hold that moral thinking and scientific thinking together do not suffice to understand human existence and therefore a further set of categories governed by the norm of authenticity is necessary to understand human existence.phenomenology is the study of the structure of experience. it is a broad philosophical movement founded in the early years of the th century by edmund husserl expanded upon by a circle of his followers at the universities of göttingen and munich in germany. the philosophy then spread to france the united states and elsewhere often in contexts far removed from husserls early work.pragmatism is a philosophical tradition centered on the linking of practice and theory. it describes a process where theory is extracted from practice and applied back to practice to form what is called intelligent practice.citation needed important positions characteristic of pragmatism include instrumentalism radical empiricism verificationism conceptual relativity and fallibilism.citation needed there is general consensus among pragmatists that philosophy should take the methods and insights of modern science into account. charles sanders peirce and his pragmatic maxim deserves most of the credit for pragmatism along with later twentieth century contributors william james and john dewey.analytic philosophy came to dominate english-speaking countries in the th century. in the united states united kingdom canada scandinavia australia and new zealand the overwhelming majority of university philosophy departments identify themselves as analytic departments. the term generally refers to a broad philosophical tradition characterized by an emphasis on clarity and argument often achieved via modern formal logic and analysis of language and a respect for the natural sciences.various philosophical movements in asia arose in the modern period including:liberty enlightening the world known as the statue of liberty was donated to the us by france in  as an artistic personification of liberty.broadly speaking liberty is the ability to do as one pleases. it is a synonym for the word freedom. in modern politics liberty is the state of being free within society from oppressive restrictions imposed by authority on ones way of life behaviour or political views. in philosophy liberty involves free will as contrasted with determinism. in theology liberty is freedom from the effects of sin spiritual servitude or worldly ties. sometimes liberty is differentiated from freedom by using the word freedom primarily if not exclusively to mean the ability to do as one wills and what one has the power to do; and using the word liberty to mean the absence of arbitrary restraints taking into account the rights of all involved. in this sense the exercise of liberty is subject to capability and limited by the rights of others. thus liberty entails the responsible use of freedom under the rule of law without depriving anyone else of their freedom. freedom is more broad in that it represents a total lack of restraint or the unrestrained ability to fulfill ones desires. for example a person can have the freedom to murder but not have the liberty to murder as the latter example deprives others of their right not to be harmed. liberty can be taken away as a form of punishment. in many countries people can be deprived of their liberty if they are convicted of criminal acts.the word liberty is often used in slogans such as life liberty and the pursuit of happiness or liberty equality fraternity.liberty originates from the latin word libertas derived from the name of the goddess libertas who along with the goddess of liberty usually portrays the concept and the archaic roman god liber.philosophers from earliest times have considered the question of liberty. roman emperor marcus aurelius – ad wrote:a polity in which there is the same law for all a polity administered with regard to equal rights and equal freedom of speech and the idea of a kingly government which respects most of all the freedom of the governed.a free man is he that in those things which by his strength and wit he is able to do is not hindered to do what he hath the will to do.john locke – rejected that definition of liberty. while not specifically mentioning hobbes he attacks sir robert filmer who had the same definition. according to locke:in the state of nature liberty consists of being free from any superior power on earth. people are not under the will or lawmaking authority of others but have only the law of nature for their rule. in political society liberty consists of being under no other lawmaking power except that established by consent in the commonwealth. people are free from the dominion of any will or legal restraint apart from that enacted by their own constituted lawmaking power according to the trust put in it. thus freedom is not as sir robert filmer defines it: a liberty for everyone to do what he likes to live as he pleases and not to be tied by any laws. freedom is constrained by laws in both the state of nature and political society. freedom of nature is to be under no other restraint but the law of nature. freedom of people under government is to be under no restraint apart from standing rules to live by that are common to everyone in the society and made by the lawmaking power established in it. persons have a right or liberty to  follow their own will in all things that the law has not prohibited and  not be subject to the inconstant uncertain unknown and arbitrary wills of others.john stuart mill – in his work on liberty was the first to recognize the difference between liberty as the freedom to act and liberty as the absence of coercion.in his book two concepts of liberty isaiah berlin formally framed the differences between two perspectives as the distinction between two opposite concepts of liberty: positive liberty and negative liberty. the latter designates a negative condition in which an individual is protected from tyranny and the arbitrary exercise of authority while the former refers to the liberty that comes from self-mastery the freedom from inner compulsions such as weakness and fear.the magna carta originally known as the charter of liberties of  written in iron gall ink on parchment in medieval latin using standard abbreviations of the period. this document is held at the british library and is identified as british library cotton ms augustus ii..historya romanticised th-century recreation of king john signing the magna carta. the charter would have been sealed rather than signed.the modern concept of political liberty has its origins in the greek concepts of freedom and slavery. to be free to the greeks was not to have a master to be independent from a master to live as one likes. that was the original greek concept of freedom. it is closely linked with the concept of democracy as aristotle put it:this then is one note of liberty which all democrats affirm to be the principle of their state. another is that a man should live as he likes. this they say is the privilege of a freeman since on the other hand not to live as a man likes is the mark of a slave. this is the second characteristic of democracy whence has arisen the claim of men to be ruled by none if possible or if this is impossible to rule and be ruled in turns; and so it contributes to the freedom based upon equality.this applied only to free men. in athens for instance women could not vote or hold office and were legally and socially dependent on a male relative.the populations of the persian empire enjoyed some degree of freedom. citizens of all religions and ethnic groups were given the same rights and had the same freedom of religion women had the same rights as men and slavery was abolished  bc. all the palaces of the kings of persia were built by paid workers in an era when slaves typically did such work.in the maurya empire of ancient india citizens of all religions and ethnic groups had some rights to freedom tolerance and equality. the need for tolerance on an egalitarian basis can be found in the edicts of ashoka the great which emphasize the importance of tolerance in public policy by the government. the slaughter or capture of prisoners of war also appears to have been condemned by ashoka. slavery also appears to have been non-existent in the maurya empire. however according to hermann kulke and dietmar rothermund ashokas orders seem to have been resisted right from the beginning.roman law also embraced certain limited forms of liberty even under the rule of the roman emperors. however these liberties were accorded only to roman citizens. many of the liberties enjoyed under roman law endured through the middle ages but were enjoyed solely by the nobility rarely by the common man.citation needed the idea of inalienable and universal liberties had to wait until the age of enlightenment.in french liberty. british slavery  james gillray caricatured french liberty as the opportunity to starve and british slavery as bloated complaints about taxation.the social contract theory most influentially formulated by hobbes john locke and rousseau though first suggested by plato in the republic was among the first to provide a political classification of rights in particular through the notion of sovereignty and of natural rights. the thinkers of the enlightenment reasoned that law governed both heavenly and human affairs and that law gave the king his power rather than the kings power giving force to law. this conception of law would find its culmination in the ideas of montesquieu. the conception of law as a relationship between individuals rather than families came to the fore and with it the increasing focus on individual liberty as a fundamental reality given by nature and natures god which in the ideal state would be as universal as possible.in on liberty john stuart mill sought to define the ...nature and limits of the power which can be legitimately exercised by society over the individual and as such he describes an inherent and continuous antagonism between liberty and authority and thus the prevailing question becomes how to make the fitting adjustment between individual independence and social control.england and following the act of union  great britain laid down the cornerstones of the concept of individual liberty.in  as a condition of his coronation william the conqueror assented to the london charter of liberties which guaranteed the saxon liberties of the city of london.in  the charter of liberties is passed which sets out certain liberties of nobles church officials and individuals.in  henry ii of england transformed english law by passing the assize of clarendon. the act a forerunner to trial by jury started the abolition of trial by combat and trial by ordeal.- sees the publication of tractatus de legibus et consuetudinibus regni anglie which contains authoritative definitions of freedom and servitude:freedom is the natural faculty of doing what each person pleases to do according to his will except what is prohibited to him of right or by force. sevitude on the other hand may be said to be the contrary as if any person contrary to freedom should be bound upon a covenant to do something or not to do it.in  magna carta was enacted arguably becoming the cornerstone of liberty in first england then great britain and later the world.in  the english parliament passed the petition of right which set out specific liberties of english subjects.in  the english parliament passed the habeas corpus act which outlawed unlawful or arbitrary imprisonment.in  the bill of rights granted freedom of speech in parliament and reinforced many existing civil rights in england. the scots law equivalent the claim of right is also passed.in  the somerset v stewart judgement found that slavery was unsupported by common law in england and wales.in  an essay by the philosopher john stuart mill entitled on liberty argued for toleration and individuality. if any opinion is compelled to silence that opinion may for aught we can certainly know be true. to deny this is to assume our own infallibility.in  two concepts of liberty by isaiah berlin identified negative liberty as an obstacle as distinct from positive liberty which promotes self-mastery and the concepts of freedom.in  british representatives attempted to but were prevented from adding a legal framework to the universal declaration of human rights. it was not until  that the international covenant on civil and political rights came into force giving a legal status to most of the declaration.the depiction of liberty on the walking liberty half dollar.according to the  united states declaration of independence all men have a natural right to life liberty and the pursuit of happiness. but this declaration of liberty was troubled from the outset by the institutionalization of legalized black slavery. slave owners argued that their liberty was paramount since it involved property their slaves and that blacks had no rights that any white man was obliged to recognize. the supreme court in the dred scott decision upheld this principle. it was not until  following the civil war that the us constitution was amended to extend these rights to persons of color and not until  that these rights were extended to women.by the later half of the th century liberty was expanded further to prohibit government interference with personal choices. in the united states supreme court decision griswold v. connecticut justice william o. douglas argued that liberties relating to personal relationships such as marriage have a unique primacy of place in the hierarchy of freedoms. jacob m. appel has summarized this principle:i am grateful that i have rights in the proverbial public square – but as a practical matter my most cherished rights are those that i possess in my bedroom and hospital room and death chamber. most people are far more concerned that they can control their own bodies than they are about petitioning congress.in modern america various competing ideologies have divergent views about how best to promote liberty. liberals in the original sense of the word see equality as a necessary component of freedom. progressives stress freedom from business monopoly as essential. libertarians disagree and see economic freedom as best. the tea party movement sees the undefined big government as the enemy of freedom.france supported the americans in their revolt against english rule and in  overthrew their own monarchy with the cry of liberté égalité fraternité. the bloodbath that followed known as the reign of terror soured many people on the idea of liberty. edmund burke considered one of the fathers of conservatism wrote the french had shewn themselves the ablest architects of ruin that had hitherto existed in the world.according to the concise oxford dictionary of politics liberalism is the belief that it is the aim of politics to preserve individual rights and to maximize freedom of choice. but they point out that there is considerable discussion about how to achieve those goals. every discussion of freedom depends on three key components: who is free what they are free to do and what forces restrict their freedom. john gray argues that the core belief of liberalism is toleration. liberals allow others freedom to do what they want in exchange for having the same freedom in return. this idea of freedom is personal rather than political. william safire points out that liberalism is attacked by both the right and the left: by the right for defending such practices as abortion homosexuality and atheism and by the left for defending free enterprise and the rights of the individual over the collective.socialists view freedom as a concrete situation as opposed to a purely abstract ideal. freedom is a state of being where individuals have agency to pursue their creative interests unhindered by coercive social relationships specifically those they are forced to engage in as a requisite for survival under a given social system. freedom thus requires both the material economic conditions that make freedom possible alongside social relationships and institutions conducive to freedom.the socialist conception of freedom is closely related to the socialist view of creativity and individuality. influenced by karl marxs concept of alienated labor socialists understand freedom to be the ability for an individual to engage in creative work in the absence of alienation where alienated labor refers to work people are forced to perform and un-alienated work refers to individuals pursuing their own creative interests.for karl marx meaningful freedom is only attainable in a communist society characterized by superabundance and free access. such a social arrangement would eliminate the need for alienated labor and enable individuals to pursue their own creative interests leaving them to develop and maximize their full potentialities. this goes alongside marxs emphasis on the ability of socialism and communism progressively reducing the average length of the workday to expand the realm of freedom or discretionary free time for each person. marxs notion of communist society and human freedom is thus radically individualistic.while many anarchists see freedom slightly differently all oppose authority including the authority of the state of capitalism and of nationalism. for the russian revolutionary anarchist mikhail bakunin liberty did not mean an abstract ideal but a concrete reality based on the equal liberty of others. in a positive sense liberty consists of the fullest development of all the faculties and powers of every human being by education by scientific training and by material prosperity. such a conception of liberty is eminently social because it can only be realized in society not in isolation. in a negative sense liberty is the revolt of the individual against all divine collective and individual authority.some authors have suggested that a virtuous culture must exist as a prerequisite for liberty. benjamin franklin stated that only a virtuous people are capable of freedom. as nations become corrupt and vicious they have more need of masters. madison likewise declared: to suppose that any form of government will secure liberty or happiness without any virtue in the people is a chimerical idea. john adams acknowledged: our constitution was made only for a moral and religious people. it is wholly inadequate to the government of any other.jauthorityfrom wikipedia the free encyclopediajump to navigationjump to searchthis article is about authority as a political concept. for other uses see authority disambiguation.authority is the legitimate power which one person or group possesses and practices over another. a civil state usually makes this formal by way of a judicial branch and an executive branch of government. in the exercise of governance the terms authority and power sometimes are inaccurately used as synonyms. the term authority identifies political legitimacy which grants and justifies the right to exercise power of government; and the term power identifies the ability to accomplish an authorized goal by way either of compliance or of obedience; hence authority is the power to make decisions and the legitimacy to make such legal decisions and order their execution.ancient understandings of authority trace back to rome and draw later from catholic thomistic thought and other traditional understandings. in more modern terms forms of authority include transitional authority exhibited in for example cambodia public authority in the form of popular power and in more administrative terms bureaucratic or managerial techniques. in terms of bureaucratic governance one limitation of the governmental agents of the executive branch as outlined by george a. krause is that they are not as close to the popular will as elected representatives are. the claims of authority can extend to national or individual sovereignty which is broadly or provisionally understood as a claim to political authority that is legitimated.historical applications of authority in political terms include the formation of the city-state of geneva and experimental treatises involving the topic of authority in relation to education include emile by jean-jacques rousseau. as david laitin defines authority is a key concept to be defined in determining the range and role of political theory science and inquiry. the relevance of a grounded understanding of authority includes the basic foundation and formation of political civil and/or ecclesiastical institutions or representatives. in recent years however authority in political contexts has been challenged or questioned.political philosophythere have been several contributions to the debate of political authority. among others hannah arendt carl joachim friedrich thomas hobbes alexandre kojève and carl schmitt have provided some of the most remarkable texts.in political philosophy the jurisdiction of political authority the location of sovereignty the balancing of freedom and authority and the requirements of political obligations have been core questions from the time of plato and aristotle to the present. most democratic societies are engaged in an ongoing discussion regarding the legitimate extent of the exercise of governmental authority. in the united states for instance there is a prevailing belief that the political system as instituted by the founding fathers should accord the populace as much freedom as reasonable and that government should limit its authority accordingly known as limited government.in the discussion regarding the legitimacy of political authority there are two beliefs at the respective ends of the spectrum. the first is the belief in the absolute freedom of the individual otherwise known as political anarchism. the second is the belief that there must be a central authority in the form of a sovereign that claims ownership and control over the masses. this belief is known as statism. sovereignty in modern terms can refer either to the adherence to a form of sovereign rule or the individual sovereignty or autonomy of a nation-state. the argument for political anarchy and anti-statism is made by michael huemer in his book the problem of political authority. on the other side one of the main arguments for the legitimacy of the state is some form of the “social contract theory” developed by thomas hobbes in his  book leviathan or by jean-jacques rousseau in his political writings on the social contract.sociologysince the emergence of the social sciences authority has become a subject of research in a variety of empirical settings: the family parental authority small groups informal authority of leadership intermediate organizations such as schools churches armies industries and bureaucracies organizational and bureaucratic authority and society-wide or inclusive organizations ranging from the most primitive tribal society to the modern nation-state and intermediate organization political authority.the definition of authority in contemporary social science remains a matter of debate. max weber in his essay politics as a vocation  divided legitimate authority into three types. others like howard bloom suggest a parallel between authority and respect/reverence for ancestors.the united kingdom and the commonwealth realmsthe political authority in the british context can be traced to james vi and i of scotland who wrote two political treatise called basilikon doron and the trve lawe of free monarchies: or the reciprock and mvtvall dvtie betwixt a free king and his naturall subiectes which advocated his right to rule on the basis of the concept of the divine right of kings a theological concept that has basis in multiple religions but in this case christianity tracing this right to the apostolic succession. the king in the united kingdom and the commonwealth states are considered the foundations of judicial legislative and executive authority.the united statesthe understanding of political authority and the exercise of political powers in the american context traces back to the writings of the founding fathers including the arguments put forward in the federalist papers by james madison alexander hamilton and the first chief justice of the united states john jay and later speeches by the th president of the united states abraham lincoln. our government rests in public opinion president abraham lincoln said in . in his  speech at peoria illinois lincoln espoused the proposition that each man should do precisely as he pleases with all which is exclusively his own a principle existing at the foundation of the sense of justice. this sense of personal ownership and stewardship was integral to the practice of self-government as abraham lincoln saw it by a republican nation and its people. this was because as abraham lincoln also declared no man is good enough to govern another man without that others consent.reason is the capacity of consciously making sense of things applying logic and adapting or justifying practices institutions and beliefs based on new or existing information. it is closely associated with such characteristically human activities as philosophy science language mathematics and art and is normally considered to be a distinguishing ability possessed by humans. reason is sometimes referred to as rationality.reasoning is associated with thinking cognition and intellect. the field of logic studies ways in which humans reason formally through argument. reasoning may be subdivided into forms of logical reasoning such as: deductive reasoning inductive reasoning and abductive reasoning. aristotle drew a distinction between logical discursive reasoning reason proper and intuitive reasoning in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. in some social and political settings logical and intuitive modes of reasoning may clash while in other contexts intuition and formal reason are seen as complementary rather than adversarial. for example in mathematics intuition is often necessary for the creative processes involved with arriving at a formal proof arguably the most difficult of formal reasoning tasks.reasoning like habit or intuition is one of the ways by which thinking moves from one idea to a related idea. for example reasoning is the means by which rational individuals understand sensory information from their environments or conceptualize abstract dichotomies such as cause and effect truth and falsehood or ideas regarding notions of good or evil. reasoning as a part of executive decision making is also closely identified with the ability to self-consciously change in terms of goals beliefs attitudes traditions and institutions and therefore with the capacity for freedom and self-determination.in contrast to the use of reason as an abstract noun a reason is a consideration given which either explains or justifies events phenomena or behavior. reasons justify decisions reasons support explanations of natural phenomena; reasons can be given to explain the actions conduct of individuals.using reason or reasoning can also be described more plainly as providing good or the best reasons. for example when evaluating a moral decision morality is at the very least the effort to guide ones conduct by reason—that is doing what there are the best reasons for doing—while giving equal and impartial weight to the interests of all those affected by what one does.psychologists and cognitive scientists have attempted to study and explain how people reason e.g. which cognitive and neural processes are engaged and how cultural factors affect the inferences that people draw. the field of automated reasoning studies how reasoning may or may not be modeled computationally. animal psychology considers the question of whether animals other than humans can reason.in the english language and other modern european languages reason and related words represent words which have always been used to translate latin and classical greek terms in the sense of their philosophical usage.the original greek term was λόγος logos the root of the modern english word logic but also a word which could mean for example speech or explanation or an account of money handled.as a philosophical term logos was translated in its non-linguistic senses in latin as ratio. this was originally not just a translation used for philosophy but was also commonly a translation for logos in the sense of an account of money.french raison is derived directly from latin and this is the direct source of the english word reason.the earliest major philosophers to publish in english such as francis bacon thomas hobbes and john locke also routinely wrote in latin and french and compared their terms to greek treating the words logos ratio raison and reason as interchangeable. the meaning of the word reason in senses such as human reason also overlaps to a large extent with rationality and the adjective of reason in philosophical contexts is normally rational rather than reasoned or reasonable. some philosophers thomas hobbes for example also used the word ratiocination as a synonym for reasoning.francisco de goya the sleep of reason produces monsters el sueño de la razón produce monstruos c. the proposal that reason gives humanity a special position in nature has been argued to be a defining characteristic of western philosophy and later western modern science starting with classical greece. philosophy can be described as a way of life based upon reason and in the other direction reason has been one of the major subjects of philosophical discussion since ancient times. reason is often said to be reflexive or self-correcting and the critique of reason has been a persistent theme in philosophy. it has been defined in different ways at different times by different thinkers about human nature.for many classical philosophers nature was understood teleologically meaning that every type of thing had a definitive purpose which fit within a natural order that was itself understood to have aims. perhaps starting with pythagoras or heraclitus the cosmos is even said to have reason. reason by this account is not just one characteristic that humans happen to have and that influences happiness amongst other characteristics. reason was considered of higher stature than other characteristics of human nature such as sociability because it is something humans share with nature itself linking an apparently immortal part of the human mind with the divine order of the cosmos itself. within the human mind or soul psyche reason was described by plato as being the natural monarch which should rule over the other parts such as spiritedness thumos and the passions. aristotle platos student defined human beings as rational animals emphasizing reason as a characteristic of human nature. he defined the highest human happiness or well being eudaimonia as a life which is lived consistently excellently and completely in accordance with reason.the conclusions to be drawn from the discussions of aristotle and plato on this matter are amongst the most debated in the history of philosophy. but teleological accounts such as aristotles were highly influential for those who attempt to explain reason in a way which is consistent with monotheism and the immortality and divinity of the human soul. for example in the neo-platonist account of plotinus the cosmos has one soul which is the seat of all reason and the souls of all individual humans are part of this soul. reason is for plotinus both the provider of form to material things and the light which brings individuals souls back into line with their source. such neo-platonist accounts of the rational part of the human soul were standard amongst medieval islamic philosophers and under this influence mainly via averroes came to be debated seriously in europe until well into the renaissance and they remain important in iranian philosophy.subject-centred reason in early modern philosophythe early modern era was marked by a number of significant changes in the understanding of reason starting in europe. one of the most important of these changes involved a change in the metaphysical understanding of human beings. scientists and philosophers began to question the teleological understanding of the world. nature was no longer assumed to be human-like with its own aims or reason and human nature was no longer assumed to work according to anything other than the same laws of nature which affect inanimate things. this new understanding eventually displaced the previous world view that derived from a spiritual understanding of the universe.accordingly in the th century rené descartes explicitly rejected the traditional notion of humans as rational animals suggesting instead that they are nothing more than thinking things along the lines of other things in nature. any grounds of knowledge outside that understanding was therefore subject to doubt.in his search for a foundation of all possible knowledge descartes deliberately decided to throw into doubt all knowledge – except that of the mind itself in the process of thinking:at this time i admit nothing that is not necessarily true. i am therefore precisely nothing but a thinking thing; that is a mind or intellect or understanding or reason – words of whose meanings i was previously ignorant.this eventually became known as epistemological or subject-centred reason because it is based on the knowing subject who perceives the rest of the world and itself as a set of objects to be studied and successfully mastered by applying the knowledge accumulated through such study. breaking with tradition and many thinkers after him descartes explicitly did not divide the incorporeal soul into parts such as reason and intellect describing them as one indivisible incorporeal entity.a contemporary of descartes thomas hobbes described reason as a broader version of addition and subtraction which is not limited to numbers. this understanding of reason is sometimes termed calculative reason. similar to descartes hobbes asserted that no discourse whatsoever can end in absolute knowledge of fact past or to come but that sense and memory is absolute knowledge.in the late th century through the th century john locke and david hume developed descartes line of thought still further. hume took it in an especially skeptical direction proposing that there could be no possibility of deducing relationships of cause and effect and therefore no knowledge is based on reasoning alone even if it seems otherwise.hume famously remarked that we speak not strictly and philosophically when we talk of the combat of passion and of reason. reason is and ought only to be the slave of the passions and can never pretend to any other office than to serve and obey them. hume also took his definition of reason to unorthodox extremes by arguing unlike his predecessors that human reason is not qualitatively different from either simply conceiving individual ideas or from judgments associating two ideas and that reason is nothing but a wonderful and unintelligible instinct in our souls which carries us along a certain train of ideas and endows them with particular qualities according to their particular situations and relations. it followed from this that animals have reason only much less complex than human reason.in the th century immanuel kant attempted to show that hume was wrong by demonstrating that a transcendental self or i was a necessary condition of all experience. therefore suggested kant on the basis of such a self it is in fact possible to reason both about the conditions and limits of human knowledge. and so long as these limits are respected reason can be the vehicle of morality justice aesthetics theories of knowledge epistemology and understanding.in the formulation of kant who wrote some of the most influential modern treatises on the subject the great achievement of reason german: vernunft is that it is able to exercise a kind of universal law-making. kant was able therefore to reformulate the basis of moral-practical theoretical and aesthetic reasoning on universal laws.here practical reasoning is the self-legislating or self-governing formulation of universal norms and theoretical reasoning the way humans posit universal laws of nature.under practical reason the moral autonomy or freedom of human beings depends on their ability to behave according to laws that are given to them by the proper exercise of that reason. this contrasted with earlier forms of morality which depended on religious understanding and interpretation or nature for their substance.according to kant in a free society each individual must be able to pursue their goals however they see fit so long as their actions conform to principles given by reason. he formulated such a principle called the categorical imperative which would justify an action only if it could be universalized:act only according to that maxim whereby you can at the same time will that it should become a universal law.in contrast to hume then kant insists that reason itself german vernunft has natural ends itself the solution to the metaphysical problems especially the discovery of the foundations of morality. kant claimed that this problem could be solved with his transcendental logic which unlike normal logic is not just an instrument which can be used indifferently as it was for aristotle but a theoretical science in its own right and the basis of all the others.according to jürgen habermas the substantive unity of reason has dissolved in modern times such that it can no longer answer the question how should i live instead the unity of reason has to be strictly formal or procedural. he thus described reason as a group of three autonomous spheres on the model of kants three critiques:cognitive–instrumental reason is the kind of reason employed by the sciences. it is used to observe events to predict and control outcomes and to intervene in the world on the basis of its hypotheses;moral–practical reason is what we use to deliberate and discuss issues in the moral and political realm according to universalizable procedures similar to kants categorical imperative; andaesthetic reason is typically found in works of art and literature and encompasses the novel ways of seeing the world and interpreting things that those practices embody.for habermas these three spheres are the domain of experts and therefore need to be mediated with the lifeworld by philosophers. in drawing such a picture of reason habermas hoped to demonstrate that the substantive unity of reason which in pre-modern societies had been able to answer questions about the good life could be made up for by the unity of reasons formalizable procedures.hamann herder kant hegel kierkegaard nietzsche heidegger foucault rorty and many other philosophers have contributed to a debate about what reason means or ought to mean. some like kierkegaard nietzsche and rorty are skeptical about subject-centred universal or instrumental reason and even skeptical toward reason as a whole. others including hegel believe that it has obscured the importance of intersubjectivity or spirit in human life and attempt to reconstruct a model of what reason should be.some thinkers e.g. foucault believe there are other forms of reason neglected but essential to modern life and to our understanding of what it means to live a life according to reason.in the last several decades a number of proposals have been made to re-orient this critique of reason or to recognize the other voices or new departments of reason:for example in opposition to subject-centred reason habermas has proposed a model of communicative reason that sees it as an essentially cooperative activity based on the fact of linguistic intersubjectivity.nikolas kompridis has proposed a widely encompassing view of reason as that ensemble of practices that contributes to the opening and preserving of openness in human affairs and a focus on reasons possibilities for social change.the philosopher charles taylor influenced by the th century german philosopher martin heidegger has proposed that reason ought to include the faculty of disclosure which is tied to the way we make sense of things in everyday life as a new department of reason.in the essay what is enlightenment michel foucault proposed a concept of critique based on kants distinction between private and public uses of reason. this distinction as suggested has two dimensions:private reason is the reason that is used when an individual is a cog in a machine or when one has a role to play in society and jobs to do: to be a soldier to have taxes to pay to be in charge of a parish to be a civil servant.public reason is the reason used when one is reasoning as a reasonable being and not as a cog in a machine when one is reasoning as a member of reasonable humanity. in these circumstances the use of reason must be free and public.the terms logic or logical are sometimes used as if they were identical with the term reason or with the concept of being rational or sometimes logic is seen as the most pure or the defining form of reason. for example in modern economics rational choice is assumed to equate to logically consistent choice.reason and logic can however be thought of as distinct although logic is one important aspect of reason. author douglas hofstadter in gödel escher bach characterizes the distinction in this way. logic is done inside a system while reason is done outside the system by such methods as skipping steps working backward drawing diagrams looking at examples or seeing what happens if you change the rules of the system.reason is a type of thought and the word logic involves the attempt to describe rules or norms by which reasoning operates so that orderly reasoning can be taught. the oldest surviving writing to explicitly consider the rules by which reason operates are the works of the greek philosopher aristotle especially prior analysis and posterior analysis. although the ancient greeks had no separate word for logic as distinct from language and reason aristotles newly coined word syllogism syllogismos identified logic clearly for the first time as a distinct field of study. when aristotle referred to the logical hē logikē he was referring more broadly to rational thought.reason compared to cause-and-effect thinking and symbolic thinkingmain articles: causality and symbolsas pointed out by philosophers such as hobbes locke and hume some animals are also clearly capable of a type of associative thinking even to the extent of associating causes and effects. a dog once kicked can learn how to recognize the warning signs and avoid being kicked in the future but this does not mean the dog has reason in any strict sense of the word. it also does not mean that humans acting on the basis of experience or habit are using their reason.human reason requires more than being able to associate two ideas even if those two ideas might be described by a reasoning human as a cause and an effect perceptions of smoke for example and memories of fire. for reason to be involved the association of smoke and the fire would have to be thought through in a way which can be explained for example as cause and effect. in the explanation of locke for example reason requires the mental use of a third idea in order to make this comparison by use of syllogism.more generally reason in the strict sense requires the ability to create and manipulate a system of symbols as well as indices and icons according to charles sanders peirce the symbols having only a nominal though habitual connection to either smoke or fire. one example of such a system of artificial symbols and signs is language.the connection of reason to symbolic thinking has been expressed in different ways by philosophers. thomas hobbes described the creation of markes or notes of remembrance leviathan ch.  as speech. he used the word speech as an english version of the greek word logos so that speech did not need to be communicated. when communicated such speech becomes language and the marks or notes or remembrance are called signes by hobbes. going further back although aristotle is a source of the idea that only humans have reason logos he does mention that animals with imagination for whom sense perceptions can persist come closest to having something like reasoning and nous and even uses the word logos in one place to describe the distinctions which animals can perceive in such cases.reason imagination mimesis and memorymain articles: imagination mimesis memory and recollectionreason and imagination rely on similar mental processes. imagination is not only found in humans. aristotle for example stated that phantasia imagination: that which can hold images or phantasmata and phronein a type of thinking that can judge and understand in some sense also exist in some animals. according to him both are related to the primary perceptive ability of animals which gathers the perceptions of different senses and defines the order of the things that are perceived without distinguishing universals and without deliberation or logos. but this is not yet reason because human imagination is different.the recent modern writings of terrence deacon and merlin donald writing about the origin of language also connect reason connected to not only language but also mimesis. more specifically they describe the ability to create language as part of an internal modeling of reality specific to humankind. other results are consciousness and imagination or fantasy. in contrast modern proponents of a genetic predisposition to language itself include noam chomsky and steven pinker to whom donald and deacon can be contrasted.as reason is symbolic thinking and peculiarly human then this implies that humans have a special ability to maintain a clear consciousness of the distinctness of icons or images and the real things they represent. starting with a modern author merlin donald writesa dog might perceive the meaning of a fight that was realistically play-acted by humans but it could not reconstruct the message or distinguish the representation from its referent a real fight. ... trained apes are able to make this distinction; young children make this distinction early – hence their effortless distinction between play-acting an event and the event itselfin classical descriptions an equivalent description of this mental faculty is eikasia in the philosophy of plato. this is the ability to perceive whether a perception is an image of something else related somehow but not the same and therefore allows humans to perceive that a dream or memory or a reflection in a mirror is not reality as such. what klein refers to as dianoetic eikasia is the eikasia concerned specifically with thinking and mental images such as those mental symbols icons signes and marks discussed above as definitive of reason. explaining reason from this direction: human thinking is special in the way that we often understand visible things as if they were themselves images of our intelligible objects of thought as foundations hypothēses in ancient greek. this thinking dianoia is ...an activity which consists in making the vast and diffuse jungle of the visible world depend on a plurality of more precise noēta.both merlin donald and the socratic authors such as plato and aristotle emphasize the importance of mimesis often translated as imitation or representation. donald writesimitation is found especially in monkeys and apes ... but ... mimesis is fundamentally different from imitation and mimicry in that it involves the invention of intentional representations. ... mimesis is not absolutely tied to external communication.mimēsis is a concept now popular again in academic discussion that was particularly prevalent in platos works and within aristotle it is discussed mainly in the poetics. in michael daviss account of the theory of man in this work.it is the distinctive feature of human action that whenever we choose what we do we imagine an action for ourselves as though we were inspecting it from the outside. intentions are nothing more than imagined actions internalizings of the external. all action is therefore imitation of action; it is poetic...donald like plato and aristotle especially in on memory and recollection emphasizes the peculiarity in humans of voluntary initiation of a search through ones mental world. the ancient greek anamnēsis normally translated as recollection was opposed to mneme or memory. memory shared with some animals requires a consciousness not only of what happened in the past but also that something happened in the past which is in other words a kind of eikasia ...but nothing except man is able to recollect. recollection is a deliberate effort to search for and recapture something once known. klein writes that to become aware of our having forgotten something means to begin recollecting. donald calls the same thing autocueing which he explains as follows: mimetic acts are reproducible on the basis of internal self-generated cues. this permits voluntary recall of mimetic representations without the aid of external cues – probably the earliest form of representational thinking.in a celebrated paper in modern times the fantasy author and philologist j.r.r. tolkien wrote in his essay on fairy stories that the terms fantasy and enchantment are connected to not only ....the satisfaction of certain primordial human desires.... but also ...the origin of language and of the mind.a subdivision of philosophy is logic. logic is the study of reasoning. looking at logical categorizations of different types of reasoning the traditional main division made in philosophy is between deductive reasoning and inductive reasoning. formal logic has been described as the science of deduction. the study of inductive reasoning is generally carried out within the field known as informal logic or critical thinking.deduction is a form of reasoning in which a conclusion follows necessarily from the stated premises. a deduction is also the conclusion reached by a deductive reasoning process. one classic example of deductive reasoning is that found in syllogisms like the following:premise : all humans are mortal.premise : socrates is a human.conclusion: socrates is mortal.the reasoning in this argument is deductively valid because there is no way in which the premises  and  could be true and the conclusion  be false.induction is a form of inference producing propositions about unobserved objects or types either specifically or generally based on previous observation. it is used to ascribe properties or relations to objects or types based on previous observations or experiences or to formulate general statements or laws based on limited observations of recurring phenomenal patterns.inductive reasoning contrasts strongly with deductive reasoning in that even in the best or strongest cases of inductive reasoning the truth of the premises does not guarantee the truth of the conclusion. instead the conclusion of an inductive argument follows with some degree of probability. relatedly the conclusion of an inductive argument contains more information than is already contained in the premises. thus this method of reasoning is ampliative.a classic example of inductive reasoning comes from the empiricist david hume:premise: the sun has risen in the east every morning up until now.conclusion: the sun will also rise in the east tomorrow.analogical reasoningmain article: analogical reasoninganalogical reasoning is a form of inductive reasoning from a particular to a particular. it is often used in case-based reasoning especially legal reasoning. an example follows:premise : socrates is human and mortal.premise : plato is human.conclusion: plato is mortal.analogical reasoning is a weaker form of inductive reasoning from a single example because inductive reasoning typically uses a large number of examples to reason from the particular to the general. analogical reasoning often leads to wrong conclusions. for example:premise : socrates is human and male.premise : ada lovelace is human.conclusion: therefore ada lovelace is male.abductive reasoning or argument to the best explanation is a form of reasoning that doesnt fit in deductive or inductive since it starts with incomplete set of observations and proceeds with likely possible explanations so the conclusion in an abductive argument does not follow with certainty from its premises and concerns something unobserved. what distinguishes abduction from the other forms of reasoning is an attempt to favour one conclusion above others by subjective judgement or attempting to falsify alternative explanations or by demonstrating the likelihood of the favoured conclusion given a set of more or less disputable assumptions. for example when a patient displays certain symptoms there might be various possible causes but one of these is preferred above others as being more probable.flawed reasoning in arguments is known as fallacious reasoning. bad reasoning within arguments can be because it commits either a formal fallacy or an informal fallacy.formal fallacies occur when there is a problem with the form or structure of the argument. the word formal refers to this link to the form of the argument. an argument that contains a formal fallacy will always be invalid.an informal fallacy is an error in reasoning that occurs due to a problem with the content rather than mere structure of the argument.traditional problems raised concerning reasonphilosophy is sometimes described as a life of reason with normal human reason pursued in a more consistent and dedicated way than usual. two categories of problem concerning reason have long been discussed by philosophers concerning reason essentially being reasonings about reasoning itself as a human aim or philosophizing about philosophizing. the first question is concerning whether we can be confident that reason can achieve knowledge of truth better than other ways of trying to achieve such knowledge. the other question is whether a life of reason a life that aims to be guided by reason can be expected to achieve a happy life more so than other ways of life whether such a life of reason results in knowledge or not.since classical times a question has remained constant in philosophical debate which is sometimes seen as a conflict between movements called platonism and aristotelianism concerning the role of reason in confirming truth. people use logic deduction and induction to reach conclusions they think are true. conclusions reached in this way are considered according to aristotle more certain than sense perceptions on their own. on the other hand if such reasoned conclusions are only built originally upon a foundation of sense perceptions then our most logical conclusions can never be said to be certain because they are built upon the very same fallible perceptions they seek to better.this leads to the question of what types of first principles or starting points of reasoning are available for someone seeking to come to true conclusions. in greek first principles are archai starting points and the faculty used to perceive them is sometimes referred to in aristotle and plato as nous which was close in meaning to awareness or consciousness.empiricism sometimes associated with aristotle but more correctly associated with british philosophers such as john locke and david hume as well as their ancient equivalents such as democritus asserts that sensory impressions are the only available starting points for reasoning and attempting to attain truth. this approach always leads to the controversial conclusion that absolute knowledge is not attainable. idealism associated with plato and his school claims that there is a higher reality from which certain people can directly arrive at truth without needing to rely only upon the senses and that this higher reality is therefore the primary source of truth.philosophers such as plato aristotle al-farabi avicenna averroes maimonides aquinas and hegel are sometimes said to have argued that reason must be fixed and discoverable—perhaps by dialectic analysis or study. in the vision of these thinkers reason is divine or at least has divine attributes. such an approach allowed religious philosophers such as thomas aquinas and étienne gilson to try to show that reason and revelation are compatible. according to hegel ...the only thought which philosophy brings with it to the contemplation of history is the simple conception of reason; that reason is the sovereign of the world; that the history of the world therefore presents us with a rational process.since the th century rationalists reason has often been taken to be a subjective faculty or rather the unaided ability pure reason to form concepts. for descartes spinoza and leibniz this was associated with mathematics. kant attempted to show that pure reason could form concepts time and space that are the conditions of experience. kant made his argument in opposition to hume who denied that reason had any role to play in experience.reason versus emotion or passionsee also: emotion and passion emotionafter plato and aristotle western literature often treated reason as being the faculty that trained the passions and appetites.citation needed stoic philosophy by contrast considered all passions undesirable.citation needed after the critiques of reason in the early enlightenment the appetites were rarely discussed or conflated with the passions.citation needed some enlightenment camps took after the stoics to say reason should oppose passion rather than order it while others like the romantics believed that passion displaces reason as in the maxim follow your heart.citation neededreason has been seen as a slave or judge of the passions notably in the work of david hume and more recently of freud.citation needed reasoning which claims that the object of a desire is demanded by logic alone is called rationalization.citation neededrousseau first proposed in his second discourse that reason and political life is not natural and possibly harmful to mankind. he asked what really can be said about what is natural to mankind. what other than reason and civil society best suits his constitution rousseau saw two principles prior to reason in human nature. first we hold an intense interest in our own well-being. secondly we object to the suffering or death of any sentient being especially one like ourselves. these two passions lead us to desire more than we could achieve. we become dependent upon each other and on relationships of authority and obedience. this effectively puts the human race into slavery. rousseau says that he almost dares to assert that nature does not destine men to be healthy. according to velkley rousseau outlines certain programs of rational self-correction most notably the political legislation of the contrat social and the moral education in émile. all the same rousseau understands such corrections to be only ameliorations of an essentially unsatisfactory condition that of socially and intellectually corrupted humanity.this quandary presented by rousseau led to kants new way of justifying reason as freedom to create good and evil. these therefore are not to be blamed on nature or god. in various ways german idealism after kant and major later figures such nietzsche bergson husserl scheler and heidegger remain preoccupied with problems coming from the metaphysical demands or urges of reason. the influence of rousseau and these later writers is also large upon art and politics. many writers such as nikos kazantzakis extol passion and disparage reason. in politics modern nationalism comes from rousseaus argument that rationalist cosmopolitanism brings man ever further from his natural state.another view on reason and emotion was proposed in the  book titled descartes error by antonio damasio. in it damasio presents the somatic marker hypothesis which states that emotions guide behavior and decision-making. damasio argues that these somatic markers known collectively as gut feelings are intuitive signals that direct our decision making processes in a certain way that cannot be solved with rationality alone. damasio further argues that rationality requires emotional input in order to function.there are many religious traditions some of which are explicitly fideist and others of which claim varying degrees of rationalism. secular critics sometimes accuse all religious adherents of irrationality since they claim such adherents are guilty of ignoring suppressing or forbidding some kinds of reasoning concerning some subjects such as religious dogmas moral taboos etc.. though the theologies and religions such as classical monotheism typically do not claim to be irrational there is often a perceived conflict or tension between faith and tradition on the one hand and reason on the other as potentially competing sources of wisdom law and truth.religious adherents sometimes respond by arguing that faith and reason can be reconciled or have different non-overlapping domains or that critics engage in a similar kind of irrationalism:reconciliation: philosopher alvin plantinga argues that there is no real conflict between reason and classical theism because classical theism explains among other things why the universe is intelligible and why reason can successfully grasp it.non-overlapping magisteria: evolutionary biologist stephen jay gould argues that there need not be conflict between reason and religious belief because they are each authoritative in their own domain or magisterium. for example perhaps reason alone is not enough to explain such big questions as the origins of the universe the origin of life the origin of consciousness the foundation of morality or the destiny of the human race. if so reason can work on those problems over which it has authority while other sources of knowledge or opinion can have authority on the big questions.tu quoque: philosophers alasdair macintyre and charles taylor argue that those critics of traditional religion who are adherents of secular liberalism are also sometimes guilty of ignoring suppressing and forbidding some kinds of reasoning about subjects. similarly philosophers of science such as paul feyarabend argue that scientists sometimes ignore or suppress evidence contrary to the dominant paradigm.unification: theologian joseph ratzinger later benedict xvi asserted that christianity has understood itself as the religion of the logos as the religion according to reason referring to john :ἐν ἀρχῇ ἦν ὁ λόγος usually translated as in the beginning was the word logos. thus he said that the christian faith is open to all that is truly rational and that the rationality of western enlightenment is of christian origin.some commentators have claimed that western civilization can be almost defined by its serious testing of the limits of tension between unaided reason and faith in revealed truths—figuratively summarized as athens and jerusalem respectively. leo strauss spoke of a greater west that included all areas under the influence of the tension between greek rationalism and abrahamic revelation including the muslim lands. he was particularly influenced by the great muslim philosopher al-farabi. to consider to what extent eastern philosophy might have partaken of these important tensions strauss thought it best to consider whether dharma or tao may be equivalent to nature by which we mean physis in greek. according to strauss the beginning of philosophy involved the discovery or invention of nature and the pre-philosophical equivalent of nature was supplied by such notions as custom or ways which appear to be really universal in all times and places. the philosophical concept of nature or natures as a way of understanding archai first principles of knowledge brought about a peculiar tension between reasoning on the one hand and tradition or faith on the other.although there is this special history of debate concerning reason and faith in the islamic christian and jewish traditions the pursuit of reason is sometimes argued to be compatible with the other practice of other religions of a different nature such as hinduism because they do not define their tenets in such an absolute way.aristotle famously described reason with language as a part of human nature which means that it is best for humans to live politically meaning in communities of about the size and type of a small city state polis in greek. for example...it is clear then that a human being is more of a political politikon = of the polis animal zōion than is any bee or than any of those animals that live in herds. for nature as we say makes nothing in vain and humans are the only animals who possess reasoned speech logos. voice of course serves to indicate what is painful and pleasant; that is why it is also found in other animals because their nature has reached the point where they can perceive what is painful and pleasant and express these to each other. but speech logos serves to make plain what is advantageous and harmful and so also what is just and unjust. for it is a peculiarity of humans in contrast to the other animals to have perception of good and bad just and unjust and the like; and the community in these things makes a household or city polis. ... by nature then the drive for such a community exists in everyone but the first to set one up is responsible for things of very great goodness. for as humans are the best of all animals when perfected so they are the worst when divorced from law and right. the reason is that injustice is most difficult to deal with when furnished with weapons and the weapons a human being has are meant by nature to go along with prudence and virtue but it is only too possible to turn them to contrary uses. consequently if a human being lacks virtue he is the most unholy and savage thing and when it comes to sex and food the worst. but justice is something political to do with the polis for right is the arrangement of the political community and right is discrimination of what is just. aristotles politics a .. peter simpsons translation with greek terms inserted in square brackets.the concept of human nature being fixed in this way implied in other words that we can define what type of community is always best for people. this argument has remained a central argument in all political ethical and moral thinking since then and has become especially controversial since firstly rousseaus second discourse and secondly the theory of evolution. already in aristotle there was an awareness that the polis had not always existed and had needed to be invented or developed by humans themselves. the household came first and the first villages and cities were just extensions of that with the first cities being run as if they were still families with kings acting like fathers.friendship philia seems to prevail in man and woman according to nature kata phusin; for people are by nature tēi phusei pairing sunduastikon more than political politikon = of the polis in as much as the household oikos is prior proteron = earlier and more necessary than the polis and making children is more common koinoteron with the animals. in the other animals community koinōnia goes no further than this but people live together sumoikousin not only for the sake of making children but also for the things for life; for from the start the functions erga are divided and are different for man and woman. thus they supply each other putting their own into the common eis to koinon. it is for these reasons that both utility chrēsimon and pleasure hēdu seem to be found in this kind of friendship. nicomachean ethics viii..a. rough literal translation with greek terms shown in square brackets.rousseau in his second discourse finally took the shocking step of claiming that this traditional account has things in reverse: with reason language and rationally organized communities all having developed over a long period of time merely as a result of the fact that some habits of cooperation were found to solve certain types of problems and that once such cooperation became more important it forced people to develop increasingly complex cooperation—often only to defend themselves from each other.in other words according to rousseau reason language and rational community did not arise because of any conscious decision or plan by humans or gods nor because of any pre-existing human nature. as a result he claimed living together in rationally organized communities like modern humans is a development with many negative aspects compared to the original state of man as an ape. if anything is specifically human in this theory it is the flexibility and adaptability of humans. this view of the animal origins of distinctive human characteristics later received support from charles darwins theory of evolution.the two competing theories concerning the origins of reason are relevant to political and ethical thought because according to the aristotelian theory a best way of living together exists independently of historical circumstances. according to rousseau we should even doubt that reason language and politics are a good thing as opposed to being simply the best option given the particular course of events that lead to today. rousseaus theory that human nature is malleable rather than fixed is often taken to imply for example by karl marx a wider range of possible ways of living together than traditionally known.however while rousseaus initial impact encouraged bloody revolutions against traditional politics including both the french revolution and the russian revolution his own conclusions about the best forms of community seem to have been remarkably classical in favor of city-states such as geneva and rural living.scientific research into reasoning is carried out within the fields of psychology and cognitive science. psychologists attempt to determine whether or not people are capable of rational thought in a number of different circumstances.assessing how well someone engages in reasoning is the project of determining the extent to which the person is rational or acts rationally. it is a key research question in the psychology of reasoning. rationality is often divided into its respective theoretical and practical counterparts.behavioral experiments on human reasoningexperimental cognitive psychologists carry out research on reasoning behaviour. such research may focus for example on how people perform on tests of reasoning such as intelligence or iq tests or on how well peoples reasoning matches ideals set by logic see for example the wason test. experiments examine how people make inferences from conditionals e.g. if a then b and how they make inferences about alternatives e.g. a or else b. they test whether people can make valid deductions about spatial and temporal relations e.g. a is to the left of b or a happens after b and about quantified assertions e.g. all the a are b. experiments investigate how people make inferences about factual situations hypothetical possibilities probabilities and counterfactual situations.developmental psychologists investigate the development of reasoning from birth to adulthood. piagets theory of cognitive development was the first complete theory of reasoning development. subsequently several alternative theories were proposed including the neo-piagetian theories of cognitive development.the biological functioning of the brain is studied by neurophysiologists and neuropsychologists. research in this area includes research into the structure and function of normally functioning brains and of damaged or otherwise unusual brains. in addition to carrying out research into reasoning some psychologists for example clinical psychologists and psychotherapists work to alter peoples reasoning habits when they are unhelpful.in artificial intelligence and computer science scientists study and use automated reasoning for diverse applications including automated theorem proving the formal semantics of programming languages and formal specification in software engineering.meta-reasoning is reasoning about reasoning. in computer science a system performs meta-reasoning when it is reasoning about its own operation. this requires a programming language capable of reflection the ability to observe and modify its own structure and behaviour.dan sperber believes that reasoning in groups is more effective and promotes their evolutionary fitness.a species could benefit greatly from better abilities to reason about predict and understand the world. french social and cognitive scientists dan sperber and hugo mercier argue that there could have been other forces driving the evolution of reason. they point out that reasoning is very difficult for humans to do effectively and that it is hard for individuals to doubt their own beliefs confirmation bias. reasoning is most effective when it is done as a collective – as demonstrated by the success of projects like science. they suggest that there are not just individual but group selection pressures at play. any group that managed to find ways of reasoning effectively would reap benefits for all its members increasing their fitness. this could also help explain why humans according to sperber are not optimized to reason effectively alone. their argumentative theory of reasoning claims that reason may have more to do with winning arguments than with the search for the truth.critical thinking is the analysis of facts to form a judgment. the subject is complex and several different definitions exist which generally include the rational skeptical unbiased analysis or evaluation of factual evidence. critical thinking is self-directed self-disciplined self-monitored and self-corrective thinking. it presupposes assent to rigorous standards of excellence and mindful command of their use. it entails effective communication and problem-solving abilities as well as a commitment to overcome native egocentrism and sociocentrism.the earliest records of critical thinking are the teachings of socrates recorded by plato. these included a part in platos early dialogues where socrates engages with one or more interlocutors on the issue of ethics such as question whether it was right for socrates to escape from prison. the philosopher considered and reflected on this question and came to the conclusion that escape violates all the things that he holds higher than himself: the laws of athens and the guiding voice that socrates claims to hear.socrates established the fact that one cannot depend upon those in authority to have sound knowledge and insight. he demonstrated that persons may have power and high position and yet be deeply confused and irrational. socrates maintained that for an individual to have a good life or to have one that is worth living he must be critical questioner or must have an interrogative soul. he established the importance of asking deep questions that probe profoundly into thinking before we accept ideas as worthy of belief.socrates established the importance of seeking evidence closely examining reasoning and assumptions analyzing basic concepts and tracing out implications not only of what is said but of what is done as well. his method of questioning is now known as socratic questioning and is the best known critical thinking teaching strategy. in his mode of questioning socrates highlighted the need for thinking for clarity and logical consistency. he asked people questions to reveal their irrational thinking or lack of reliable knowledge. socrates demonstrated that having authority does not ensure accurate knowledge. he established the method of questioning beliefs closely inspecting assumptions and relying on evidence and sound rationale. plato recorded socrates teachings and carried on the tradition of critical thinking. aristotle and subsequent greek skeptics refined socrates teachings using systematic thinking and asking questions to ascertain the true nature of reality beyond the way things appear from a glance.socrates set the agenda for the tradition of critical thinking namely to reflectively question common beliefs and explanations carefully distinguishing beliefs that are reasonable and logical from those that—however appealing to our native egocentrism however much they serve our vested interests however comfortable or comforting they may be—lack adequate evidence or rational foundation to warrant belief.critical thinking was described by richard w. paul as a movement in two waves . the first wave of critical thinking is often referred to as a critical analysis that is clear rational thinking involving critique. its details vary amongst those who define it. according to barry k. beyer  critical thinking means making clear reasoned judgments. during the process of critical thinking ideas should be reasoned well thought out and judged. the u.s. national council for excellence in critical thinking defines critical thinking as the intellectually disciplined process of actively and skillfully conceptualizing applying analyzing synthesizing or evaluating information gathered from or generated by observation experience reflection reasoning or communication as a guide to belief and action.in the term critical thinking the word critical grk. κριτικός = kritikos = critic derives from the word critic and implies a critique; it identifies the intellectual capacity and the means of judging of judgement for judging and of being able to discern. the intellectual roots of critical thinking are as ancient as its etymology traceable ultimately to the teaching practice and vision of socrates  years ago who discovered by a method of probing questioning that people could not rationally justify their confident claims to knowledge.traditionally critical thinking has been variously defined as follows:the process of actively and skillfully conceptualizing applying analyzing synthesizing and evaluating information to reach an answer or conclusiondisciplined thinking that is clear rational open-minded and informed by evidencepurposeful self-regulatory judgment which results in interpretation analysis evaluation and inference as well as explanation of the evidential conceptual methodological criteriological or contextual considerations upon which that judgment is basedincludes a commitment to using reason in the formulation of our beliefsthe skill and propensity to engage in an activity with reflective scepticism mcpeck thinking about ones thinking in a manner designed to organize and clarify raise the efficiency of and recognize errors and biases in ones own thinking. critical thinking is not hard thinking nor is it directed at solving problems other than improving ones own thinking. critical thinking is inward-directed with the intent of maximizing the rationality of the thinker. one does not use critical thinking to solve problems—one uses critical thinking to improve ones process of thinking.an appraisal based on careful analytical evaluationcritical thinking is a type of thinking pattern that requires people to be reflective and pay attention to decision-making which guides their beliefs and actions. critical thinking allows people to deduct with more logic to process sophisticated information and to look at various sides of issues so that they can produce more solid conclusions.critical thinking has seven critical features: being inquisitive and curious being open-minded to different sides being able to think systematically being analytical being persistent to truth being confident about critical thinking itself and lastly being mature.although critical thinking could be defined in several different ways there is a general agreement in its key component—the desire to reach for a satisfactory result and this should be achieved by rational thinking and result-driven manner. halpern thinks that critical thinking firstly involves learned abilities such as problem-solving calculation and successful probability application. it also includes a tendency to engage the thinking process. in recent times stanovich believed that modern iq test could hardly measure the ability of critical thinking.contemporary critical thinking scholars have expanded these traditional definitions to include qualities concepts and processes such as creativity imagination discovery reflection empathy connecting knowing feminist theory subjectivity ambiguity and inconclusiveness. some definitions of critical thinking exclude these subjective practices.according to ennis critical thinking is the intellectually disciplined process of actively and skillfully conceptualizing applying analyzing synthesizing and/or evaluating information gathered from or generated by observation experience reflection reasoning or communication as a guide to belief and action. this definition ennis provided is highly agreed by harvey siegel peter facione and deanna kuhn.according to the definition by ennis critical thinking requires a lot of attention and brain function. when critical thinking approach toward education it will help the students brain to be more function-able and understand texts differently.critical thinking can be specifically identified into many different portions different fields of student requires different types of critical thinking. critical thinking provides more angles and perspectives upon the same materialthe study of logical argumentation is relevant to the study of critical thinking. logic is concerned with the analysis of arguments including the appraisal of their correctness or incorrectness. in the field of epistemology critical thinking is considered to be logically correct thinking which allows for differentiation between logically true and logically false statements.in first wave logical thinking the thinker is removed from the train of thought and the analysis of connections between concepts or points in thought is ostencibly free of any bias. in his essay beyond logicism in critical thinking kerry s. walters describes this ideology thus: a logistic approach to critical thinking conveys the message to students that thinking is legitimate only when it conforms to the procedures of informal and to a lesser extent formal logic and that the good thinker necessarily aims for styles of examination and appraisal that are analytical abstract universal and objective. this model of thinking has become so entrenched in conventional academic wisdom that many educators accept it as canon. such principles are concomitant with the increasing dependence on a quantitative understanding of the world.in the second wave of critical thinking authors consciously moved away from the logocentric mode of critical thinking characteristic of the first wave. although many scholars began to take a less exclusive view of what constitutes critical thinking rationality and logic remain widely accepted as essential bases for critical thinking. walters argues that exclusive logicism in the first wave sense is based on the unwarranted assumption that good thinking is reducible to logical thinking.there are three types of logical reasoning. informally two kinds of logical reasoning can be distinguished in addition to formal deduction which are induction and abduction.deductiondeduction is the conclusion drawn from the structure of an arguments premises by use of rules of inference formally those of propositional calculus. for example: x is human and all humans have a face so x has a face.inductioninduction is drawing a conclusion from a pattern that is guaranteed by the strictness of the structure to which it applies. for example: the sum of even integers is even. let {\displaystyle xyz\in \mathbb {z} }{\displaystyle xyz\in \mathbb {z} } then {\displaystyle xyz}{\displaystyle xyz} are even by definition. {\displaystyle x+y=x+y=z}{\displaystyle x+y=x+y=z} which is even; so summing two even numbers results in an even number.abductionabduction is drawing a conclusion using a heuristic that is likely but not inevitable given some foreknowledge. for example: i observe sheep in a field and they appear white from my viewing angle so sheep are white. contrast with the deductive statement: some sheep are white on at least one side.critical thinking and rationalitykerry s. walters an emeritus philosophy professor from gettysburg college argues that rationality demands more than just logical or traditional methods of problem solving and analysis or what he calls the calculus of justification but also considers cognitive acts such as imagination conceptual creativity intuition and insight p. . these functions are focused on discovery on more abstract processes instead of linear rules-based approaches to problem-solving. the linear and non-sequential mind must both be engaged in the rational mind.the ability to critically analyze an argument—to dissect structure and components thesis and reasons—is essential. but so is the ability to be flexible and consider non-traditional alternatives and perspectives. these complementary functions are what allow for critical thinking to be a practice encompassing imagination and intuition in cooperation with traditional modes of deductive inquiry.functionsthe list of core critical thinking skills includes observation interpretation analysis inference evaluation explanation and metacognition. according to reynolds  an individual or group engaged in a strong way of critical thinking gives due consideration to establish for instance:evidence through realitycontext skills to isolate the problem from contextrelevant criteria for making the judgment wellapplicable methods or techniques for forming the judgmentapplicable theoretical constructs for understanding the problem and the question at handin addition to possessing strong critical-thinking skills one must be disposed to engage problems and decisions using those skills. critical thinking employs not only logic but broad intellectual criteria such as clarity credibility accuracy precision relevance depth breadth significance and fairness.critical thinking calls for the ability to:recognize problems to find workable means for meeting those problemsunderstand the importance of prioritization and order of precedence in problem-solvinggather and marshal pertinent relevant informationrecognize unstated assumptions and valuescomprehend and use language with accuracy clarity and discernmentinterpret data to appraise evidence and evaluate argumentsrecognize the existence or non-existence of logical relationships between propositionsdraw warranted conclusions and generalizationsput to test the conclusions and generalizations at which one arrivesreconstruct ones patterns of beliefs on the basis of wider experiencerender accurate judgments about specific things and qualities in everyday lifein sum:a persistent effort to examine any belief or supposed form of knowledge in the light of the evidence that supports or refutes it and the further conclusions to which it tends.the habits of mind that characterize a person strongly disposed toward critical thinking include a desire to follow reason and evidence wherever they may lead a systematic approach to problem solving inquisitiveness even-handedness and confidence in reasoning.according to a definition analysis by kompf & bond  critical thinking involves problem solving decision making metacognition rationality rational thinking reasoning knowledge intelligence and also a moral component such as reflective thinking. critical thinkers therefore need to have reached a level of maturity in their development possess a certain attitude as well as a set of taught skills.there is a postulation by some writers that the tendencies from habits of mind should be thought as virtues to demonstrate the characteristics of a critical thinker. these intellectual virtues are ethical qualities that encourage motivation to think in particular ways towards specific circumstances. however these virtues have also been criticized by skeptics who argue that there is lacking evidence for this specific mental basis that are causative to critical thinking.edward m. glaser proposed that the ability to think critically involves three elements:an attitude of being disposed to consider in a thoughtful way the problems and subjects that come within the range of ones experiencesknowledge of the methods of logical inquiry and reasoningsome skill in applying those methods.educational programs aimed at developing critical thinking in children and adult learners individually or in group problem solving and decision making contexts continue to address these same three central elements.the critical thinking project at human science lab london is involved in the scientific study of all major educational systems in prevalence today to assess how the systems are working to promote or impede critical thinking.contemporary cognitive psychology regards human reasoning as a complex process that is both reactive and reflective. this presents a problem which is detailed as a division of a critical mind in juxtaposition to sensory data and memory.the psychological theory disposes of the absolute nature of the rational mind in reference to conditions abstract problems and discursive limitations. where the relationship between critical thinking skills and critical thinking dispositions is an empirical question the ability to attain causal domination exists for which socrates was known to be largely disposed against as the practice of sophistry. accounting for a measure of critical thinking dispositions is the california measure of mental motivation and the california critical thinking dispositions inventory. the critical thinking toolkit is an alternative measure that examines student beliefs and attitudes about critical thinkingjohn dewey is one of many educational leaders who recognized that a curriculum aimed at building thinking skills would benefit the individual learner the community and the entire democracy.critical thinking is significant in the learning process of internalization in the construction of basic ideas principles and theories inherent in content. and critical thinking is significant in the learning process of application whereby those ideas principles and theories are implemented effectively as they become relevant in learners lives.each discipline adapts its use of critical thinking concepts and principles. the core concepts are always there but they are embedded in subject-specific content. for students to learn content intellectual engagement is crucial. all students must do their own thinking their own construction of knowledge. good teachers recognize this and therefore focus on the questions readings activities that stimulate the mind to take ownership of key concepts and principles underlying the subject.historically the teaching of critical thinking focused only on logical procedures such as formal and informal logic. this emphasized to students that good thinking is equivalent to logical thinking. however a second wave of critical thinking urges educators to value conventional techniques meanwhile expanding what it means to be a critical thinker. in  kerry walters compiled a conglomeration of sources surpassing this logical restriction to include many different authors research regarding connected knowing empathy gender-sensitive ideals collaboration world views intellectual autonomy morality and enlightenment. these concepts invite students to incorporate their own perspectives and experiences into their thinking.in the english and welsh school systems critical thinking is offered as a subject that - to -year-olds can take as an a-level. under the ocr exam board students can sit two exam papers for the as: credibility of evidence and assessing and developing argument. the full advanced gce is now available: in addition to the two as units candidates sit the two papers resolution of dilemmas and critical reasoning. the a-level tests candidates on their ability to think critically about and analyze arguments on their deductive or inductive validity as well as producing their own arguments. it also tests their ability to analyze certain related topics such as credibility and ethical decision-making. however due to its comparative lack of subject content many universities do not accept it as a main a-level for admissions. nevertheless the as is often useful in developing reasoning skills and the full advanced gce is useful for degree courses in politics philosophy history or theology providing the skills required for critical analysis that are useful for example in biblical study.there used to also be an advanced extension award offered in critical thinking in the uk open to any a-level student regardless of whether they have the critical thinking a-level. cambridge international examinations have an a-level in thinking skills.from  assessment and qualifications alliance has also been offering an a-level critical thinking specification. ocr exam board have also modified theirs for . many examinations for university entrance set by universities on top of a-level examinations also include a critical thinking component such as the lnat the ukcat the biomedical admissions test and the thinking skills assessment.in qatar critical thinking was offered by al-bairaq—an outreach non-traditional educational program that targets high school students and focuses on a curriculum based on stem fields. the idea behind al-bairaq is to offer high school students the opportunity to connect with the research environment in the center for advanced materials cam at qatar university. faculty members train and mentor the students and help develop and enhance their critical thinking problem-solving and teamwork skills.failed verificationin  a meta-analysis of the literature on teaching effectiveness in higher education was undertaken. the study noted concerns from higher education politicians and business that higher education was failing to meet societys requirements for well-educated citizens. it concluded that although faculty may aspire to develop students thinking skills in practice they have tended to aim at facts and concepts utilizing lowest levels of cognition rather than developing intellect or values.in a more recent meta-analysis researchers reviewed  quasi- or true-experimental studies all of which used some form of standardized critical thinking measure to assess the outcome variable. the authors describe the various methodological approaches and attempt to categorize the differing assessment tools which include standardized tests and second-source measures tests developed by teachers tests developed by researchers and tests developed by teachers who also serve the role as the researcher. the results emphasized the need for exposing students to real-world problems and the importance of encouraging open dialogue within a supportive environment. effective strategies for teaching critical thinking are thought to be possible in a wide variety of educational settings. one attempt to assess the humanities role in teaching critical thinking and reducing belief in pseudoscientific claims was made at north carolina state university. some success was noted and the researchers emphasized the value of the humanities in providing the skills to evaluate current events and qualitative data in context.scott lilienfeld notes that there is some evidence to suggest that basic critical thinking skills might be successfully taught to children at a younger age than previously thought.critical thinking is an important element of all professional fields and academic disciplines by referencing their respective sets of permissible questions evidence sources criteria etc.. within the framework of scientific skepticism the process of critical thinking involves the careful acquisition and interpretation of information and use of it to reach a well-justified conclusion. the concepts and principles of critical thinking can be applied to any context or case but only by reflecting upon the nature of that application. critical thinking forms therefore a system of related and overlapping modes of thought such as anthropological thinking sociological thinking historical thinking political thinking psychological thinking philosophical thinking mathematical thinking chemical thinking biological thinking ecological thinking legal thinking ethical thinking musical thinking thinking like a painter sculptor engineer business person etc. in other words though critical thinking principles are universal their application to disciplines requires a process of reflective contextualization. psychology offerings for example have included courses such as critical thinking about the paranormal in which students are subjected to a series of cold readings and tested on their belief of the psychic who is eventually announced to be a fake.critical thinking is considered important in the academic fields for enabling one to analyze evaluate explain and restructure thinking thereby ensuring the act of thinking without false belief. however even with knowledge of the methods of logical inquiry and reasoning mistakes occur and due to a thinkers inability to apply the methodology consistently and because of overruling character traits such as egocentrism. critical thinking includes identification of prejudice bias propaganda self-deception distortion misinformation etc. given research in cognitive psychology some educators believe that schools should focus on teaching their students critical thinking skills and cultivation of intellectual traits.critical thinking skills can be used to help nurses during the assessment process. through the use of critical thinking nurses can question evaluate and reconstruct the nursing care process by challenging the established theory and practice. critical thinking skills can help nurses problem solve reflect and make a conclusive decision about the current situation they face. critical thinking creates new possibilities for the development of the nursing knowledge. due to the sociocultural environmental and political issues that are affecting healthcare delivery it would be helpful to embody new techniques in nursing. nurses can also engage their critical thinking skills through the socratic method of dialogue and reflection. this practice standard is even part of some regulatory organizations such as the college of nurses of ontarios professional standards for continuing competencies . it requires nurses to engage in reflective practice and keep records of this continued professional development for possible review by the college.critical thinking is also considered important for human rights education for toleration. the declaration of principles on tolerance adopted by unesco in  affirms that education for tolerance could aim at countering factors that lead to fear and exclusion of others and could help young people to develop capacities for independent judgement critical thinking and ethical reasoning.the advent and rising popularity of online courses have prompted some to ask if computer-mediated communication cmc promotes hinders or has no effect on the amount and quality of critical thinking in a course relative to face-to-face communication. there is some evidence to suggest a fourth more nuanced possibility: that cmc may promote some aspects of critical thinking but hinder others. for example guiller et al.  found that relative to face-to-face discourse online discourse featured more justifications while face-to-face discourse featured more instances of students expanding on what others had said. the increase in justifications may be due to the asynchronous nature of online discussions while the increase in expanding comments may be due to the spontaneity of real-time discussion. newman et al.  showed similar differential effects. they found that while cmc boasted more important statements and linking of ideas it lacked novelty. the authors suggest that this may be due to difficulties participating in a brainstorming-style activity in an asynchronous environment. rather the asynchrony may promote users to put forth considered thought out contributions.researchers assessing critical thinking in online discussion forums often employ a technique called content analysis where the text of online discourse or the transcription of face-to-face discourse is systematically coded for different kinds of statements relating to critical thinking. for example a statement might be coded as discuss ambiguities to clear them up or welcoming outside knowledge as positive indicators of critical thinking. conversely statements reflecting poor critical thinking may be labeled as sticking to prejudice or assumptions or squashing attempts to bring in outside knowledge. the frequency of these codes in cmc and face-to-face discourse can be compared to draw conclusions about the quality of critical thinking.searching for evidence of critical thinking in discourse has roots in a definition of critical thinking put forth by kuhn  which emphasizes the social nature of discussion and knowledge construction. there is limited research on the role of social experience in critical thinking development but there is some evidence to suggest it is an important factor. for example research has shown that - to -year-old children can discern to some extent the differential creditability and expertise of individuals. further evidence for the impact of social experience on the development of critical thinking skills comes from work that found that - to -year-olds from china have similar levels of skepticism to - and -year-olds in the united states. if the development of critical thinking skills was solely due to maturation it is unlikely we would see such dramatic differences across cultures.abstraction in its main sense is a conceptual process where general rules and concepts are derived from the usage and classification of specific examples literal real or concrete signifiers first principles or other methods.an abstraction is the outcome of this process—a concept that acts as a common noun for all subordinate concepts and connects any related concepts as a group field or category.conceptual abstractions may be formed by filtering the information content of a concept or an observable phenomenon selecting only the aspects which are relevant for a particular subjectively valued purpose. for example abstracting a leather soccer ball to the more general idea of a ball selects only the information on general ball attributes and behavior excluding but not eliminating the other phenomenal and cognitive characteristics of that particular ball. in a type–token distinction a type e.g. a ball is more abstract than its tokens e.g. that leather soccer ball.abstraction in its secondary use is a material process discussed in the themes below.thinking in abstractions is considered by anthropologists archaeologists and sociologists to be one of the key traits in modern human behaviour which is believed to have developed between  and  years ago. its development is likely to have been closely connected with the development of human language which whether spoken or written appears to both involve and facilitate abstract thinking.abstraction involves induction of ideas or the synthesis of particular facts into one general theory about something. it is the opposite of specification which is the analysis or breaking-down of a general idea or abstraction into concrete facts. abstraction can be illustrated with francis bacons novum organum  a book of modern scientific philosophy written in the late jacobean era of england to encourage modern thinkers to collect specific facts before making any generalizations.bacon used and promoted induction as an abstraction tool and it countered the ancient deductive-thinking approach that had dominated the intellectual world since the times of greek philosophers like thales anaximander and aristotle. thales c. – bce believed that everything in the universe comes from one main substance water. he deduced or specified from a general idea everything is water to the specific forms of water such as ice snow fog and rivers.modern scientists can also use the opposite approach of abstraction or going from particular facts collected into one general idea such as the motion of the planets newton –. when determining that the sun is the center of our solar system copernicus – scientists had to utilize thousands of measurements to finally conclude that mars moves in an elliptical orbit about the sun kepler – or to assemble multiple specific facts into the law of falling bodies galileo –.an abstraction can be seen as a compression process mapping multiple different pieces of constituent data to a single piece of abstract data; based on similarities in the constituent data for example many different physical cats map to the abstraction cat. this conceptual scheme emphasizes the inherent equality of both constituent and abstract data thus avoiding problems arising from the distinction between abstract and concrete. in this sense the process of abstraction entails the identification of similarities between objects and the process of associating these objects with an abstraction which is itself an object.for example picture  below illustrates the concrete relationship cat sits on mat.chains of abstractions can be construed moving from neural impulses arising from sensory perception to basic abstractions such as color or shape to experiential abstractions such as a specific cat to semantic abstractions such as the idea of a cat to classes of objects such as mammals and even categories such as object as opposed to action.for example graph  below expresses the abstraction agent sits on location. this conceptual scheme entails no specific hierarchical taxonomy such as the one mentioned involving cats and mammals only a progressive exclusion of detail.instantiationnon-existent things in any particular place and time are often seen as abstract. by contrast instances or members of such an abstract thing might exist in many different places and times.those abstract things are then said to be multiply instantiated in the sense of picture  picture  etc. shown below. it is not sufficient however to define abstract ideas as those that can be instantiated and to define abstraction as the movement in the opposite direction to instantiation. doing so would make the concepts cat and telephone abstract ideas since despite their varying appearances a particular cat or a particular telephone is an instance of the concept cat or the concept telephone. although the concepts cat and telephone are abstractions they are not abstract in the sense of the objects in graph  below. we might look at other graphs in a progression from cat to mammal to animal and see that animal is more abstract than mammal; but on the other hand mammal is a harder idea to express certainly in relation to marsupial or monotreme.perhaps confusingly some philosophies refer to tropes instances of properties as abstract particulars—e.g. the particular redness of a particular apple is an abstract particular. this is similar to qualia and sumbebekos.still retaining the primary meaning of abstrere or to draw away from the abstraction of money for example works by drawing away from the particular value of things allowing completely incommensurate objects to be compared see the section on physicality below. karl marxs writing on the commodity abstraction recognizes a parallel process.the state polity as both concept and material practice exemplifies the two sides of this process of abstraction. conceptually the current concept of the state is an abstraction from the much more concrete early-modern use as the standing or status of the prince his visible estates. at the same time materially the practice of statehood is now constitutively and materially more abstract than at the time when princes ruled as the embodiment of extended power.the way that physical objects like rocks and trees have being differs from the way that properties of abstract concepts or relations have being for example the way the concrete particular individuals pictured in picture  exist differs from the way the concepts illustrated in graph  exist. that difference accounts for the ontological usefulness of the word abstract. the word applies to properties and relations to mark the fact that if they exist they do not exist in space or time but that instances of them can exist potentially in many different places and times.further information: history of accounting § ancient historya physical object a possible referent of a concept or word is considered concrete not abstract if it is a particular individual that occupies a particular place and time. however in the secondary sense of the term abstraction this physical object can carry materially abstracting processes. for example record-keeping aids throughout the fertile crescent included calculi clay spheres cones etc. which represented counts of items probably livestock or grains sealed in containers. according to schmandt-besserat &  these clay containers contained tokens the total of which were the count of objects being transferred. the containers thus served as something of a bill of lading or an accounts book. in order to avoid breaking open the containers for the count marks were placed on the outside of the containers. these physical marks in other words acted as material abstractions of a materially abstract process of accounting using conceptual abstractions numbers to communicate its meaning.abstract things are sometimes defined as those things that do not exist in reality or exist only as sensory experiences like the color red. that definition however suffers from the difficulty of deciding which things are real i.e. which things exist in reality. for example it is difficult to agree to whether concepts like god the number three and goodness are real abstract or both.an approach to resolving such difficulty is to use predicates as a general term for whether things are variously real abstract concrete or of a particular property e.g. good. questions about the properties of things are then propositions about predicates which propositions remain to be evaluated by the investigator. in the graph  below the graphical relationships like the arrows joining boxes and ellipses might denote predicates.abstractions sometimes have ambiguous referents; for example happiness when used as an abstraction can refer to as many things as there are people and events or states of being which make them happy. likewise architecture refers not only to the design of safe functional buildings but also to elements of creation and innovation which aim at elegant solutions to construction problems to the use of space and to the attempt to evoke an emotional response in the builders owners viewers and users of the building.abstraction uses a strategy of simplification wherein formerly concrete details are left ambiguous vague or undefined; thus effective communication about things in the abstract requires an intuitive or common experience between the communicator and the communication recipient. this is true for all verbal/abstract communication.for example many different things can be red. likewise many things sit on surfaces as in picture  to the right. the property of redness and the relation sitting-on are therefore abstractions of those objects. specifically the conceptual diagram graph  identifies only three boxes two ellipses and four arrows and their five labels whereas the picture  shows much more pictorial detail with the scores of implied relationships as implicit in the picture rather than with the nine explicit details in the graph.graph  details some explicit relationships between the objects of the diagram. for example the arrow between the agent and cat:elsie depicts an example of an is-a relationship as does the arrow between the location and the mat. the arrows between the gerund/present participle sitting and the nouns agent and location express the diagrams basic relationship; agent is sitting on location; elsie is an instance of cat.although the description sitting-on graph  is more abstract than the graphic image of a cat sitting on a mat picture  the delineation of abstract things from concrete things is somewhat ambiguous; this ambiguity or vagueness is characteristic of abstraction. thus something as simple as a newspaper might be specified to six levels as in douglas hofstadters illustration of that ambiguity with a progression from abstract to concrete in gödel escher bach :an abstraction can thus encapsulate each of these levels of detail with no loss of generality. but perhaps a detective or philosopher/scientist/engineer might seek to learn about something at progressively deeper levels of detail to solve a crime or a puzzle.in philosophical terminology abstraction is the thought process wherein ideas are distanced from objects.typically abstraction is used in the arts as a synonym for abstract art in general. strictly speaking it refers to art unconcerned with the literal depiction of things from the visible world—it can however refer to an object or image which has been distilled from the real world or indeed another work of art. artwork that reshapes the natural world for expressive purposes is called abstract; that which derives from but does not imitate a recognizable subject is called nonobjective abstraction. in the th century the trend toward abstraction coincided with advances in science technology and changes in urban life eventually reflecting an interest in psychoanalytic theory. later still abstraction was manifest in more purely formal terms such as color freedom from objective context and a reduction of form to basic geometric designs.computer scientists use abstraction to make models that can be used and re-used without having to re-write all the program code for each new application on every different type of computer. they communicate their solutions with the computer by writing source code in some particular computer language which can be translated into machine code for different types of computers to execute. abstraction allows program designers to separate a framework categorical concepts related to computing problems from specific instances which implement details. this means that the program code can be written so that code doesnt have to depend on the specific details of supporting applications operating system software or hardware but on a categorical concept of the solution. a solution to the problem can then be integrated into the system framework with minimal additional work. this allows programmers to take advantage of another programmers work while requiring only an abstract understanding of the implementation of anothers work apart from the problem that it solves.abstractions and levels of abstraction play an important role in the theory of general semantics originated by alfred korzybski. anatol rapoport wrote: abstracting is a mechanism by which an infinite variety of experiences can be mapped on short noises words.francis fukuyama defines history as a deliberate attempt of abstraction in which we separate out important from unimportant events.researchers in linguistics frequently apply abstraction so as to allow analysis of the phenomena of language at the desired level of detail. a commonly used abstraction the phoneme abstracts speech sounds in such a way as to neglect details that cannot serve to differentiate meaning. other analogous kinds of abstractions sometimes called emic units considered by linguists include morphemes graphemes and lexemes.abstraction also arises in the relation between syntax semantics and pragmatics. pragmatics involves considerations that make reference to the user of the language; semantics considers expressions and what they denote the designata abstracted from the language user; and syntax considers only the expressions themselves abstracted from the designata.abstraction in mathematics is the process of extracting the underlying structures patterns or properties of a mathematical concept or object removing any dependence on real world objects with which it might originally have been connected and generalizing it so that it has wider applications or matching among other abstract descriptions of equivalent phenomena.the advantages of abstraction in mathematics are:it reveals deep connections between different areas of mathematics.known results in one area can suggest conjectures in another related area.techniques and methods from one area can be applied to prove results in other related area.patterns from one mathematical object can be generalized to other similar objects in the same class.the main disadvantage of abstraction is that highly abstract concepts are more difficult to learn and might require a degree of mathematical maturity and experience before they can be assimilated.in music the term abstraction can be used to describe improvisatory approaches to interpretation and may sometimes indicate abandonment of tonality. atonal music has no key signature and is characterized by the exploration of internal numeric relationships.further information: intelligence mental rotation and mental operationsa recent meta-analysis suggests that the verbal system has greater engagement for abstract concepts when the perceptual system is more engaged for processing of concrete concepts. this is because abstract concepts elicit greater brain activity in the inferior frontal gyrus and middle temporal gyrus compared to concrete concepts which elicit greater activity in the posterior cingulate precuneus fusiform gyrus and parahippocampal gyrus. other research into the human brain suggests that the left and right hemispheres differ in their handling of abstraction. for example one meta-analysis reviewing human brain lesions has shown a left hemisphere bias during tool usage.abstraction in philosophy is the process or to some the alleged process in concept formation of recognizing some set of common features in individuals and on that basis forming a concept of that feature. the notion of abstraction is important to understanding some philosophical controversies surrounding empiricism and the problem of universals. it has also recently become popular in formal logic under predicate abstraction. another philosophical tool for discussion of abstraction is thought space.john locke defined abstraction in an essay concerning human understanding:so words are used to stand as outward marks of our internal ideas which are taken from particular things; but if every particular idea that we take in had its own special name there would be no end to names. to prevent this the mind makes particular ideas received from particular things become general; which it does by considering them as they are in the mind—mental appearances—separate from all other existences and from the circumstances of real existence such as time place and so on. this procedure is called abstraction. in it an idea taken from a particular thing becomes a general representative of all of the same kind and its name becomes a general name that is applicable to any existing thing that fits that abstract idea. ..carl jungs definition of abstraction broadened its scope beyond the thinking process to include exactly four mutually exclusive different complementary psychological functions: sensation intuition feeling and thinking. together they form a structural totality of the differentiating abstraction process. abstraction operates in one of these functions when it excludes the simultaneous influence of the other functions and other irrelevancies such as emotion. abstraction requires selective use of this structural split of abilities in the psyche. the opposite of abstraction is concretism. abstraction is one of jungs  definitions in chapter xi of psychological types.there is an abstract thinking just as there is abstract feeling sensation and intuition. abstract thinking singles out the rational logical qualities ... abstract feeling does the same with ... its feeling-values. ... i put abstract feelings on the same level as abstract thoughts. ... abstract sensation would be aesthetic as opposed to sensuous sensation and abstract intuition would be symbolic as opposed to fantastic intuition. jung  : par. .in social theory abstraction is used as both an ideational and material process. alfred sohn-rethel asked can there be abstraction other than by thought he used the example of commodity abstraction to show that abstraction occurs in practice as people create systems of abstract exchange that extend beyond the immediate physicality of the object and yet have real and immediate consequences. this work was extended through the constitutive abstraction approach of writers associated with the journal arena. two books that have taken this theme of the abstraction of social relations as an organizing process in human history are nation formation: towards a theory of abstract community. and the second volume of towards a theory of abstract community published in : globalism nationalism tribalism: bringing theory back in – volume  of towards a theory of abstract community. these books argue that the nation is an abstract community bringing together strangers who will never meet as such; thus constituting materially real and substantial but abstracted and mediated relations. the books suggest that contemporary processes of globalization and mediatization have contributed to materially abstracting relations between people with major consequences for how we live our lives.it can be easily argued that abstraction is an elementary methodological tool in several disciplines of social science. these disciplines have definite and different man concepts that highlight those aspects of man and his behaviour by idealization that are relevant for the given human science. for example homo sociologicus is the man as sociology abstracts and idealizes it depicting man as a social being. moreover we could talk about homo cyber sapiens the man who can extend his biologically determined intelligence thanks to new technologies or homo creativus who is simply creative.abstraction combined with weberian idealization plays a crucial role in economics. breaking away from directly experienced reality was a common trend in th century sciences especially physics and this was the effort which was fundamentally determined the way economics tried and still tries to approach the economic aspects of social life. it is abstraction we meet in the case of both newtons physics and the neoclassical theory since the goal was to grasp the unchangeable and timeless essence of phenomena. for example newton created the concept of the material point by following the abstraction method so that he abstracted from the dimension and shape of any perceptible object preserving only inertial and translational motion. material point is the ultimate and common feature of all bodies. neoclassical economists created the indefinitely abstract notion of homo economicus by following the same procedure. economists abstract from all individual and personal qualities in order to get to those characteristics that embody the essence of economic activity. eventually it is the substance of the economic man that they try to grasp. any characteristic beyond it only disturbs the functioning of this essential core.a picture of a lightbulb is associated to someone having an idea a sign of creativity.creativity is a phenomenon whereby something new and somehow valuable is formed. the created item may be intangible such as an idea a scientific theory a musical composition or a joke or a physical object such as an invention a printed literary work or a painting.scholarly interest in creativity is found in a number of disciplines primarily psychology business studies and cognitive science but also education technology engineering philosophy particularly philosophy of science theology sociology linguistics economics and mathematics covering the relations between creativity and general intelligence personality type mental and neural processes mental health or artificial intelligence; the potential for fostering creativity through education and training; the fostering of creativity for national economic benefit and the application of creative resources to improve the effectiveness of teaching and learning.the english word creativity comes from the latin term creare to create make: its derivational suffixes also come from latin. the word create appeared in english as early as the th century notably in chaucer to indicate divine creation in the parsons talehowever its modern meaning as an act of human creation did not emerge until after the enlightenment.in a summary of scientific research into creativity michael mumford suggested: over the course of the last decade however we seem to have reached a general agreement that creativity involves the production of novel useful products mumford  p.  or in robert sternbergs words the production of something original and worthwhile. authors have diverged dramatically in their precise definitions beyond these general commonalities: peter meusburger reckons that over a hundred different analyses can be found in the literature. as an illustration one definition given by dr. e. paul torrance described it as a process of becoming sensitive to problems deficiencies gaps in knowledge missing elements disharmonies and so on; identifying the difficulty; searching for solutions making guesses or formulating hypotheses about the deficiencies: testing and retesting these hypotheses and possibly modifying and retesting them; and finally communicating the results.creativity in general is usually distinguished from innovation in particular where the stress is on implementation. for example teresa amabile and pratt  defines creativity as production of novel and useful ideas and innovation as implementation of creative ideas while the oecd and eurostat state that innovation is more than a new idea or an invention. an innovation requires implementation either by being put into active use or by being made available for use by other parties firms individuals or organisations.there is also an emotional creativity ec which is described as a pattern of cognitive abilities and personality traits related to originality and appropriateness in emotional experience. research has shown emotional creativity is interrelated with the real-life involvement in different types of specific creative leisure activities.theories of creativity particularly investigation of why some people are more creative than others have focused on a variety of aspects. the dominant factors are usually identified as the four ps — process product person and place according to mel rhodes. a focus on process is shown in cognitive approaches that try to describe thought mechanisms and techniques for creative thinking. theories invoking divergent rather than convergent thinking such as guilford or those describing the staging of the creative process such as wallas are primarily theories of creative process. a focus on creative product usually appears in attempts to measure creativity psychometrics see below and in creative ideas framed as successful memes. the psychometric approach to creativity reveals that it also involves the ability to produce more. a focus on the nature of the creative person considers more general intellectual habits such as openness levels of ideation autonomy expertise exploratory behavior and so on. a focus on place considers the circumstances in which creativity flourishes such as degrees of autonomy access to resources and the nature of gatekeepers. creative lifestyles are characterized by nonconforming attitudes and behaviors as well as flexibility.greek philosophers like plato rejected the concept of creativity preferring to see art as a form of discovery. asked in the republic will we say of a painter that he makes something plato answers certainly not he merely imitates.most ancient cultures including thinkers of ancient greece ancient china and ancient india lacked the concept of creativity seeing art as a form of discovery and not creation. the ancient greeks had no terms corresponding to to create or creator except for the expression poiein to make which only applied to poiesis poetry and to the poietes poet or maker who made it. plato did not believe in art as a form of creation. asked in the republic will we say of a painter that he makes something he answers certainly not he merely imitates.it is commonly argued that the notion of creativity originated in western culture through christianity as a matter of divine inspiration. according to the historian daniel j. boorstin the early western conception of creativity was the biblical story of creation given in the genesis. however this is not creativity in the modern sense which did not arise until the renaissance. in the judaeo-christian tradition creativity was the sole province of god; humans were not considered to have the ability to create something new except as an expression of gods work. a concept similar to that of christianity existed in greek culture for instance muses were seen as mediating inspiration from the gods. romans and greeks invoked the concept of an external creative daemon greek or genius latin linked to the sacred or the divine. however none of these views are similar to the modern concept of creativity and the individual was not seen as the cause of creation until the renaissance. it was during the renaissance that creativity was first seen not as a conduit for the divine but from the abilities of great men.the rejection of creativity in favor of discovery and the belief that individual creation was a conduit of the divine would dominate the west probably until the renaissance and even later. the development of the modern concept of creativity begins in the renaissance when creation began to be perceived as having originated from the abilities of the individual and not god. this could be attributed to the leading intellectual movement of the time aptly named humanism which developed an intensely human-centric outlook on the world valuing the intellect and achievement of the individual. from this philosophy arose the renaissance man or polymath an individual who embodies the principals of humanism in their ceaseless courtship with knowledge and creation. one of the most well-known and immensely accomplished examples is leonardo da vinci.however this shift was gradual and would not become immediately apparent until the enlightenment. by the th century and the age of enlightenment mention of creativity notably in aesthetics linked with the concept of imagination became more frequent. in the writing of thomas hobbes imagination became a key element of human cognition; william duff was one of the first to identify imagination as a quality of genius typifying the separation being made between talent productive but breaking no new ground and genius.as a direct and independent topic of study creativity effectively received no attention until the th century. runco and albert argue that creativity as the subject of proper study began seriously to emerge in the late th century with the increased interest in individual differences inspired by the arrival of darwinism. in particular they refer to the work of francis galton who through his eugenicist outlook took a keen interest in the heritability of intelligence with creativity taken as an aspect of genius.in the late th and early th centuries leading mathematicians and scientists such as hermann von helmholtz  and henri poincaré  began to reflect on and publicly discuss their creative processes.the insights of poincaré and von helmholtz were built on in early accounts of the creative process by pioneering theorists such as graham wallas and max wertheimer. in his work art of thought published in  wallas presented one of the first models of the creative process. in the wallas stage model creative insights and illuminations may be explained by a process consisting of  stages:i preparation preparatory work on a problem that focuses the individuals mind on the problem and explores the problems dimensionsii incubation where the problem is internalized into the unconscious mind and nothing appears externally to be happeningiii intimation the creative person gets a feeling that a solution is on its wayiv illumination or insight where the creative idea bursts forth from its preconscious processing into conscious awareness;v verification where the idea is consciously verified elaborated and then applied.wallas model is often treated as four stages with intimation seen as a sub-stage.wallas considered creativity to be a legacy of the evolutionary process which allowed humans to quickly adapt to rapidly changing environments. simonton provides an updated perspective on this view in his book origins of genius: darwinian perspectives on creativity.in  alfred north whitehead gave the gifford lectures at the university of edinburgh later published as process and reality. he is credited with having coined the term creativity to serve as the ultimate category of his metaphysical scheme: whitehead actually coined the term – our term still the preferred currency of exchange among literature science and the arts. . . a term that quickly became so popular so omnipresent that its invention within living memory and by alfred north whitehead of all people quickly became occluded.although psychometric studies of creativity had been conducted by the london school of psychology as early as  with the work of h. l. hargreaves into the faculty of imagination the formal psychometric measurement of creativity from the standpoint of orthodox psychological literature is usually considered to have begun with j. p. guilfords address to the american psychological association in . the address helped to popularize the study of creativity and to focus attention on scientific approaches to conceptualizing creativity. statistical analyses led to the recognition of creativity as measured as a separate aspect of human cognition to iq-type intelligence into which it had previously been subsumed. guilfords work suggested that above a threshold level of iq the relationship between creativity and classically measured intelligence broke down.james c. kaufman and beghetto introduced a four c model of creativity; mini-c transformative learning involving personally meaningful interpretations of experiences actions and insights little-c everyday problem solving and creative expression pro-c exhibited by people who are professionally or vocationally creative though not necessarily eminent and big-c creativity considered great in the given field. this model was intended to help accommodate models and theories of creativity that stressed competence as an essential component and the historical transformation of a creative domain as the highest mark of creativity. it also the authors argued made a useful framework for analyzing creative processes in individuals.the contrast of terms big c and little c has been widely used. kozbelt beghetto and runco use a little-c/big-c model to review major theories of creativity. margaret boden distinguishes between h-creativity historical and p-creativity personal.robinson and anna craft have focused on creativity in a general population particularly with respect to education. craft makes a similar distinction between high and little c creativity. and cites ken robinson as referring to high and democratic creativity. mihaly csikszentmihalyi has defined creativity in terms of those individuals judged to have made significant creative perhaps domain-changing contributions. simonton has analysed the career trajectories of eminent creative people in order to map patterns and predictors of creative productivity.there has been much empirical study in psychology and cognitive science of the processes through which creativity occurs. interpretation of the results of these studies has led to several possible explanations of the sources and methods of creativity.incubation is a temporary break from creative problem solving that can result in insight. there has been some empirical research looking at whether as the concept of incubation in wallas model implies a period of interruption or rest from a problem may aid creative problem-solving. ward lists various hypotheses that have been advanced to explain why incubation may aid creative problem-solving and notes how some empirical evidence is consistent with the hypothesis that incubation aids creative problem in that it enables forgetting of misleading clues. absence of incubation may lead the problem solver to become fixated on inappropriate strategies of solving the problem. this work disputes the earlier hypothesis that creative solutions to problems arise mysteriously from the unconscious mind while the conscious mind is occupied on other tasks. this earlier hypothesis is discussed in csikszentmihalyis five phase model of the creative process which describes incubation as a time that your unconscious takes over. this allows for unique connections to be made without our consciousness trying to make logical order out of the problem.j. p. guilford drew a distinction between convergent and divergent production commonly renamed convergent and divergent thinking. convergent thinking involves aiming for a single correct solution to a problem whereas divergent thinking involves creative generation of multiple answers to a set problem. divergent thinking is sometimes used as a synonym for creativity in psychology literature. other researchers have occasionally used the terms flexible thinking or fluid intelligence which are roughly similar to but not synonymous with creativity.in  finke et al. proposed the geneplore model in which creativity takes place in two phases: a generative phase where an individual constructs mental representations called preinventive structures and an exploratory phase where those structures are used to come up with creative ideas. some evidence shows that when people use their imagination to develop new ideas those ideas are heavily structured in predictable ways by the properties of existing categories and concepts. weisberg argued by contrast that creativity only involves ordinary cognitive processes yielding extraordinary results.helie and sun more recently proposed a unified framework for understanding creativity in problem solving namely the explicit–implicit interaction eii theory of creativity. this new theory constitutes an attempt at providing a more unified explanation of relevant phenomena in part by reinterpreting/integrating various fragmentary existing theories of incubation and insight.the eii theory relies mainly on five basic principles namely:the co-existence of and the difference between explicit and implicit knowledge;the simultaneous involvement of implicit and explicit processes in most tasks;the redundant representation of explicit and implicit knowledge;the integration of the results of explicit and implicit processing;the iterative and possibly bidirectional processing.a computational implementation of the theory was developed based on the clarion cognitive architecture and used to simulate relevant human data. this work represents an initial step in the development of process-based theories of creativity encompassing incubation insight and various other related phenomena.in the act of creation arthur koestler introduced the concept of bisociation — that creativity arises as a result of the intersection of two quite different frames of reference. this idea was later developed into conceptual blending. in the s various approaches in cognitive science that dealt with metaphor analogy and structure mapping have been converging and a new integrative approach to the study of creativity in science art and humor has emerged under the label conceptual blending.honing theory developed principally by psychologist liane gabora posits that creativity arises due to the self-organizing self-mending nature of a worldview. the creative process is a way in which the individual hones and re-hones an integrated worldview. honing theory places emphasis not only on the externally visible creative outcome but also the internal cognitive restructuring and repair of the worldview brought about by the creative process. when faced with a creatively demanding task there is an interaction between the conception of the task and the worldview. the conception of the task changes through interaction with the worldview and the worldview changes through interaction with the task. this interaction is reiterated until the task is complete at which point not only is the task conceived of differently but the worldview is subtly or drastically transformed as it follows the natural tendency of a worldview to attempt to resolve dissonance and seek internal consistency amongst its components whether they be ideas attitudes or bits of knowledge.a central feature of honing theory is the notion of a potentiality state. honing theory posits that creative thought proceeds not by searching through and randomly ‘mutating’ predefined possibilities but by drawing upon associations that exist due to overlap in the distributed neural cell assemblies that participate in the encoding of experiences in memory. midway through the creative process one may have made associations between the current task and previous experiences but not yet disambiguated which aspects of those previous experiences are relevant to the current task. thus the creative idea may feel ‘half-baked’. it is at that point that it can be said to be in a potentiality state because how it will actualize depends on the different internally or externally generated contexts it interacts with.honing theory is held to explain certain phenomena not dealt with by other theories of creativity for example how different works by the same creator are observed in studies to exhibit a recognizable style or voice even though in different creative outlets. this is not predicted by theories of creativity that emphasize chance processes or the accumulation of expertise but it is predicted by honing theory according to which personal style reflects the creators uniquely structured worldview. another example is in the environmental stimulus for creativity. creativity is commonly considered to be fostered by a supportive nurturing trustworthy environment conducive to self-actualization. however research shows that creativity is also associated with childhood adversity which would stimulate honing.in everyday thought people often spontaneously imagine alternatives to reality when they think if only.... their counterfactual thinking is viewed as an example of everyday creative processes. it has been proposed that the creation of counterfactual alternatives to reality depends on similar cognitive processes to rational thought.holm-hadulla developed with his colleagues a dialectical theory of creativity. it is an interdisciplinary theory. the dialectical theory of creativity starts with the antique concept that creativity takes place in an interplay between order and chaos. similar ideas can be found in neurosciences and psychology. neurobiologically it can be shown that the creative process takes place in a dynamic interplay between coherence and incoherence that leads to new and usable neuronal networks. psychology shows how the dialectics of convergent and focused thinking with divergent and associative thinking leads to new ideas and products. also creative personality traits like the ‘big five’ seem to be dialectically intertwined in the creative process: emotional instability vs. stability extraversion vs. introversion openness vs. reserve agreeableness vs. antagonism and disinhibition vs. constraint. holm-hadulla and colleagues exemplified the dialectics of creative processes and personality traits on behalf of extraordinary personalities like johann w. v. goethe robert schumann jim morrison madonna ciccone and mick jagger. the dialectical theory of creativity applies also to counseling and psychotherapy.there was a creativity quotient developed similar to the intelligence quotient iq. it makes use of the results of divergent thinking tests see below by processing them further. it gives more weight to ideas that are radically different from other ideas in the response.j. p. guilfords group which pioneered the modern psychometric study of creativity constructed several tests to measure creativity in :plot titles where participants are given the plot of a story and asked to write original titles.quick responses is a word-association test scored for uncommonness.figure concepts where participants were given simple drawings of objects and individuals and asked to find qualities or features that are common by two or more drawings; these were scored for uncommonness.unusual uses is finding unusual uses for common everyday objects such as bricks.remote associations where participants are asked to find a word between two given words e.g. hand _____ callremote consequences where participants are asked to generate a list of consequences of unexpected events e.g. loss of gravityoriginally guilford was trying to create a model for intellect as a whole but in doing so also created a model for creativity. guilford made an important assumption for creative research: creativity isnt one abstract concept.  the idea that creativity is a category rather than one single concept opened up the ability for other researchers to look at creativity with a whole new perspective.additionally guilford hypothesized one of the first models for the components of creativity.  he explained that creativity was a result of having:sensitivity to problems or the ability to recognize problems;fluency which encompassesa. ideational fluency or the ability rapidly to produce a variety of ideas that fulfill stated requirements;b. associational fluency or the ability to generate a list of words each of which is associated with a given word;                    c. expressional fluency or the ability to organize words into larger units such as phrases sentences and paragraphs;flexibility which encompasses                      a. spontaneous flexibility or the ability to demonstrate flexibility;                          b. adaptive flexibility or the ability to produce responses that are novel and high in quality.this represents the base model by which several researchers would take and alter to produce their new theories of creativity years later. building on guilfords work torrance developed the torrance tests of creative thinking in . they involved simple tests of divergent thinking and other problem-solving skills which were scored on:fluency – the total number of interpretable meaningful and relevant ideas generated in response to the stimulus.originality – the statistical rarity of the responses among the test subjects.elaboration – the amount of detail in the responses.such tests sometimes called divergent thinking dt tests have been both supported and criticized.considerable progress has been made in automated scoring of divergent thinking tests using semantic approach. when compared to human raters nlp techniques were shown to be reliable and valid in scoring the originality. the reported computer programs were able to achieve a correlation of . and . respectively to human graders.semantic networks were also used to devise originality scores that yielded significant correlations with socio-personal measures. most recently an nsf-funded team of researchers led by james c. kaufman and mark a. runco combined expertise in creativity research natural language processing computational linguistics and statistical data analysis to devise a scalable system for computerized automated testing sparcit creativity index testing system. this system enabled automated scoring of dt tests that is reliable objective and scalable thus addressing most of the issues of dt tests that had been found and reported. the resultant computer system was able to achieve a correlation of . to human graders.some researchers have taken a social-personality approach to the measurement of creativity. in these studies personality traits such as independence of judgement self-confidence attraction to complexity aesthetic orientation and risk-taking are used as measures of the creativity of individuals. a meta-analysis by gregory feist showed that creative people tend to be more open to new experiences less conventional and less conscientious more self-confident self-accepting driven ambitious dominant hostile and impulsive. openness conscientiousness self-acceptance hostility and impulsivity had the strongest effects of the traits listed. within the framework of the big five model of personality some consistent traits have emerged. openness to experience has been shown to be consistently related to a whole host of different assessments of creativity. among the other big five traits research has demonstrated subtle differences between different domains of creativity. compared to non-artists artists tend to have higher levels of openness to experience and lower levels of conscientiousness while scientists are more open to experience conscientious and higher in the confidence-dominance facets of extraversion compared to non-scientists.an alternative is using biographical methods. these methods use quantitative characteristics such as the number of publications patents or performances of a work. while this method was originally developed for highly creative personalities today it is also available as self-report questionnaires supplemented with frequent less outstanding creative behaviors such as writing a short story or creating your own recipes. for example the creative achievement questionnaire a self-report test that measures creative achievement across  domains was described in  and shown to be reliable and valid when compared to other measures of creativity and to independent evaluation of creative output. besides the english original it was also used in a chinese french and german-speaking version. it is the self-report questionnaire most frequently used in research.the potential relationship between creativity and intelligence has been of interest since the late s when a multitude of influential studies – from getzels & jackson barron wallach & kogan and guilford – focused not only on creativity but also on intelligence. this joint focus highlights both the theoretical and practical importance of the relationship: researchers are interested not only if the constructs are related but also how and why.there are multiple theories accounting for their relationship with the  main theories as follows:threshold theory – intelligence is a necessary but not sufficient condition for creativity. there is a moderate positive relationship between creativity and intelligence until iq ~.certification theory – creativity is not intrinsically related to intelligence. instead individuals are required to meet the requisite level intelligence in order to gain a certain level of education/work which then in turn offers the opportunity to be creative. displays of creativity are moderated by intelligence.interference theory – extremely high intelligence might interfere with creative ability.sternberg and o’hara proposed a framework of  possible relationships between creativity and intelligence:creativity is a subset of intelligenceintelligence is a subset of creativitycreativity and intelligence are overlapping constructscreativity and intelligence are part of the same construct coincident setscreativity and intelligence are distinct constructs disjoint setscreativity as a subset of intelligencea number of researchers include creativity either explicitly or implicitly as a key component of intelligence.examples of theories that include creativity as a subset of intelligencesternbergs theory of successful intelligence see triarchic theory of intelligence includes creativity as a main component and comprises  sub-theories: componential analytic contextual practical and experiential creative. experiential sub-theory – the ability to use pre-existing knowledge and skills to solve new and novel problems – is directly related to creativity.the cattell–horn–carroll theory includes creativity as a subset of intelligence. specifically it is associated with the broad group factor of long-term storage and retrieval glr. glr narrow abilities relating to creativity include: ideational fluency associational fluency and originality/creativity. silvia et al. conducted a study to look at the relationship between divergent thinking and verbal fluency tests and reported that both fluency and originality in divergent thinking were significantly affected by the broad level glr factor. martindale extended the chc-theory in the sense that it was proposed that those individuals who are creative are also selective in their processing speed martindale argues that in the creative process larger amounts of information are processed more slowly in the early stages and as the individual begins to understand the problem the processing speed is increased.the dual process theory of intelligence posits a two-factor/type model of intelligence. type  is a conscious process and concerns goal directed thoughts which are explained by g. type  is an unconscious process and concerns spontaneous cognition which encompasses daydreaming and implicit learning ability. kaufman argues that creativity occurs as a result of type  and type  processes working together in combination. the use of each type in the creative process can be used to varying degrees.intelligence as a subset of creativityin this relationship model intelligence is a key component in the development of creativity.sternberg & lubarts investment theory. using the metaphor of a stock market they demonstrate that creative thinkers are like good investors – they buy low and sell high in their ideas. like under/low-valued stock creative individuals generate unique ideas that are initially rejected by other people. the creative individual has to persevere and convince the others of the ideas value. after convincing the others and thus increasing the ideas value the creative individual ‘sells high’ by leaving the idea with the other people and moves onto generating another idea. according to this theory six distinct but related elements contribute to successful creativity: intelligence knowledge thinking styles personality motivation and environment. intelligence is just one of the six factors that can either solely or in conjunction with the other five factors generate creative thoughts.amabiles componential model of creativity. in this model there are  within-individual components needed for creativity – domain-relevant skills creativity-relevant processes and task motivation – and  component external to the individual: their surrounding social environment. creativity requires a confluence of all components. high creativity will result when an individual is: intrinsically motivated possesses both a high level of domain-relevant skills and has high skills in creative thinking and is working in a highly creative environment.amusement park theoretical model. in this -step theory both domain-specific and generalist views are integrated into a model of creativity. the researchers make use of the metaphor of the amusement park to demonstrate that within each of these creative levels intelligence plays a key role:to get into the amusement park there are initial requirements e.g. time/transport to go to the park. initial requirements like intelligence are necessary but not sufficient for creativity. they are more like prerequisites for creativity and if an individual does not possess the basic level of the initial requirement intelligence then they will not be able to generate creative thoughts/behaviour.secondly are the subcomponents – general thematic areas – that increase in specificity. like choosing which type of amusement park to visit e.g. a zoo or a water park these areas relate to the areas in which someone could be creative e.g. poetry.thirdly there are specific domains. after choosing the type of park to visit e.g. waterpark you then have to choose which specific park to go to. within the poetry domain there are many different types e.g. free verse riddles sonnet etc. that have to be selected from.lastly there are micro-domains. these are the specific tasks that reside within each domain e.g. individual lines in a free verse poem / individual rides at the waterpark.creativity and intelligence as overlapping yet distinct constructsthis possible relationship concerns creativity and intelligence as distinct but intersecting constructs.renzullis three-ring conception of giftedness. in this conceptualisation giftedness occurs as a result from the overlap of above average intellectual ability creativity and task commitment. under this view creativity and intelligence are distinct constructs but they do overlap under the correct conditions.pass theory of intelligence. in this theory the planning component – relating to the ability to solve problems make decisions and take action – strongly overlaps with the concept of creativity.threshold theory tt. a number of previous research findings have suggested that a threshold exists in the relationship between creativity and intelligence – both constructs are moderately positively correlated up to an iq of ~. above this threshold of an iq of  if there is a relationship at all it is small and weak. tt posits that a moderate level of intelligence is necessary for creativity.in support of the tt barron reported finding a non-significant correlation between creativity and intelligence in a gifted sample; and a significant correlation in a non-gifted sample. yamamoto in a sample of secondary school children reported a significant correlation between creativity and intelligence of r = . and reported no significant correlation when the sample consisted of gifted children. fuchs-beauchamp et al. in a sample of preschoolers found that creativity and intelligence correlated from r = . to r = . in the group of children who had an iq below the threshold; and in the group above the threshold the correlations were r = <.. cho et al. reported a correlation of . between creativity and intelligence in the average iq group of a sample of adolescents and adults; and a correlation of close to r = . for the high iq group. jauk et al. found support for the tt but only for measures of creative potential; not creative performance.much modern day research reports findings against tt. wai et al. in a study using data from the longitudinal study of mathematically precocious youth – a cohort of elite students from early adolescence into adulthood – found that differences in sat scores at age  were predictive of creative real-life outcomes  years later. kims meta-analysis of  studies did not find any supporting evidence for tt and instead negligible correlations were reported between intelligence creativity and divergent thinking both below and above iqs of . preckel et al. investigating fluid intelligence and creativity reported small correlations of r = . to r = . across all levels of cognitive ability.under this view researchers posit that there are no differences in the mechanisms underlying creativity in those used in normal problem solving; and in normal problem solving there is no need for creativity. thus creativity and intelligence problem solving are the same thing. perkins referred to this as the ‘nothing-special’ view.weisberg & alba examined problem solving by having participants complete the -dot problem see thinking outside the box#nine dots puzzle – where the participants are asked to connect all  dots in the  rows of  dots using  straight lines or less without lifting their pen or tracing the same line twice. the problem can only be solved if the lines go outside the boundaries of the square of dots. results demonstrated that even when participants were given this insight they still found it difficult to solve the problem thus showing that to successfully complete the task it is not just insight or creativity that is required.in this view creativity and intelligence are completely different unrelated constructs.getzels and jackson administered  creativity measures to a group of  children from grades - and compared these test findings to results from previously administered by the school iq tests. they found that the correlation between the creativity measures and iq was r = .. the high creativity group scored in the top % of the overall creativity measures but were not included in the top % of iq scorers. the high intelligence group scored the opposite: they scored in the top % for iq but were outside the top % scorers for creativity thus showing that creativity and intelligence are distinct and unrelated.however this work has been heavily criticised. wallach and kogan highlighted that the creativity measures were not only weakly related to one another to the extent that they were no more related to one another than they were with iq but they seemed to also draw upon non-creative skills. mcnemar noted that there were major measurement issues in that the iq scores were a mixture from  different iq tests.wallach and kogan administered  measures of creativity each of which resulted in a score for originality and fluency; and  measures of general intelligence to  th grade children. these tests were untimed and given in a game-like manner aiming to facilitate creativity. inter-correlations between creativity tests were on average r = .. inter-correlations between intelligence measures were on average r = . with each other. creativity tests and intelligence measures correlated r = ..distributed functional brain network associated with divergent thinkingthe neuroscience of creativity looks at the operation of the brain during creative behaviour. it has been addressed in the article creative innovation: possible brain mechanisms. the authors write that creative innovation might require coactivation and communication between regions of the brain that ordinarily are not strongly connected. highly creative people who excel at creative innovation tend to differ from others in three ways:they have a high level of specialized knowledgethey are capable of divergent thinking mediated by the frontal lobe.and they are able to modulate neurotransmitters such as norepinephrine in their frontal lobe.thus the frontal lobe appears to be the part of the cortex that is most important for creativity.this article also explored the links between creativity and sleep mood and addiction disorders and depression.in  alice flaherty presented a three-factor model of the creative drive. drawing from evidence in brain imaging drug studies and lesion analysis she described the creative drive as resulting from an interaction of the frontal lobes the temporal lobes and dopamine from the limbic system. the frontal lobes can be seen as responsible for idea generation and the temporal lobes for idea editing and evaluation. abnormalities in the frontal lobe such as depression or anxiety generally decrease creativity while abnormalities in the temporal lobe often increase creativity. high activity in the temporal lobe typically inhibits activity in the frontal lobe and vice versa. high dopamine levels increase general arousal and goal directed behaviors and reduce latent inhibition and all three effects increase the drive to generate ideas. a  study on creativity found that it involves the interaction of multiple neural networks including those that support associative thinking along with other default mode network functions.vandervert described how the brains frontal lobes and the cognitive functions of the cerebellum collaborate to produce creativity and innovation. vanderverts explanation rests on considerable evidence that all processes of working memory responsible for processing all thought are adaptively modeled for increased efficiency by the cerebellum. the cerebellum consisting of  billion neurons which is more than the entirety of the rest of the brain is also widely known to adaptively model all bodily movement for efficiency. the cerebellums adaptive models of working memory processing are then fed back to especially frontal lobe working memory control processes where creative and innovative thoughts arise. apparently creative insight or the aha experience is then triggered in the temporal lobe.according to vandervert the details of creative adaptation begin in forward cerebellar models which are anticipatory/exploratory controls for movement and thought. these cerebellar processing and control architectures have been termed hierarchical modular selection and identification for control hmosaic. new hierarchically arranged levels of the cerebellar control architecture hmosaic develop as mental mulling in working memory is extended over time. these new levels of the control architecture are fed forward to the frontal lobes. since the cerebellum adaptively models all movement and all levels of thought and emotion vanderverts approach helps explain creativity and innovation in sports art music the design of video games technology mathematics the child prodigy and thought in general.essentially vandervert has argued that when a person is confronted with a challenging new situation visual-spatial working memory and speech-related working memory are decomposed and re-composed fractionated by the cerebellum and then blended in the cerebral cortex in an attempt to deal with the new situation. with repeated attempts to deal with challenging situations the cerebro-cerebellar blending process continues to optimize the efficiency of how working memory deals with the situation or problem. most recently he has argued that this is the same process only involving visual-spatial working memory and pre-language vocalization that led to the evolution of language in humans. vandervert and vandervert-weathers have pointed out that this blending process because it continuously optimizes efficiencies constantly improves prototyping attempts toward the invention or innovation of new ideas music art or technology. prototyping they argue not only produces new products it trains the cerebro-cerebellar pathways involved to become more efficient at prototyping itself. further vandervert and vandervert-weathers believe that this repetitive mental prototyping or mental rehearsal involving the cerebellum and the cerebral cortex explains the success of the self-driven individualized patterning of repetitions initiated by the teaching methods of the khan academy. the model proposed by vandervert has however received incisive critique from several authors.creativity involves the forming of associative elements into new combinations that are useful or meet some requirement. sleep aids this process. rem rather than nrem sleep appears to be responsible. this has been suggested to be due to changes in cholinergic and noradrenergic neuromodulation that occurs during rem sleep. during this period of sleep high levels of acetylcholine in the hippocampus suppress feedback from the hippocampus to the neocortex and lower levels of acetylcholine and norepinephrine in the neocortex encourage the spread of associational activity within neocortical areas without control from the hippocampus. this is in contrast to waking consciousness where higher levels of norepinephrine and acetylcholine inhibit recurrent connections in the neocortex. it is proposed that rem sleep adds creativity by allowing neocortical structures to reorganize associative hierarchies in which information from the hippocampus would be reinterpreted in relation to previous semantic representations or nodes.some theories suggest that creativity may be particularly susceptible to affective influence. as noted in voting behavior the term affect in this context can refer to liking or disliking key aspects of the subject in question. this work largely follows from findings in psychology regarding the ways in which affective states are involved in human judgment and decision-making.according to alice isen positive affect has three primary effects on cognitive activity:positive affect makes additional cognitive material available for processing increasing the number of cognitive elements available for association;positive affect leads to defocused attention and a more complex cognitive context increasing the breadth of those elements that are treated as relevant to the problem;positive affect increases cognitive flexibility increasing the probability that diverse cognitive elements will in fact become associated. together these processes lead positive affect to have a positive influence on creativity.barbara fredrickson in her broaden-and-build model suggests that positive emotions such as joy and love broaden a persons available repertoire of cognitions and actions thus enhancing creativity.according to these researchers positive emotions increase the number of cognitive elements available for association attention scope and the number of elements that are relevant to the problem cognitive scope.various meta-analyses such as baas et al.  of  studies about creativity and affect support the link between creativity and positive affect. research has shown that practicing creative leisure activities is interrelated with the emotional creativity.jürgen schmidhubers formal theory of creativity postulates that creativity curiosity and interestingness are by-products of a simple computational principle for measuring and optimizing learning progress. consider an agent able to manipulate its environment and thus its own sensory inputs. the agent can use a black box optimization method such as reinforcement learning to learn through informed trial and error sequences of actions that maximize the expected sum of its future reward signals. there are extrinsic reward signals for achieving externally given goals such as finding food when hungry. but schmidhubers objective function to be maximized also includes an additional intrinsic term to model wow-effects. this non-standard term motivates purely creative behavior of the agent even when there are no external goals. a wow-effect is formally defined as follows. as the agent is creating and predicting and encoding the continually growing history of actions and sensory inputs it keeps improving the predictor or encoder which can be implemented as an artificial neural network or some other machine learning device that can exploit regularities in the data to improve its performance over time. the improvements can be measured precisely by computing the difference in computational costs storage size number of required synapses errors time needed to encode new observations before and after learning. this difference depends on the encoders present subjective knowledge which changes over time but the theory formally takes this into account. the cost difference measures the strength of the present wow-effect due to sudden improvements in data compression or computational speed. it becomes an intrinsic reward signal for the action selector. the objective function thus motivates the action optimizer to create action sequences causing more wow-effects. irregular random data or noise do not permit any wow-effects or learning progress and thus are boring by nature providing no reward. already known and predictable regularities also are boring. temporarily interesting are only the initially unknown novel regular patterns in both actions and observations. this motivates the agent to perform continual open-ended active creative exploration. schmidhubers work is highly influential in intrinsic motivation which has emerged as a research topic in its own right as part of the study of artificial intelligence and robotics.according to schmidhuber his objective function explains the activities of scientists artists and comedians. for example physicists are motivated to create experiments leading to observations obeying previously unpublished physical laws permitting better data compression. likewise composers receive intrinsic reward for creating non-arbitrary melodies with unexpected but regular harmonies that permit wow-effects through data compression improvements. similarly a comedian gets intrinsic reward for inventing a novel joke with an unexpected punch line related to the beginning of the story in an initially unexpected but quickly learnable way that also allows for better compression of the perceived data. schmidhuber argues that ongoing computer hardware advances will greatly scale up rudimentary artificial scientists and artistsclarification needed based on simple implementations of the basic principle since . he used the theory to create low-complexity art and an attractive human face.a study by psychologist j. philippe rushton found creativity to correlate with intelligence and psychoticism. another study found creativity to be greater in schizotypal than in either normal or schizophrenic individuals. while divergent thinking was associated with bilateral activation of the prefrontal cortex schizotypal individuals were found to have much greater activation of their right prefrontal cortex. this study hypothesizes that such individuals are better at accessing both hemispheres allowing them to make novel associations at a faster rate. in agreement with this hypothesis ambidexterity is also associated with schizotypal and schizophrenic individuals. three recent studies by mark batey and adrian furnham have demonstrated the relationships between schizotypal and hypomanic personality and several different measures of creativity.particularly strong links have been identified between creativity and mood disorders particularly manic-depressive disorder a.k.a. bipolar disorder and depressive disorder a.k.a. unipolar disorder. in touched with fire: manic-depressive illness and the artistic temperament kay redfield jamison summarizes studies of mood-disorder rates in writers poets and artists. she also explores research that identifies mood disorders in such famous writers and artists as ernest hemingway who shot himself after electroconvulsive treatment virginia woolf who drowned herself when she felt a depressive episode coming on composer robert schumann who died in a mental institution and even the famed visual artist michelangelo.a study looking at  persons with schizophrenia bipolar disorder or unipolar depression and their relatives found overrepresentation in creative professions for those with bipolar disorder as well as for undiagnosed siblings of those with schizophrenia or bipolar disorder. there was no overall overrepresentation but overrepresentation for artistic occupations among those diagnosed with schizophrenia. there was no association for those with unipolar depression or their relatives.another study involving more than one million people conducted by swedish researchers at the karolinska institute reported a number of correlations between creative occupations and mental illnesses. writers had a higher risk of anxiety and bipolar disorders schizophrenia unipolar depression and substance abuse and were almost twice as likely as the general population to kill themselves. dancers and photographers were also more likely to have bipolar disorder.as a group those in the creative professions were no more likely to have psychiatric disorders than other people although they were more likely to have a close relative with a disorder including anorexia and to some extent autism the journal of psychiatric research reports.according to psychologist robert epstein phd creativity can be obstructed through stress.conversely research has shown that creative activities such as art therapy poetry writing journaling and reminiscence can promote mental well-being.creativity can be expressed in a number of different forms depending on unique people and environments. a number of different theorists have suggested models of the creative person. one model suggests that there are four creativity profiles that can help produce growth innovation speed etc.i incubate long-term developmentii imagine breakthrough ideasiii improve incremental adjustmentsiv invest short-term goalsresearch by dr mark batey of the psychometrics at work research group at manchester business school has suggested that the creative profile can be explained by four primary creativity traits with narrow facets within eachi idea generation fluency originality incubation and illuminationii personality curiosity and tolerance for ambiguityiii motivation intrinsic extrinsic and achievementiv confidence producing sharing and implementingthis model was developed in a sample of  working adults using the statistical techniques of exploratory factor analysis followed by confirmatory factor analysis by structural equation modelling.an important aspect of the creativity profiling approach is to account for the tension between predicting the creative profile of an individual as characterised by the psychometric approach and the evidence that team creativity is founded on diversity and difference.one characteristic of creative people as measured by some psychologists is what is called divergent production. divergent production is the ability of a person to generate a diverse assortment yet an appropriate amount of responses to a given situation. one way of measuring divergent production is by administering the torrance tests of creative thinking. the torrance tests of creative thinking assesses the diversity quantity and appropriateness of participants responses to a variety of open-ended questions.other researchers of creativity see the difference in creative people as a cognitive process of dedication to problem solving and developing expertise in the field of their creative expression. hard working people study the work of people before them and within their current area become experts in their fields and then have the ability to add to and build upon previous information in innovative and creative ways. in a study of projects by design students students who had more knowledge on their subject on average had greater creativity within their projects.the aspect of motivation within a persons personality may predict creativity levels in the person. motivation stems from two different sources intrinsic and extrinsic motivation. intrinsic motivation is an internal drive within a person to participate or invest as a result of personal interest desires hopes goals etc. extrinsic motivation is a drive from outside of a person and might take the form of payment rewards fame approval from others etc. although extrinsic motivation and intrinsic motivation can both increase creativity in certain cases strictly extrinsic motivation often impedes creativity in people.from a personality-traits perspective there are a number of traits that are associated with creativity in people. creative people tend to be more open to new experiences are more self-confident are more ambitious self-accepting impulsive driven dominant and hostile compared to people with less creativity.from an evolutionary perspective creativity may be a result of the outcome of years of generating ideas. as ideas are continuously generated the need to evolve produces a need for new ideas and developments. as a result people have been creating and developing new innovative and creative ideas to build our progress as a society.in studying exceptionally creative people in history some common traits in lifestyle and environment are often found. creative people in history usually had supportive parents but rigid and non-nurturing. most had an interest in their field at an early age and most had a highly supportive and skilled mentor in their field of interest. often the field they chose was relatively uncharted allowing for their creativity to be expressed more in a field with less previous information. most exceptionally creative people devoted almost all of their time and energy into their craft and after about a decade had a creative breakthrough of fame. their lives were marked with extreme dedication and a cycle of hard-work and breakthroughs as a result of their determination.another theory of creative people is the investment theory of creativity. this approach suggest that there are many individual and environmental factors that must exist in precise ways for extremely high levels of creativity opposed to average levels of creativity. in the investment sense a person with their particular characteristics in their particular environment may see an opportunity to devote their time and energy into something that has been overlooked by others. the creative person develops an undervalued or under-recognised idea to the point that it is established as a new and creative idea. just like in the financial world some investments are worth the buy in while others are less productive and do not build to the extent that the investor expected. this investment theory of creativity views creativity in a unique perspective compared to others by asserting that creativity might rely to some extent on the right investment of effort being added to a field at the right time in the right way.so called malevolent creativity is associated with the dark side of creativity. this type of creativity is not typically accepted within society and is defined by the intention to cause harm to others through original and innovative means. malevolent creativity should be distinguished from negative creativity in that negative creativity may unintentionally cause harm to others whereas malevolent creativity is explicitly malevolently motivated. while it is often associated with criminal behaviour it can also be observed in ordinary day-to-day life as lying cheating and betrayal.malevolent creativity is often a key contributor to crime and in its most destructive form can even manifest as terrorism. as creativity requires deviating from the conventional there is a permanent tension between being creative and producing products that go too far and in some cases to the point of breaking the law. aggression is a key predictor of malevolent creativity and studies have also shown that increased levels of aggression also correlates to a higher likelihood of committing crime.although everyone shows some levels of malevolent creativity under certain conditions those that have a higher propensity towards it have increased tendencies to deceive and manipulate others to their own gain. while malevolent creativity appears to dramatically increase when an individual is placed under unfair conditions personality particularly aggressiveness is also a key predictor in anticipating levels of malevolent thinking. researchers harris and reiter-palmon investigated the role of aggression in levels of malevolent creativity in particular levels of implicit aggression and the tendency to employ aggressive actions in response to problem solving. the personality traits of physical aggression conscientiousness emotional intelligence and implicit aggression all seem to be related with malevolent creativity. harris and reiter-palmons research showed that when subjects were presented with a problem that triggered malevolent creativity participants high in implicit aggression and low in premeditation expressed the largest number of malevolently-themed solutions. when presented with the more benign problem that triggered prosocial motives of helping others and cooperating those high in implicit aggression even if they were high in impulsiveness were far less destructive in their imagined solutions. they concluded premeditation more than implicit aggression controlled an individuals expression of malevolent creativity.creativity is viewed differently in different countries. for example cross-cultural research centred on hong kong found that westerners view creativity more in terms of the individual attributes of a creative person such as their aesthetic taste while chinese people view creativity more in terms of the social influence of creative people e.g. what they can contribute to society. mpofu et al. surveyed  african languages and found that  had no word which directly translated to creativity the exception being arabic. the principle of linguistic relativity i.e. that language can affect thought suggests that the lack of an equivalent word for creativity may affect the views of creativity among speakers of such languages. however more research would be needed to establish this and there is certainly no suggestion that this linguistic difference makes people any less or more creative; africa has a rich heritage of creative pursuits such as music art and storytelling. nevertheless it is true that there has been very little research on creativity in africa and there has also been very little research on creativity in latin america. creativity has been more thoroughly researched in the northern hemisphere but here again there are cultural differences even between countries or groups of countries in close proximity. for example in scandinavian countries creativity is seen as an individual attitude which helps in coping with lifes challenges while in germany creativity is seen more as a process that can be applied to help solve problems.training meeting in an eco-design stainless steel company in brazil. the leaders among other things wish to cheer and encourage the workers in order to achieve a higher level of creativity.it has been the topic of various research studies to establish that organizational effectiveness depends on the creativity of the workforce to a large extent. for any given organization measures of effectiveness vary depending upon its mission environmental context nature of work the product or service it produces and customer demands. thus the first step in evaluating organizational effectiveness is to understand the organization itself — how it functions how it is structured and what it emphasizes.amabile argued that to enhance creativity in business three components were needed:expertise technical procedural and intellectual knowledgecreative thinking skills how flexibly and imaginatively people approach problemsand motivation especially intrinsic motivation.there are two types of motivation:extrinsic motivation – external factors for example threats of being fired or money as a rewardintrinsic motivation – comes from inside an individual satisfaction enjoyment of work etc.six managerial practices to encourage motivation are:challenge – matching people with the right assignments;freedom – giving people autonomy choosing means to achieve goals;resources – such as time money space etc. there must be balance fit among resources and people;work group features – diverse supportive teams where members share the excitement willingness to help and recognize each others talents;supervisory encouragement – recognitions cheering praising;organizational support – value emphasis information sharing collaboration.nonaka who examined several successful japanese companies similarly saw creativity and knowledge creation as being important to the success of organizations. in particular he emphasized the role that tacit knowledge has to play in the creative process.in business originality is not enough. the idea must also be appropriate—useful and actionable. creative competitive intelligence is a new solution to solve this problem. according to reijo siltala it links creativity to innovation process and competitive intelligence to creative workers.creativity can be encouraged in people and professionals and in the workplace. it is essential for innovation and is a factor affecting economic growth and businesses. in  the sociologist silvia leal martín using the innova dx method suggested measuring the various parameters that encourage creativity and innovation: corporate culture work environment leadership and management creativity self-esteem and optimism locus of control and learning orientation motivation and fear.similarly social psychologists organizational scientists and management scientists who conduct extensive research on the factors that influence creativity and innovation in teams and organizations have developed integrative theoretical models that emphasize the roles of team composition team processes and organizational culture as well as the mutually reinforcing relationships between them in promoting innovation.the investigation by loo   on creative working in the knowledge economy brings together studies of creativity as delineated in this web page. it offers connections with the sections on the ‘”four c” model’ ‘theories of creative processes’ ‘creativity as a subset of intelligence’ ‘creativity and personality’ and ‘in organisations’ it is the last section that the investigation addresses.research studies of the knowledge economy may be classified into three levels: macro meso and micro. macro studies refer to investigations at a societal or transnational dimension. meso studies focus on organisations. micro investigations centre on the minutiae workings of workers. there is also an interdisciplinary dimension such as research from businesses e.g. burton-jones ; drucker  economics e.g. cortada ; reich ; florida  education e.g. farrell and fenwick ; brown lauder and ashton  human resource management e.g. davenport  knowledge and organizational management alvesson ; defillippi arthur and lindsay ; orr nutley russell bain hacking and moran  sociology psychology and knowledge economy-related sectors – especially information technology it software e.g. o’riain ; nerland  and advertising e.g. grabher ; lury  loo .loo  studies how individual workers in the knowledge economy use their creativity and know-how in the advertising and it software sectors. it examines this phenomenon across three developed countries of england japan and singapore to observe global perspectives. specifically the study uses qualitative data from semi-structured interviews of the related professionals in the roles of creative directing and copywriting in advertising and systems software developing and software programme managing.the study offers a conceptual framework loo  p.  of a two-dimensional matrix of individual and collaborative working styles and single and multi-contexts. the investigation draws on literature sources from the four disciplines of economics e.g. reich ; quah  management e.g. drucker ; nonaka and takeuchi ; von hippel  sociology e.g. zuboff ; bell ; lash and urry ; castells ; knorr cetina  and psychology e.g. gardner ; csikszentmihalyi ; sternberg kaufman and pretz . the themes arising from the analysis of knowledge work and creativity literature serve to create a distinct theoretical framework of creative knowledge work. these workers apply their cognitive abilities creative personalities and skill sets in the areas of science technology or culture industries to invent or discover new possibilities – e.g. a medium product or service. these work activities may be done individually or collectively. education training and ‘encultured environments’ are necessary for the performance of these creative activities. acts of creativity are viewed as asking new questions over and above those questions asked by an intelligent person seeking novelty when reviewing a situation gardner  and creating something that is different and novel i.e. a ‘variation’ on the idea of existing ideas in a domain csikszentmihalyi . this framework is evidenced by the empirical chapters on the micro-workings of creative workers in the two knowledge economy sectors from global perspectives.this investigation identifies a definition of creative work three types of work and the necessary conditions for it to occur. these workers use a combination of creative applications including anticipatory imagination problem-solving problem seeking and generating ideas and aesthetic sensibilities. taking aesthetic sensibilities as an example for a creative director in the advertising industry it is a visual imagery whether still or moving via a camera lens and for a software programmer it is the innovative technical expertise in which the software is written. there are specific creative applications for each of the sectors such as emotional connection in the advertising sector and the power of expression and sensitivity in the it software sector. in addition to the creative applications creative workers require abilities and aptitudes to carry out their roles. passion for ones job is generic. for copywriters this passion is identified with fun enjoyment and happiness alongside attributes such as honesty regarding the product confidence and patience in finding the appropriate copy. knowledge is also required in the disciplines of the humanities e.g. literature the creative arts e.g. painting and music and technical-related know-how e.g. mathematics computer sciences and physical sciences. in the it software technical knowledge of computer languages e.g. c++ is especially significant for programmers whereas the degree of technical expertise may be less for a programme manager as only knowledge of the relevant language is necessary to understand the issues for communicating with the team of developers and testers.there are three types of work. one is intra-sectoral e.g. ‘general sponge’ and ’in tune with the zeitgeist’ advertising and ‘power of expression’ and ‘sensitivity’ it software. the second is inter-sectoral e.g. ‘integration of advertising activities’ advertising and ‘autonomous decentralized systems’ ads it software. the third relates to changes in culture/practices in the sectors e.g. ‘three-dimensional trust’ and ‘green credentials’ advertising and ‘collaboration with heis and industry’ and ‘ads system in the tokyo train operator’ it software.the necessary conditions for creative work to exist are a supportive environment such as supportive information communications and electronic technologies icet infrastructure training work environment and education.this investigation has implications for lifelong learning of these workers informally and formally. teaching institutions need to offer multi-disciplinary knowledge of humanities arts and sciences and it has impacts on the programme structure delivery approaches and assessments. at a macro level governments need to offer a rich diet of cultural activities outdoor activities and sports fixtures that inform potential creative workers in the areas of video gaming and advertising. this study has implications for work organisations that support and encourage collaborative working alongside individual working offer opportunities to engage in continuous professional development formally and informally and foster an environment which promotes experiential functioning and supports experimentation.diversity between team members’ backgrounds and knowledge can increase team creativity by expanding the total collection of unique information that is available to the team and introducing different perspectives that can integrate in novel ways. however under some conditions diversity can also decrease team creativity by making it more difficult for team members to communicate about ideas and causing interpersonal conflicts between those with different perspectives. thus the potential advantages of diversity must be supported by appropriate team processes and organizational cultures in order to enhance creativity.team communication norms such as respecting others’ expertise paying attention to others’ ideas expecting information sharing tolerating disagreements negotiating remaining open to others’ ideas learning from others and building on each others ideas increase team creativity by facilitating the social processes involved with brainstorming and problem solving. through these processes team members are able to access their collective pool of knowledge reach shared understandings identify new ways of understanding problems or tasks and make new connections between ideas. engaging in these social processes also promotes positive team affect which facilitates collective creativity.supportive and motivational environments that create psychological safety by encouraging risk taking and tolerating mistakes increase team creativity as well. organizations in which help-seeking help giving and collaboration are rewarded promote innovation by providing opportunities and contexts in which team processes that lead to collective creativity can occur. additionally leadership styles that downplay status hierarchies or power differences within an organization and empower people to speak up about their ideas or opinions also help to create cultures that are conducive to creativity.there is a long-standing debate on how material constraints e.g. lack of money materials or equipment affect creativity. in psychological and managerial research two competing views in this regard prevail. in one view many scholars propose a negative effect of material constraints on innovation and claim that material constraints starve creativity. the proponents of this view argue that adequate material resources are needed to engage in creative activities like experimenting with new solutions and idea exploration. in an opposing view scholars assert that people tend to stick to established routines or solutions as long as they are not forced to deviate from them by constraints. in this sense neren posits that scarcity is an important driver of creativity. consistently gibbert and scranton demonstrated how material constraints facilitated the development of jet engines in world war ii.to reconcile these competing views contingency models were proposed. the rationale behind these models is that certain contingency factors e.g. creativity climate or creativity relevant skills influence the relationship between constraints and creativity. these contingency factors reflect the need for higher levels of motivation and skills when working on creative tasks under constraints. depending on these contingency factors there is either a positive or negative relationship between constraints and creativity.economic approaches to creativity have focussed on three aspects — the impact of creativity on economic growth methods of modelling markets for creativity and the maximisation of economic creativity innovation.in the early th century joseph schumpeter introduced the economic theory of creative destruction to describe the way in which old ways of doing things are endogenously destroyed and replaced by the new. some economists such as paul romer view creativity as an important element in the recombination of elements to produce new technologies and products and consequently economic growth. creativity leads to capital and creative products are protected by intellectual property laws.mark a. runco and daniel rubenson have tried to describe a psychoeconomic model of creativity. in such a model creativity is the product of endowments and active investments in creativity; the costs and benefits of bringing creative activity to market determine the supply of creativity. such an approach has been criticised for its view of creativity consumption as always having positive utility and for the way it analyses the value of future innovations.the creative class is seen by some to be an important driver of modern economies. in his  book the rise of the creative class economist richard florida popularized the notion that regions with  ts of economic development: technology talent and tolerance also have high concentrations of creative professionals and tend to have a higher level of economic development.several different researchers have proposed methods of increasing the creativity of an individual. such ideas range from the psychological-cognitive such as osborn-parnes creative problem solving process synectics science-based creative thinking purdue creative thinking program and edward de bonos lateral thinking; to the highly structured such as triz the theory of inventive problem-solving and its variant algorithm of inventive problem solving developed by the russian scientist genrich altshuller and computer-aided morphological analysis.daniel pink in his  book a whole new mind repeating arguments posed throughout the th century argues that we are entering a new age where creativity is becoming increasingly important. in this conceptual age we will need to foster and encourage right-directed thinking representing creativity and emotion over left-directed thinking representing logical analytical thought. however this simplification of right versus left brain thinking is not supported by the research data.nickerson provides a summary of the various creativity techniques that have been proposed. these include approaches that have been developed by both academia and industry:establishing purpose and intentionbuilding basic skillsencouraging acquisitions of domain-specific knowledgestimulating and rewarding curiosity and explorationbuilding motivation especially internal motivationencouraging confidence and a willingness to take risksfocusing on mastery and self-competitionpromoting supportable beliefs about creativityproviding opportunities for choice and discoverydeveloping self-management metacognitive skillsteaching techniques and strategies for facilitating creative performanceproviding balancemanaging the need for closureexperiments suggest the need for closure of task participants whether as a reflection of personality or induced through time pressure negatively impacts creativity. accordingly it has been suggested that reading fiction which can reduce the cognitive need for closure may help to encourage creativity.some see the conventional system of schooling as stifling of creativity and attempt particularly in the preschool/kindergarten and early school years to provide a creativity-friendly rich imagination-fostering environment for young children. researchers have seen this as important because technology is advancing our society at an unprecedented rate and creative problem solving will be needed to cope with these challenges as they arise. in addition to helping with problem solving creativity also helps students identify problems where others have failed to do so. see the waldorf school as an example of an education program that promotes creative thought.promoting intrinsic motivation and problem solving are two areas where educators can foster creativity in students. students are more creative when they see a task as intrinsically motivating valued for its own sake. to promote creative thinking educators need to identify what motivates their students and structure teaching around it. providing students with a choice of activities to complete allows them to become more intrinsically motivated and therefore creative in completing the tasks.teaching students to solve problems that do not have well defined answers is another way to foster their creativity. this is accomplished by allowing students to explore problems and redefine them possibly drawing on knowledge that at first may seem unrelated to the problem in order to solve it. in adults mentoring individuals is another way to foster their creativiy. however the benefits of mentoring creativity apply only to creative contributions considered great in a given field not to everyday creative expression.in the scottish education system creativity is identified as a core skillset for learning life and work and is defined as “a process which generates ideas that have value to the individual. it involves looking at familiar things with a fresh eye examining problems with an open mind making connections learning from mistakes and using imagination to explore new possibilities.”  the need to develop a shared language and understanding of creativity and its role across every aspect of learning teaching and continuous improvement was identified as a necessary aim  and a set of four skills is used to allow educators to discuss and develop creativity skills across all subjects and sectors of education – curiosity open—mindedness imagination and problem solving.  distinctions are made between creative learning when learners are using their creativity skills creative teaching when educators are using their creativity skills and creative change when creativity skills are applied to planning and improvement.  scotlands national creative learning plan  supports the development of creativity skills in all learners and of educators’ expertise in developing creativity skills. a range of resources have been created to support and assess this  including a national review of creativity across learning by her majestys inspectorate for education. danah zohar coined the term spiritual intelligence and introduced the idea in  in her book rewiring the corporate brain.in the same year  ken odonnell an australian author and consultant living in brazil also introduced the term spiritual intelligence in his book endoquality - the emotional and spiritual dimensions of the human being in organizations.in  in the book spiritual intelligence author steven benedict outlined the concept as a perspective offering a way to bring together the spiritual and the material that is ultimately concerned with the well-being of the universe and all who live there.howard gardner the originator of the theory of multiple intelligences chose not to include spiritual intelligence in his intelligences due to the challenge of codifying quantifiable scientific criteria. instead gardner suggested an existential intelligence as viable. however contemporary researchers continue to explore the viability of spiritual intelligence often abbreviated as sq and to create tools for measuring and developing it. so far measurement of spiritual intelligence has tended to rely on self-assessment instruments which can be susceptible to false or unreliable reporting.variations of spiritual intelligence are sometimes used in corporate settings as a means of motivating employees. and providing a non-religious diversity-sensitive framework for addressing issues of values in the workplace. according to stephen covey spiritual intelligence is the central and most fundamental of all the intelligences because it becomes the source of guidance for the others.definitions of spiritual intelligence rely on the concept of spirituality as being distinct from religiosity - existential intelligence.danah zohar defined  principles underlying spiritual intelligence:self-awareness: knowing what i believe in and value and what deeply motivates me.spontaneity: living in and being responsive to the moment.being vision- and value-led: acting from principles and deep beliefs and living accordingly.holism: seeing larger patterns relationships and connections; having a sense of belonging.compassion: having the quality of feeling-with and deep empathy.celebration of diversity: valuing other people for their differences not despite them.field independence: standing against the crowd and having ones own convictions.humility: having the sense of being a player in a larger drama of ones true place in the world.tendency to ask fundamental why questions: needing to understand things and get to the bottom of them.ability to reframe: standing back from a situation or problem and seeing the bigger picture or wider context.positive use of adversity: learning and growing from mistakes setbacks and suffering.sense of vocation: feeling called upon to serve to give something back.ken odonnell advocates the integration of spiritual intelligence sq with both rational intelligence iq and emotional intelligence eq. iq helps us to interact with numbers formulas and things eq helps us to interact with people and sq helps us to maintain inner balance. to calculate ones level of sq he suggests the following criteria:how much time money and energy and thoughts do we need to obtain a desired result.how much bilateral respect there exists in our relationships.how clean a game we play with others.how much dignity we retain in respecting the dignity of others.how tranquil we remain in spite of the workload.how sensible our decisions are.how stable we remain in upsetting situations.how easily we see virtues in others instead of defects.robert emmons defines spiritual intelligence as the adaptive use of spiritual information to facilitate everyday problem solving and goal attainment. he originally proposed  components of spiritual intelligence:the capacity to transcend the physical and material.the ability to experience heightened states of consciousness.the ability to sanctify everyday experience.the ability to utilize spiritual resources to solve problems.the capacity to be virtuous.higher level of intelligence and self awareness.early maturingcontrol over emotions.the fifth capacity was later removed due to its focus on human behavior rather than ability thereby not meeting previously established scientific criteria for intelligence.frances vaughan offers the following description: spiritual intelligence is concerned with the inner life of mind and spirit and its relationship to being in the world.cindy wigglesworth defines spiritual intelligence as the ability to act with wisdom and compassion while maintaining inner and outer peace regardless of the circumstances. she breaks down the competencies that comprise sq into  skills arranged into a four quadrant model similar to daniel golemans widely used model of emotional intelligence or eq. the four quadrants of spiritual intelligence are defined as:david b. king has undertaken research on spiritual intelligence at trent university in peterborough ontario canada. king defines spiritual intelligence as a set of adaptive mental capacities based on non-material and transcendent aspects of reality specifically those that:...contribute to the awareness integration and adaptive application of the nonmaterial and transcendent aspects of ones existence leading to such outcomes as deep existential reflection enhancement of meaning recognition of a transcendent self and mastery of spiritual states.king further proposes four core abilities or capacities of spiritual intelligence:critical existential thinking: the capacity to critically contemplate the nature of existence reality the universe space time and other existential/metaphysical issues; also the capacity to contemplate non-existential issues in relation to ones existence i.e. from an existential perspective.personal meaning production: the ability to derive personal meaning and purpose from all physical and mental experiences including the capacity to create and master a life purpose.transcendental awareness: the capacity to identify transcendent dimensions/patterns of the self i.e. a transpersonal or transcendent self of others and of the physical world e.g. nonmaterialism during normal states of consciousness accompanied by the capacity to identify their relationship to ones self and to the physical.conscious state expansion: the ability to enter and exit higher states of consciousness e.g. pure consciousness cosmic consciousness unity oneness and other states of trance at ones own discretion as in deep contemplation meditation prayer etc..also vineeth v. kumar and manju mehta have also researched the concept extensively. operationalizing the construct they defined spiritual intelligence as the capacity of an individual to possess a socially relevant purpose in life by understanding self and having a high degree of conscience compassion and commitment to human values.measurement of spiritual intelligence relies on self-reporting. david king and teresa l. decicco have developed a self-report measure the spiritual intelligence self-report inventory sisri- with psychometric and statistical support across two large university samples. cindy wigglesworth has developed the sq a self-assessment inventory that has tested positively for criterion validity and construct validity in statistically significant samples. wigglesworths sq model and assessment instrument have been successfully used in corporate settings.the scale for spiritual intelligence ssi; kumar & mehta  is a -item self-report measure of spiritual intelligence in adolescents. the idea behind the development of this scale was to generate and assess the concept of spiritual intelligence in the collectivist culture bounded with eastern philosophy. the ssi is rated on a likert scale and can be completed in  minutes. the -item spiritual intelligence questionnaire:this test was normalized by abdollahzadeh with the collaboration of mahdieh kashmiri and fatemeh arabameri on students. the normal group was  people  of whom were the students of gorgan university of natural resources and  students of payame noor university of behshahr. of these  were female and  were male. first a -item questionnaire was prepared by the test developers and implemented on  students.the reliability of the test in the initial phase was . by the alpha method. in the analysis of the question by loop method  questions were removed and the final questionnaire was adjusted with  phrases. at the final stage the questionnaire was implemented on  subjects and the reliability was . at this stage. factor analysis was used to evaluate validity in addition to formal content validity that the questions were confirmed by the experts colleagues and the correlation of all questions was higher than .. in varimax rotation two major factors were found to reduce variables. the first factor with  question was called understanding and communicating with the source of universe” and the second factor with  items was called “spiritual life or reliance on the inner core. the first factor included the questions             and the second factor included the questions                 . it has been argued that spiritual intelligence cannot be recognized as a form of intelligence. howard gardner originator of multiple intelligence theory chose not to include spiritual intelligence amongst his intelligences due to the challenge of codifying quantifiable scientific criteria. later gardner suggested an existential intelligence as viable but argued that it was better toput aside the term spiritual with its manifest and problematic connotations and to speak instead of an intelligence that explores the nature of existence in its multifarious guises. thus an explicit concern with spiritual or religious matters would be one variety — often the most important variety — of an existential intelligence.
Love encompasses a range of strong and positive emotional and mental states, from the most sublime virtue or good habit, the deepest interpersonal affection, to the simplest pleasure.[1][2] An example of this range of meanings is that the love of a mother differs from the love of a spouse, which differs from the love of food. Most commonly, love refers to a feeling of strong attraction and emotional attachment.[3]

Love is considered to be both positive and negative, with its virtue representing human kindness, compassion, and affection, as "the unselfish loyal and benevolent concern for the good of another" and its vice representing human moral flaw, akin to vanity, selfishness, amour-propre, and egotism, as potentially leading people into a type of mania, obsessiveness or codependency.[4][5] It may also describe compassionate and affectionate actions towards other humans, one's self or animals.[6] In its various forms, love acts as a major facilitator of interpersonal relationships and, owing to its central psychological importance, is one of the most common themes in the creative arts.[7] Love has been postulated to be a function that keeps human beings together against menaces and to facilitate the continuation of the species.[8]

Ancient Greek philosophers identified six forms of love: essentially, familial love (in Greek, Storge), friendly love or platonic love (Philia), romantic love (Eros), self-love (Philautia), guest love (Xenia) and divine love (Agape). Modern authors have distinguished further varieties of love: unrequited love, empty love, companionate love, consummate love, infatuated love, self-love, and courtly love. Numerous cultures have also distinguished Ren, Yuanfen, Mamihlapinatapai, Cafuné, Kama, Bhakti, Mettā, Ishq, Chesed, Amore, Charity, Saudade (and other variants or symbioses of these states), as culturally unique words, definitions, or expressions of love in regards to a specified "moments" currently lacking in the English language.[9][10][11]

Scientific research on emotion has increased significantly over the past two decades. The color wheel theory of love defines three primary, three secondary and nine tertiary love styles, describing them in terms of the traditional color wheel. The triangular theory of love suggests "intimacy, passion and commitment" are core components of love. Love has additional religious or spiritual meaning. This diversity of uses and meanings combined with the complexity of the feelings involved makes love unusually difficult to consistently define, compared to other emotional states.

Romeo and Juliet, depicted as they part on the balcony in Act III, 1867 by Ford Madox Brown
The word "love" can have a variety of related but distinct meanings in different contexts. Many other languages use multiple words to express some of the different concepts that in English are denoted as "love"; one example is the plurality of Greek words for "love" which includes agape and eros.[12] Cultural differences in conceptualizing love thus doubly impede the establishment of a universal definition.[13]

Although the nature or essence of love is a subject of frequent debate, different aspects of the word can be clarified by determining what isn't love (antonyms of "love"). Love as a general expression of positive sentiment (a stronger form of like) is commonly contrasted with hate (or neutral apathy). As a less-sexual and more-emotionally intimate form of romantic attachment, love is commonly contrasted with lust. As an interpersonal relationship with romantic overtones, love is sometimes contrasted with friendship, although the word love is often applied to close friendships or platonic love. (Further possible ambiguities come with usages "girlfriend", "boyfriend", "just good friends").


Fraternal love (Prehispanic sculpture from 250–900 AD, of Huastec origin). Museum of Anthropology in Xalapa, Veracruz, Mexico
Abstractly discussed, love usually refers to an experience one person feels for another. Love often involves caring for, or identifying with, a person or thing (cf. vulnerability and care theory of love), including oneself (cf. narcissism). In addition to cross-cultural differences in understanding love, ideas about love have also changed greatly over time. Some historians date modern conceptions of romantic love to courtly Europe during or after the Middle Ages, although the prior existence of romantic attachments is attested by ancient love poetry.[14]

The complex and abstract nature of love often reduces discourse of love to a thought-terminating cliché. Several common proverbs regard love, from Virgil's "Love conquers all" to The Beatles' "All You Need Is Love". St. Thomas Aquinas, following Aristotle, defines love as "to will the good of another."[15] Bertrand Russell describes love as a condition of "absolute value," as opposed to relative value.[citation needed] Philosopher Gottfried Leibniz said that love is "to be delighted by the happiness of another."[16] Meher Baba stated that in love there is a "feeling of unity" and an "active appreciation of the intrinsic worth of the object of love."[17] Biologist Jeremy Griffith defines love as "unconditional selflessness".[18]

Impersonal
People can be said to love an object, principle, or goal to which they are deeply committed and greatly value. For example, compassionate outreach and volunteer workers' "love" of their cause may sometimes be born not of interpersonal love but impersonal love, altruism, and strong spiritual or political convictions.[19] People can also "love" material objects, animals, or activities if they invest themselves in bonding or otherwise identifying with those things. If sexual passion is also involved, then this feeling is called paraphilia.[20] A common principle that people say they love is life itself.

Interpersonal
Together.png
Relationships
(Outline)
Types[show]
Activities[show]
Endings[show]
Emotions and feelings[hide]
AffinityAttachmentIntimacyJealousyLimerenceLove PlatonicunconditionalPassionSexuality
Practices[show]
Abuse[show]
vte
Interpersonal love refers to love between human beings. It is a much more potent sentiment than a simple liking for a person. Unrequited love refers to those feelings of love that are not reciprocated. Interpersonal love is most closely associated with Interpersonal relationships.[19] Such love might exist between family members, friends, and couples. There are also a number of psychological disorders related to love, such as erotomania. Throughout history, philosophy and religion have done the most speculation on the phenomenon of love. In the 20th century, the science of psychology has written a great deal on the subject. In recent years, the sciences of psychology, anthropology, neuroscience, and biology have added to the understanding the concept of love.

Biological basis
Main article: Biological basis of love
Biological models of sex tend to view love as a mammalian drive, much like hunger or thirst.[21] Helen Fisher, an anthropologist and human behavior researcher, divides the experience of love into three partly overlapping stages: lust, attraction, and attachment. Lust is the feeling of sexual desire; romantic attraction determines what partners mates find attractive and pursue, conserving time and energy by choosing; and attachment involves sharing a home, parental duties, mutual defense, and in humans involves feelings of safety and security.[22] Three distinct neural circuitries, including neurotransmitters, and three behavioral patterns, are associated with these three romantic styles.[22]


Pair of Lovers. 1480–1485
Lust is the initial passionate sexual desire that promotes mating, and involves the increased release of chemicals such as testosterone and estrogen. These effects rarely last more than a few weeks or months. Attraction is the more individualized and romantic desire for a specific candidate for mating, which develops out of lust as commitment to an individual mate forms. Recent studies in neuroscience have indicated that as people fall in love, the brain consistently releases a certain set of chemicals, including the neurotransmitter hormones, dopamine, norepinephrine, and serotonin, the same compounds released by amphetamine, stimulating the brain's pleasure center and leading to side effects such as increased heart rate, loss of appetite and sleep, and an intense feeling of excitement. Research has indicated that this stage generally lasts from one and a half to three years.[23]

Since the lust and attraction stages are both considered temporary, a third stage is needed to account for long-term relationships. Attachment is the bonding that promotes relationships lasting for many years and even decades. Attachment is generally based on commitments such as marriage and children, or mutual friendship based on things like shared interests. It has been linked to higher levels of the chemicals oxytocin and vasopressin to a greater degree than short-term relationships have.[23] Enzo Emanuele and coworkers reported the protein molecule known as the nerve growth factor (NGF) has high levels when people first fall in love, but these return to previous levels after one year.[24]

Psychological basis
Further information: Human bonding

Grandmother and grandchild in Sri Lanka
Psychology depicts love as a cognitive and social phenomenon. Psychologist Robert Sternberg formulated a triangular theory of love and argued that love has three different components: intimacy, commitment, and passion. Intimacy is a form in which two people share confidences and various details of their personal lives, and is usually shown in friendships and romantic love affairs. Commitment, on the other hand, is the expectation that the relationship is permanent. The last form of love is sexual attraction and passion. Passionate love is shown in infatuation as well as romantic love. All forms of love are viewed as varying combinations of these three components. Non-love does not include any of these components. Liking only includes intimacy. Infatuated love only includes passion. Empty love only includes commitment. Romantic love includes both intimacy and passion. Companionate love includes intimacy and commitment. Fatuous love includes passion and commitment. Lastly, consummate love includes all three components.[25] American psychologist Zick Rubin sought to define love by psychometrics in the 1970s. His work states that three factors constitute love: attachment, caring, and intimacy.[26][27]

Following developments in electrical theories such as Coulomb's law, which showed that positive and negative charges attract, analogs in human life were developed, such as "opposites attract". Over the last century, research on the nature of human mating has generally found this not to be true when it comes to character and personality—people tend to like people similar to themselves. However, in a few unusual and specific domains, such as immune systems, it seems that humans prefer others who are unlike themselves (e.g., with an orthogonal immune system), since this will lead to a baby that has the best of both worlds.[28] In recent years, various human bonding theories have been developed, described in terms of attachments, ties, bonds, and affinities. Some Western authorities disaggregate into two main components, the altruistic and the narcissistic. This view is represented in the works of Scott Peck, whose work in the field of applied psychology explored the definitions of love and evil. Peck maintains that love is a combination of the "concern for the spiritual growth of another," and simple narcissism.[29] In combination, love is an activity, not simply a feeling.

Psychologist Erich Fromm maintained in his book The Art of Loving that love is not merely a feeling but is also actions, and that in fact, the "feeling" of love is superficial in comparison to one's commitment to love via a series of loving actions over time.[19] In this sense, Fromm held that love is ultimately not a feeling at all, but rather is a commitment to, and adherence to, loving actions towards another, oneself, or many others, over a sustained duration.[19] Fromm also described love as a conscious choice that in its early stages might originate as an involuntary feeling, but which then later no longer depends on those feelings, but rather depends only on conscious commitment.[19]

Evolutionary basis

Wall of Love on Montmartre in Paris: "I love you" in 250 languages, by calligraphist Fédéric Baron and artist Claire Kito (2000)
Evolutionary psychology has attempted to provide various reasons for love as a survival tool. Humans are dependent on parental help for a large portion of their lifespans compared to other mammals. Love has therefore been seen as a mechanism to promote parental support of children for this extended time period. Furthermore, researchers as early as Charles Darwin himself identified unique features of human love compared to other mammals and credit love as a major factor for creating social support systems that enabled the development and expansion of the human species.[30] Another factor may be that sexually transmitted diseases can cause, among other effects, permanently reduced fertility, injury to the fetus, and increase complications during childbirth. This would favor monogamous relationships over polygamy.[31]

Comparison of scientific models
Biological models of love tend to see it as a mammalian drive, similar to hunger or thirst.[21] Psychology sees love as more of a social and cultural phenomenon. Certainly, love is influenced by hormones (such as oxytocin), neurotrophins (such as NGF), and pheromones, and how people think and behave in love is influenced by their conceptions of love. The conventional view in biology is that there are two major drives in love: sexual attraction and attachment. Attachment between adults is presumed to work on the same principles that lead an infant to become attached to its mother. The traditional psychological view sees love as being a combination of companionate love and passionate love. Passionate love is intense longing, and is often accompanied by physiological arousal (shortness of breath, rapid heart rate); companionate love is affection and a feeling of intimacy not accompanied by physiological arousal.

Cultural views
Ancient Greek
See also: Greek words for love

Roman copy of a Greek sculpture by Lysippus depicting Eros, the Greek personification of romantic love
Greek distinguishes several different senses in which the word "love" is used. Ancient Greeks identified four forms of love: kinship or familiarity (in Greek, storge), friendship and/or platonic desire (philia), sexual and/or romantic desire (eros), and self-emptying or divine love (agape).[32][33] Modern authors have distinguished further varieties of romantic love.[34] However, with Greek (as with many other languages), it has been historically difficult to separate the meanings of these words totally. At the same time, the Ancient Greek text of the Bible has examples of the verb agapo having the same meaning as phileo.

Agape (ἀγάπη agápē) means love in modern-day Greek. The term s'agapo means I love you in Greek. The word agapo is the verb I love. It generally refers to a "pure," ideal type of love, rather than the physical attraction suggested by eros. However, there are some examples of agape used to mean the same as eros. It has also been translated as "love of the soul."[35]

Eros (ἔρως érōs) (from the Greek deity Eros) is passionate love, with sensual desire and longing. The Greek word erota means in love. Plato refined his own definition. Although eros is initially felt for a person, with contemplation it becomes an appreciation of the beauty within that person, or even becomes appreciation of beauty itself. Eros helps the soul recall knowledge of beauty and contributes to an understanding of spiritual truth. Lovers and philosophers are all inspired to seek truth by eros. Some translations list it as "love of the body".[35]

Philia (φιλία philía), a dispassionate virtuous love, was a concept addressed and developed by Aristotle in his Nicomachean Ethics Book VIII.[36] It includes loyalty to friends, family, and community, and requires virtue, equality, and familiarity. Philia is motivated by practical reasons; one or both of the parties benefit from the relationship. It can also mean "love of the mind."

Storge (στοργή storgē) is natural affection, like that felt by parents for offspring.

Xenia (ξενία xenía), hospitality, was an extremely important practice in ancient Greece. It was an almost ritualized friendship formed between a host and his guest, who could previously have been strangers. The host fed and provided quarters for the guest, who was expected to repay only with gratitude. The importance of this can be seen throughout Greek mythology—in particular, Homer's Iliad and Odyssey.

Ancient Roman (Latin)
The Latin language has several different verbs corresponding to the English word "love." amō is the basic verb meaning I love, with the infinitive amare ("to love") as it still is in Italian today. The Romans used it both in an affectionate sense as well as in a romantic or sexual sense. From this verb come amans—a lover, amator, "professional lover," often with the accessory notion of lechery—and amica, "girlfriend" in the English sense, often being applied euphemistically to a prostitute. The corresponding noun is amor (the significance of this term for the Romans is well illustrated in the fact, that the name of the City, Rome—in Latin: Roma—can be viewed as an anagram for amor, which was used as the secret name of the City in wide circles in ancient times),[37] which is also used in the plural form to indicate love affairs or sexual adventures. This same root also produces amicus—"friend"—and amicitia, "friendship" (often based to mutual advantage, and corresponding sometimes more closely to "indebtedness" or "influence"). Cicero wrote a treatise called On Friendship (de Amicitia), which discusses the notion at some length. Ovid wrote a guide to dating called Ars Amatoria (The Art of Love), which addresses, in depth, everything from extramarital affairs to overprotective parents.

Latin sometimes uses amāre where English would simply say to like. This notion, however, is much more generally expressed in Latin by the terms placere or delectāre, which are used more colloquially, the latter used frequently in the love poetry of Catullus. Diligere often has the notion "to be affectionate for," "to esteem," and rarely if ever is used for romantic love. This word would be appropriate to describe the friendship of two men. The corresponding noun diligentia, however, has the meaning of "diligence" or "carefulness," and has little semantic overlap with the verb. Observare is a synonym for diligere; despite the cognate with English, this verb and its corresponding noun, observantia, often denote "esteem" or "affection." Caritas is used in Latin translations of the Christian Bible to mean "charitable love"; this meaning, however, is not found in Classical pagan Roman literature. As it arises from a conflation with a Greek word, there is no corresponding verb.

Chinese and other Sinic

愛 (Mandarin: ài), the traditional Chinese character for love contains a heart (心) in the middle.
Two philosophical underpinnings of love exist in the Chinese tradition, one from Confucianism which emphasized actions and duty while the other came from Mohism which championed a universal love. A core concept to Confucianism is 仁 (Ren, "benevolent love"), which focuses on duty, action and attitude in a relationship rather than love itself. In Confucianism, one displays benevolent love by performing actions such as filial piety from children, kindness from parents, loyalty to the king and so forth.

The concept of 愛 (Mandarin: ài) was developed by the Chinese philosopher Mozi in the 4th century BC in reaction to Confucianism's benevolent love. Mozi tried to replace what he considered to be the long-entrenched Chinese over-attachment to family and clan structures with the concept of "universal love" (兼愛, jiān'ài). In this, he argued directly against Confucians who believed that it was natural and correct for people to care about different people in different degrees. Mozi, by contrast, believed people in principle should care for all people equally. Mohism stressed that rather than adopting different attitudes towards different people, love should be unconditional and offered to everyone without regard to reciprocation; not just to friends, family and other Confucian relations. Later in Chinese Buddhism, the term Ai (愛) was adopted to refer to a passionate, caring love and was considered a fundamental desire. In Buddhism, Ai was seen as capable of being either selfish or selfless, the latter being a key element towards enlightenment.

In Mandarin Chinese, 愛 (ài) is often used as the equivalent of the Western concept of love. 愛 (ài) is used as both a verb (e.g. 我愛你, Wǒ ài nǐ, or "I love you") and a noun (such as 愛情 àiqíng, or "romantic love"). However, due to the influence of Confucian 仁 (rén), the phrase 我愛你 (Wǒ ài nǐ, I love you) carries with it a very specific sense of responsibility, commitment and loyalty. Instead of frequently saying "I love you" as in some Western societies, the Chinese are more likely to express feelings of affection in a more casual way. Consequently, "I like you" (我喜欢你, Wǒ xǐhuan nǐ) is a more common way of expressing affection in Mandarin; it is more playful and less serious.[38] This is also true in Japanese (suki da, 好きだ).

Japanese
The Japanese language uses three words to convey the English equivalent of "love". Because "love" covers a wide range of emotions and behavioral phenomena, there are nuances distinguishing the three terms.[39][40] The term ai (愛), which is often associated with maternal love[39] or selfless love,[40] originally referred to beauty and was often used in religious context. Following the Meiji Restoration 1868, the term became associated with "love" in order to translate Western literature. Prior to Western influence, the term koi (恋 or 孤悲) generally represented romantic love, and was often the subject of the popular Man'yōshū Japanese poetry collection.[39] Koi describes a longing for a member of the opposite sex and is typically interpreted as selfish and wanting.[40] The term's origins come from the concept of lonely solitude as a result of separation from a loved one. Though modern usage of koi focuses on sexual love and infatuation, the Manyō used the term to cover a wider range of situations, including tenderness, benevolence, and material desire.[39] The third term, ren'ai (恋愛), is a more modern construction that combines the kanji characters for both ai and koi, though its usage more closely resembles that of koi in the form of romantic love.[39][40]

Indian

Hindu god Krishna and his consort Radha making love
In contemporary literature, the Sanskrit words for love is sneha. Other terms such as Priya refers to innocent love, Prema refers to spiritual love, and Kama refers usually to sexual desire.[41][42] However, the term also refers to any sensory enjoyment, emotional attraction and aesthetic pleasure such as from arts, dance, music, painting, sculpture and nature.[43][44]

The concept of kama is found in some of the earliest known verses in Vedas. For example, Book 10 of Rig Veda describes the creation of the universe from nothing by the great heat. There in hymn 129, it states:

कामस्तदग्रे समवर्तताधि मनसो रेतः परथमं यदासीत |
सतो बन्धुमसति निरविन्दन हर्दि परतीष्याकवयो मनीषा ||[45]

Thereafter rose Desire in the beginning, Desire the primal seed and germ of Spirit,
Sages who searched with their heart's thought discovered the existent's kinship in the non-existent.

— Rig Veda, ~ 15th century BC[46]
Persian
The children of Adam are limbs of one body
Having been created of one essence.
When the calamity of time afflicts one limb
The other limbs cannot remain at rest.
If you have no sympathy for the troubles of others
You are not worthy to be called by the name of "man".

Sa'di, Gulistan   
Rumi, Hafiz and Sa'di are icons of the passion and love that the Persian culture and language present.[citation needed] The Persian word for love is Ishq, which is derived from Arabic language; however, it is considered by most to be too stalwart a term for interpersonal love and is more commonly substituted for "doost dashtan" ("liking").[citation needed] In the Persian culture, everything is encompassed by love and all is for love, starting from loving friends and family, husbands and wives, and eventually reaching the divine love that is the ultimate goal in life.[citation needed]

Aziz Nasafi, a famous Muslim mystic from Central Asia and Iran, wrote the “Epistle on Love” (Risala fi’l ‘Ishq) in his work The Book of the Perfect Man (Kitab Insan al-Kamil). In the epistle, he describes love as an emotion that is fostered in an individual for the beloved through four stages. These four stages are inclination (mayl), desire (iradat), affection (mahabbat) and love (‘ishq). He explains that these four stages lead the lover on a journey through which his love for his beloved progressively strengthens, until he becomes completely immersed in the beloved and the beloved becomes a part of him.[47]

Religious views
Main article: Religious views on love
Abrahamic

Robert Indiana's 1977 Love sculpture spelling ahava
Judaism
See also: Jewish views on love
In Hebrew, אהבה (ahava) is the most commonly used term for both interpersonal love and love between God and God's creations. Chesed, often translated as loving-kindness, is used to describe many forms of love between human beings.

The commandment to love other people is given in the Torah, which states, "Love your neighbor like yourself" (Leviticus 19:18). The Torah's commandment to love God "with all your heart, with all your soul and with all your might" (Deuteronomy 6:5) is taken by the Mishnah (a central text of the Jewish oral law) to refer to good deeds, willingness to sacrifice one's life rather than commit certain serious transgressions, willingness to sacrifice all of one's possessions, and being grateful to the Lord despite adversity (tractate Berachoth 9:5). Rabbinic literature differs as to how this love can be developed, e.g., by contemplating divine deeds or witnessing the marvels of nature.

As for love between marital partners, this is deemed an essential ingredient to life: "See life with the wife you love" (Ecclesiastes 9:9). Rabbi David Wolpe writes that "...love is not only about the feelings of the lover...It is when one person believes in another person and shows it." He further states that "...love...is a feeling that expresses itself in action. What we really feel is reflected in what we do."[48] The biblical book Song of Solomon is considered a romantically phrased metaphor of love between God and his people, but in its plain reading, reads like a love song. The 20th-century rabbi Eliyahu Eliezer Dessler is frequently quoted as defining love from the Jewish point of view as "giving without expecting to take" (from his Michtav me-Eliyahu, Vol. 1).

Christianity
The Christian understanding is that love comes from God. The love of man and woman—eros in Greek—and the unselfish love of others (agape), are often contrasted as "descending" and "ascending" love, respectively, but are ultimately the same thing.[49]

There are several Greek words for "love" that are regularly referred to in Christian circles.

Agape: In the New Testament, agapē is charitable, selfless, altruistic, and unconditional. It is parental love, seen as creating goodness in the world; it is the way God is seen to love humanity, and it is seen as the kind of love that Christians aspire to have for one another.[35]
Phileo: Also used in the New Testament, phileo is a human response to something that is found to be delightful. Also known as "brotherly love."
Two other words for love in the Greek language, eros (sexual love) and storge (child-to-parent love), were never used in the New Testament.[35]
Christians believe that to Love God with all your heart, mind, and strength and Love your neighbor as yourself are the two most important things in life (the greatest commandment of the Jewish Torah, according to Jesus; cf. Gospel of Mark chapter 12, verses 28–34). Saint Augustine summarized this when he wrote "Love God, and do as thou wilt."

The Apostle Paul glorified love as the most important virtue of all. Describing love in the famous poetic interpretation in 1 Corinthians, he wrote, "Love is patient, love is kind. It does not envy, it does not boast, it is not proud. It is not rude, it is not self-seeking, it is not easily angered, it keeps no record of wrongs. Love does not delight in evil but rejoices with the truth. It always protects, always trusts, always hopes, and always perseveres." (1 Cor. 13:4–7, NIV)

The Apostle John wrote, "For God so loved the world that he gave his one and only Son, that whoever believes in him shall not perish but have eternal life. For God did not send his Son into the world to condemn the world, but to save the world through him." (John 3:16–17, NIV) John also wrote, "Dear friends, let us love one another for love comes from God. Everyone who loves has been born of God and knows God. Whoever does not love does not know God, because God is love." (1 John 4:7–8, NIV)


Sacred and Profane Love (1602–03) by Giovanni Baglione. Intended as an attack on his hated enemy the artist Caravaggio, it shows a boy (hinting at Caravaggio's homosexuality) on one side, a devil with Caravaggio's face on the other, and between an angel representing pure, meaning non-erotic, love.[50]
Saint Augustine says that one must be able to decipher the difference between love and lust. Lust, according to Saint Augustine, is an overindulgence, but to love and be loved is what he has sought for his entire life. He even says, "I was in love with love." Finally, he does fall in love and is loved back, by God. Saint Augustine says the only one who can love you truly and fully is God, because love with a human only allows for flaws such as "jealousy, suspicion, fear, anger, and contention." According to Saint Augustine, to love God is "to attain the peace which is yours." (Saint Augustine's Confessions)

Augustine regards the duplex commandment of love in Matthew 22 as the heart of Christian faith and the interpretation of the Bible. After the review of Christian doctrine, Augustine treats the problem of love in terms of use and enjoyment until the end of Book I of De Doctrina Christiana (1.22.21–1.40.44;).[51]

Christian theologians see God as the source of love, which is mirrored in humans and their own loving relationships. Influential Christian theologian C. S. Lewis wrote a book called The Four Loves. Benedict XVI named his first encyclical God is love. He said that a human being, created in the image of God, who is love, is able to practice love; to give himself to God and others (agape) and by receiving and experiencing God's love in contemplation (eros). This life of love, according to him, is the life of the saints such as Teresa of Calcutta and the Blessed Virgin Mary and is the direction Christians take when they believe that God loves them.[49]

Pope Francis taught that "True love is both loving and letting oneself be loved...what is important in love is not our loving, but allowing ourselves to be loved by God."[52] And so, in the analysis of a Catholic theologian, for Pope Francis, "the key to love...is not our activity. It is the activity of the greatest, and the source, of all the powers in the universe: God's."[53]

In Christianity the practical definition of love is summarised by St. Thomas Aquinas, who defined love as "to will the good of another," or to desire for another to succeed.[15] This is an explanation of the Christian need to love others, including their enemies. As Thomas Aquinas explains, Christian love is motivated by the need to see others succeed in life, to be good people.

Regarding love for enemies, Jesus is quoted in the Gospel of Matthew chapter five:

"You have heard that it was said, 'Love your neighbor and hate your enemy.' But I tell you, love your enemies and pray for those who persecute you, that you may be children of your Father in heaven. He causes his sun to rise on the evil and the good, and sends rain on the righteous and the unrighteous. If you love those who love you, what reward will you get? Are not even the tax collectors doing that? And if you greet only your own people, what are you doing more than others? Do not even pagans do that? Be perfect, therefore, as your heavenly Father is perfect." – Matthew 5: 43–48.

Do not forget to love with forgiveness, Christ saved an adulterous woman from those who would stone her. A world of wronged hypocrites needs forgiving love. Mosaic Law would hold Deuteronomy 22:22-24 "If a man is found lying with a woman married to a husband, then both of them shall die—the man that lay with the woman, and the woman; so you shall put away the evil from Israel. If a young woman who is a virgin is betrothed to a husband, and a man finds her in the city and lies with her, then you shall bring them both out to the gate of that city, and you shall stone them to death with stones, the young woman because she did not cry out in the city, and the man because he humbled his neighbor's wife; so you shall put away the evil from among you."[54][circular reference]

Tertullian wrote regarding love for enemies: "Our individual, extraordinary, and perfect goodness consists in loving our enemies. To love one's friends is common practice, to love one's enemies only among Christians."[55]

Islam
Al-Wadūd or The Loving is a name of God in Islam.
In Islam, one of the 99 names of God is Al-Wadūd, which means "The Loving"
Love encompasses the Islamic view of life as universal brotherhood that applies to all who hold faith. Amongst the 99 names of God (Allah), there is the name Al-Wadud, or "the Loving One," which is found in Surah [Quran 11:90] as well as Surah [Quran 85:14]. God is also referenced at the beginning of every chapter in the Qur'an as Ar-Rahman and Ar-Rahim, or the "Most Compassionate" and the "Most Merciful", indicating that nobody is more loving, compassionate and benevolent than God. The Qur'an refers to God as being "full of loving kindness."

The Qur'an exhorts Muslim believers to treat all people, those who have not persecuted them, with birr or "deep kindness" as stated in Surah [Quran 6:8-9]. Birr is also used by the Qur'an in describing the love and kindness that children must show to their parents.

Ishq, or divine love, is the emphasis of Sufism in the Islamic tradition. Practitioners of Sufism believe that love is a projection of the essence of God to the universe. God desires to recognize beauty, and as if one looks at a mirror to see oneself, God "looks" at himself within the dynamics of nature. Since everything is a reflection of God, the school of Sufism practices to see the beauty inside the apparently ugly. Sufism is often referred to as the religion of love.[56] God in Sufism is referred to in three main terms, which are the Lover, Loved, and Beloved, with the last of these terms being often seen in Sufi poetry. A common viewpoint of Sufism is that through love, humankind can get back to its inherent purity and grace. The saints of Sufism are infamous for being "drunk" due to their love of God; hence, the constant reference to wine in Sufi poetry and music.

Aziz Nasafi, a famous Muslim mystic from Central Asia and Iran, wrote the “Epistle on Love” (Risala fi’l Ishq) in his work, The Book of the Perfect Man (Kitab Insan al-Kamil). In the epistle, he draws parallels between love and the remembrance of God. He explains that both love and remembrance have four stages. These four stages are inclination (mayl), desire (iradat), affection (mahabbat) and love (‘ishq). He explains that these four stages lead the lover on a journey through which his love for his beloved progressively strengthens, until he becomes completely immersed in the beloved and the beloved becomes a part of him. Similarly, a ‘rememberer’ (of God) progresses through the stages until God becomes predominant in his heart.[47]

Bahá'í Faith
In his Paris Talks, `Abdu'l-Bahá described four types of love: the love that flows from God to human beings; the love that flows from human beings to God; the love of God towards the Self or Identity of God; and the love of human beings for human beings.[57]

Indian
Buddhism
In Buddhism, Kāma is sensuous, sexual love. It is an obstacle on the path to enlightenment, since it is selfish. Karuṇā is compassion and mercy, which reduces the suffering of others. It is complementary to wisdom and is necessary for enlightenment. Adveṣa and mettā are benevolent love. This love is unconditional and requires considerable self-acceptance. This is quite different from ordinary love, which is usually about attachment and sex and which rarely occurs without self-interest. Instead, in Buddhism it refers to detachment and unselfish interest in others' welfare.

The Bodhisattva ideal in Mahayana Buddhism involves the complete renunciation of oneself in order to take on the burden of a suffering world. The strongest motivation one has in order to take the path of the Bodhisattva is the idea of salvation within unselfish, altruistic love for all sentient beings.

Hinduism
Main articles: Kama and Kama Sutra

Kama (left) with Rati on a temple wall of Chennakesava Temple, Belur
In Hinduism, kāma is pleasurable, sexual love, personified by the god Kamadeva. For many Hindu schools, it is the third end (Kama) in life. Kamadeva is often pictured holding a bow of sugar cane and an arrow of flowers; he may ride upon a great parrot. He is usually accompanied by his consort Rati and his companion Vasanta, lord of the spring season. Stone images of Kamadeva and Rati can be seen on the door of the Chennakeshava temple at Belur, in Karnataka, India. Maara is another name for kāma.

In contrast to kāma, prema – or prem – refers to elevated love. Karuna is compassion and mercy, which impels one to help reduce the suffering of others. Bhakti is a Sanskrit term, meaning "loving devotion to the supreme God." A person who practices bhakti is called a bhakta. Hindu writers, theologians, and philosophers have distinguished nine forms of bhakti, which can be found in the Bhagavata Purana and works by Tulsidas. The philosophical work Narada Bhakti Sutras, written by an unknown author (presumed to be Narada), distinguishes eleven forms of love.

In certain Vaishnava sects within Hinduism, attaining unadulterated, unconditional and incessant love for Godhead is considered the foremost goal of life. Gaudiya Vaishnavas who worship Krishna as the Supreme Personality of Godhead and the cause of all causes consider Love for Godhead (Prema) to act in two ways: sambhoga and vipralambha (union and separation)—two opposites.[58]

In the condition of separation, there is an acute yearning for being with the beloved and in the condition of union, there is supreme happiness and nectarean. Gaudiya Vaishnavas consider that Krishna-prema (Love for Godhead) is not fire but that it still burns away one's material desires. They consider that Kṛṣṇa-prema is not a weapon, but it still pierces the heart. It is not water, but it washes away everything—one's pride, religious rules, and one's shyness. Krishna-prema is considered to make one drown in the ocean of transcendental ecstasy and pleasure. The love of Radha, a cowherd girl, for Krishna is often cited as the supreme example of love for Godhead by Gaudiya Vaishnavas. Radha is considered to be the internal potency of Krishna, and is the supreme lover of Godhead. Her example of love is considered to be beyond the understanding of material realm as it surpasses any form of selfish love or lust that is visible in the material world. The reciprocal love between Radha (the supreme lover) and Krishna (God as the Supremely Loved) is the subject of many poetic compositions in India such as the Gita Govinda and Hari Bhakti Shuddhodhaya.

In the Bhakti tradition within Hinduism, it is believed that execution of devotional service to God leads to the development of Love for God (taiche bhakti-phale krsne prema upajaya), and as love for God increases in the heart, the more one becomes free from material contamination (krishna-prema asvada haile, bhava nasa paya). Being perfectly in love with God or Krishna makes one perfectly free from material contamination. and this is the ultimate way of salvation or liberation. In this tradition, salvation or liberation is considered inferior to love, and just an incidental by-product. Being absorbed in Love for God is considered to be the perfection of life.[59]

Political views
Free love
Main article: Free love
The term "free love" has been used[60] to describe a social movement that rejects marriage, which is seen as a form of social bondage. The Free Love movement's initial goal was to separate the state from sexual matters such as marriage, birth control, and adultery. It claimed that such issues were the concern of the people involved, and no one else.[61]

Many people in the early 19th century believed that marriage was an important aspect of life to "fulfill earthly human happiness." Middle-class Americans wanted the home to be a place of stability in an uncertain world. This mentality created a vision of strongly defined gender roles, which provoked the advancement of the free love movement as a contrast.[62]

The term "sex radical" has been used interchangeably with the term "free lover".[citation needed] By whatever name, advocates had two strong beliefs: opposition to the idea of forceful sexual activity in a relationship and advocacy for a woman to use her body in any way that she pleases.[63] These are also beliefs of Feminism.[64]

Philosophical views
Main article: Philosophy of love

Graffiti in East Timor
The philosophy of love is a field of social philosophy and ethics that attempts to explain the nature of love.[65] The philosophical investigation of love includes the tasks of distinguishing between the various kinds of personal love, asking if and how love is or can be justified, asking what the value of love is, and what impact love has on the autonomy of both the lover and the beloved.[64]

Emotions are biological states associated with the nervous system[1][2][3] brought on by neurophysiological changes variously associated with thoughts, feelings, behavioural responses, and a degree of pleasure or displeasure.[4][5] There is currently no scientific consensus on a definition. Emotions are often intertwined with mood, temperament, personality, disposition, creativity,[6] and motivation.[7]

Research on emotion has increased significantly over the past two decades with many fields contributing including psychology, neuroscience, affective neuroscience, endocrinology, medicine, history, sociology of emotions, and computer science. The numerous theories that attempt to explain the origin, neurobiology, experience, and function of emotions have only fostered more intense research on this topic. Current areas of research in the concept of emotion include the development of materials that stimulate and elicit emotion. In addition, PET scans and fMRI scans help study the affective picture processes in the brain.[8]

From a purely mechanistic perspective, emotions can be defined as "a positive or negative experience that is associated with a particular pattern of physiological activity." Emotions produce different physiological, behavioral and cognitive changes. The original role of emotions was to motivate adaptive behaviors that in the past would have contributed to the passing on of genes through survival, reproduction, and kin selection.[9][10]

In some theories, cognition is an important aspect of emotion. For those who act primarily on emotions, they may assume that they are not thinking, but mental processes involving cognition are still essential, particularly in the interpretation of events. For example, the realization of our believing that we are in a dangerous situation and the subsequent arousal of our body's nervous system (rapid heartbeat and breathing, sweating, muscle tension) is integral to the experience of our feeling afraid. Other theories, however, claim that emotion is separate from and can precede cognition. Consciously experiencing an emotion is exhibiting a mental representation of that emotion from a past or hypothetical experience, which is linked back to a content state of pleasure or displeasure.[11] The content states are established by verbal explanations of experiences, describing an internal state.[12]

Emotions are complex. According to some theories, they are states of feeling that result in physical and psychological changes that influence our behavior.[5] The physiology of emotion is closely linked to arousal of the nervous system with various states and strengths of arousal relating, apparently, to particular emotions. Emotion is also linked to behavioral tendency. Extroverted people are more likely to be social and express their emotions, while introverted people are more likely to be more socially withdrawn and conceal their emotions. Emotion is often the driving force behind motivation, positive or negative.[13] According to other theories, emotions are not causal forces but simply syndromes of components, which might include motivation, feeling, behavior, and physiological changes, but no one of these components is the emotion. Nor is the emotion an entity that causes these components.[14]

Emotions involve different components, such as subjective experience, cognitive processes, expressive behavior, psychophysiological changes, and instrumental behavior. At one time, academics attempted to identify the emotion with one of the components: William James with a subjective experience, behaviorists with instrumental behavior, psychophysiologists with physiological changes, and so on. More recently, emotion is said to consist of all the components. The different components of emotion are categorized somewhat differently depending on the academic discipline. In psychology and philosophy, emotion typically includes a subjective, conscious experience characterized primarily by psychophysiological expressions, biological reactions, and mental states. A similar multi-componential description of emotion is found in sociology. For example, Peggy Thoits[15] described emotions as involving physiological components, cultural or emotional labels (anger, surprise, etc.), expressive body actions, and the appraisal of situations and contexts.

Human nature and the following bodily sensations have been always part of the interest of thinkers and philosophers. Far most extensively, this interest has been of great interest by both Western and Eastern societies. Emotional states have been associated with the divine and the enlightenment of the human mind and body.[16] The ever changing actions of individuals and its mood variations have been of great importance by most of the Western philosophers (Aristotle, Plato, Descartes, Aquinas, Hobbes) that lead them to propose vast theories; often competing theories, that sought to explain emotion and the following motivators of human action and its consequences.

In the Age of Enlightenment Scottish thinker David Hume[17] proposed a revolutionary argument that sought to explain the main motivators of human action and conduct. He proposed that actions are motivated by "fears, desires, and passions". As he wrote in his book Treatise of Human Nature (1773): "Reason alone can never be a motive to any action of the will… it can never oppose passion in the direction of the will… Reason is, and ought to be the slave of the passions, and can never pretend to any other office than to serve and obey them".[18] With these lines Hume pretended to explain that reason and further action will be subjected to the desires and experience of the self. Later thinkers would propose that actions and emotions are deeply interrelated to social, political, historical, and cultural aspects of reality that would be also associated with sophisticated neurological and physiological research on the brain and other parts of the physical body.

Etymology

Sixteen faces expressing the human passions-coloured engraving by J. Pass, 1821, after Charles Le Brun
The word "emotion" dates back to 1579, when it was adapted from the French word émouvoir, which means "to stir up". The term emotion was introduced into academic discussion as a catch-all term to passions, sentiments and affections.[19] The word "emotion" was coined in the early 1800s by Thomas Brown and it is around the 1830s that the modern concept of emotion first emerged for the English language.[20] "No one felt emotions before about 1830. Instead they felt other things - "passions", "accidents of the soul", "moral sentiments" - and explained them very differently from how we understand emotions today."[20]

Some cross-cultural studies indicate that the categorization of "emotion" and classification of basic emotions such as "anger" and "sadness" are not universal and that the boundaries and domains of these concepts are categorized differently by all cultures.[21] However, others argue that there are some universal bases of emotions (see Section 6.1).[22] In psychiatry and psychology, an inability to express or perceive emotion is sometimes referred to as alexithymia.[23]

Definitions
The Oxford Dictionaries definition of emotion is "A strong feeling deriving from one's circumstances, mood, or relationships with others."[24] Emotions are responses to significant internal and external events.[25]

Emotions can be occurrences (e.g., panic) or dispositions (e.g., hostility), and short-lived (e.g., anger) or long-lived (e.g., grief).[26] Psychotherapist Michael C. Graham describes all emotions as existing on a continuum of intensity.[27] Thus fear might range from mild concern to terror or shame might range from simple embarrassment to toxic shame.[28] Emotions have been described as consisting of a coordinated set of responses, which may include verbal, physiological, behavioral, and neural mechanisms.[29]

Emotions have been categorized, with some relationships existing between emotions and some direct opposites existing. Graham differentiates emotions as functional or dysfunctional and argues all functional emotions have benefits.[30]

In some uses of the word, emotions are intense feelings that are directed at someone or something.[31] On the other hand, emotion can be used to refer to states that are mild (as in annoyed or content) and to states that are not directed at anything (as in anxiety and depression). One line of research looks at the meaning of the word emotion in everyday language and finds that this usage is rather different from that in academic discourse.[32]

In practical terms, Joseph LeDoux has defined emotions as the result of a cognitive and conscious process which occurs in response to a body system response to a trigger.[33]

Components
According to Scherer's Component Process Model (CPM) of emotion,[34] there are five crucial elements of emotion. From the component process perspective, emotional experience requires that all of these processes become coordinated and synchronized for a short period of time, driven by appraisal processes. Although the inclusion of cognitive appraisal as one of the elements is slightly controversial, since some theorists make the assumption that emotion and cognition are separate but interacting systems, the CPM provides a sequence of events that effectively describes the coordination involved during an emotional episode.

Cognitive appraisal: provides an evaluation of events and objects.
Bodily symptoms: the physiological component of emotional experience.
Action tendencies: a motivational component for the preparation and direction of motor responses.
Expression: facial and vocal expression almost always accompanies an emotional state to communicate reaction and intention of actions.
Feelings: the subjective experience of emotional state once it has occurred.
Differentiation
See also: Affect measures § Differentiating affect from other terms
Emotion can be differentiated from a number of similar constructs within the field of affective neuroscience:[29]

Feeling; not all feelings include emotion, such as the feeling of knowing. In the context of emotion, feelings are best understood as a subjective representation of emotions, private to the individual experiencing them.[35][better source needed]
Moods are diffuse affective states that generally last for much longer durations than emotions, are also usually less intense than emotions and often appear to lack a contextual stimulus.[31]
Affect is used to describe the underlying affective experience of an emotion or a mood.
Purpose and value
One view is that emotions facilitate adaptive responses to environmental challenges. Emotions have been described as a result of evolution because they provided good solutions to ancient and recurring problems that faced our ancestors.[36] Emotions can function as a way to communicate what's important to us, such as values and ethics.[37] However some emotions, such as some forms of anxiety, are sometimes regarded as part of a mental illness and thus possibly of negative value.[38]

Classification
Main article: Emotion classification
A distinction can be made between emotional episodes and emotional dispositions. Emotional dispositions are also comparable to character traits, where someone may be said to be generally disposed to experience certain emotions. For example, an irritable person is generally disposed to feel irritation more easily or quickly than others do. Finally, some theorists place emotions within a more general category of "affective states" where affective states can also include emotion-related phenomena such as pleasure and pain, motivational states (for example, hunger or curiosity), moods, dispositions and traits.[39]

Basic emotions

Examples of basic emotions

The emotion wheel.
For more than 40 years, Paul Ekman has supported the view that emotions are discrete, measurable, and physiologically distinct. Ekman's most influential work revolved around the finding that certain emotions appeared to be universally recognized, even in cultures that were preliterate and could not have learned associations for facial expressions through media. Another classic study found that when participants contorted their facial muscles into distinct facial expressions (for example, disgust), they reported subjective and physiological experiences that matched the distinct facial expressions. Ekman's facial-expression research examined six basic emotions: anger, disgust, fear, happiness, sadness and surprise.[40] Later in his career,[41] Ekman theorized that other universal emotions may exist beyond these six. In light of this, recent cross-cultural studies led by Daniel Cordaro and Dacher Keltner, both former students of Ekman, extended the list of universal emotions. In addition to the original six, these studies provided evidence for amusement, awe, contentment, desire, embarrassment, pain, relief, and sympathy in both facial and vocal expressions. They also found evidence for boredom, confusion, interest, pride, and shame facial expressions, as well as contempt, relief, and triumph vocal expressions.[42][43][44]

Robert Plutchik agreed with Ekman's biologically driven perspective but developed the "wheel of emotions", suggesting eight primary emotions grouped on a positive or negative basis: joy versus sadness; anger versus fear; trust versus disgust; and surprise versus anticipation.[45] Some basic emotions can be modified to form complex emotions. The complex emotions could arise from cultural conditioning or association combined with the basic emotions. Alternatively, similar to the way primary colors combine, primary emotions could blend to form the full spectrum of human emotional experience. For example, interpersonal anger and disgust could blend to form contempt. Relationships exist between basic emotions, resulting in positive or negative influences.[46]

Multi-dimensional analysis
Sorting emotions into unpleasant-pleasant and activated-calm.
Two dimensions of emotions. Made accessible for practical use.[47]

Two dimensions of emotion
Psychologists have used methods such as factor analysis to attempt to map emotion-related responses onto a more limited number of dimensions. Such methods attempt to boil emotions down to underlying dimensions that capture the similarities and differences between experiences.[48] Often, the first two dimensions uncovered by factor analysis are valence (how negative or positive the experience feels) and arousal (how energized or enervated the experience feels). These two dimensions can be depicted on a 2D coordinate map.[49] This two-dimensional map has been theorized to capture one important component of emotion called core affect.[50][51] Core affect is not theorized to be the only component to emotion, but to give the emotion its hedonic and felt energy.

Using statistical methods to analyze emotional states elicited by short videos, Cowen and Keltner identified 27 varieties of emotional experience: admiration, adoration, aesthetic appreciation, amusement, anger, anxiety, awe, awkwardness, boredom, calmness, confusion, craving, disgust, empathic pain, entrancement, excitement, fear, horror, interest, joy, nostalgia, relief, romance, sadness, satisfaction, sexual desire and surprise.[52]

Theories
See also: Functional accounts of emotion
Pre-modern history
In Buddhism, emotions occur when an object is considered as attractive or repulsive. There is a felt tendency impelling people towards attractive objects and impelling them to move away from repulsive or harmful objects; a disposition to possess the object (greed), to destroy it (hatred), to flee from it (fear), to get obsessed or worried over it (anxiety), and so on.[53]

In stoic theories it was seen as a hindrance to reason and therefore a hindrance to virtue. Aristotle believed that emotions were an essential component of virtue.[54] In the Aristotelian view all emotions (called passions) corresponded to appetites or capacities. During the Middle Ages, the Aristotelian view was adopted and further developed by scholasticism and Thomas Aquinas[55] in particular.

In Chinese antiquity, excessive emotion was believed to cause damage to qi, which in turn, damages the vital organs.[56] The four humours theory made popular by Hippocrates contributed to the study of emotion in the same way that it did for medicine.

In the early 11th century, Avicenna theorized about the influence of emotions on health and behaviors, suggesting the need to manage emotions.[57]

Early modern views on emotion are developed in the works of philosophers such as René Descartes, Niccolò Machiavelli, Baruch Spinoza,[58] Thomas Hobbes[59] and David Hume. In the 19th century emotions were considered adaptive and were studied more frequently from an empiricist psychiatric perspective.

Western theological
Christian perspective on emotion presupposes a theistic origin to humanity. God who created humans gave humans the ability to feel emotion and interact emotionally. Biblical content expresses that God is a person who feels and expresses emotion. Though a somatic view would place the locus of emotions in the physical body, Christian theory of emotions would view the body more as a platform for the sensing and expression of emotions. Therefore emotions themselves arise from the person, or that which is "imago-dei" or image of God in humans. In Christian thought, emotions have the potential to be controlled through reasoned reflection. That reasoned reflection also mimics God who made mind. The purpose of emotions in human life are therefore summarized in God's call to enjoy Him and creation, humans are to enjoy emotions and benefit from them and use them to energize behavior.

Evolutionary theories
Main articles: Evolution of emotion and Evolutionary psychology

Illustration from Charles Darwin's The Expression of the Emotions in Man and Animals (1872)
19th century
Perspectives on emotions from evolutionary theory were initiated during the mid-late 19th century with Charles Darwin's 1872 book The Expression of the Emotions in Man and Animals.[60] Surprisingly, Darwin argued that emotions served no evolved purpose for humans, neither in communication, nor in aiding survival.[61] Darwin largely argued that emotions evolved via the inheritance of acquired characters.[62] He pioneered various methods for studying non-verbal expressions, from which he concluded that some expressions had cross-cultural universality. Darwin also detailed homologous expressions of emotions that occur in animals. This led the way for animal research on emotions and the eventual determination of the neural underpinnings of emotion.

Contemporary
More contemporary views along the evolutionary psychology spectrum posit that both basic emotions and social emotions evolved to motivate (social) behaviors that were adaptive in the ancestral environment.[13] Emotion is an essential part of any human decision-making and planning, and the famous distinction made between reason and emotion is not as clear as it seems.[63] Paul D. MacLean claims that emotion competes with even more instinctive responses, on one hand, and the more abstract reasoning, on the other hand. The increased potential in neuroimaging has also allowed investigation into evolutionarily ancient parts of the brain. Important neurological advances were derived from these perspectives in the 1990s by Joseph E. LeDoux and António Damásio.

Research on social emotion also focuses on the physical displays of emotion including body language of animals and humans (see affect display). For example, spite seems to work against the individual but it can establish an individual's reputation as someone to be feared.[13] Shame and pride can motivate behaviors that help one maintain one's standing in a community, and self-esteem is one's estimate of one's status.[13][64]

Somatic theories
Somatic theories of emotion claim that bodily responses, rather than cognitive interpretations, are essential to emotions. The first modern version of such theories came from William James in the 1880s. The theory lost favor in the 20th century, but has regained popularity more recently due largely to theorists such as John Cacioppo,[65] António Damásio,[66] Joseph E. LeDoux[67] and Robert Zajonc[68] who are able to appeal to neurological evidence.[69]

James–Lange theory
Main article: James–Lange theory

Simplified graph of James-Lange Theory of Emotion
In his 1884 article[70] William James argued that feelings and emotions were secondary to physiological phenomena. In his theory, James proposed that the perception of what he called an "exciting fact" directly led to a physiological response, known as "emotion."[71] To account for different types of emotional experiences, James proposed that stimuli trigger activity in the autonomic nervous system, which in turn produces an emotional experience in the brain. The Danish psychologist Carl Lange also proposed a similar theory at around the same time, and therefore this theory became known as the James–Lange theory. As James wrote, "the perception of bodily changes, as they occur, is the emotion." James further claims that "we feel sad because we cry, angry because we strike, afraid because we tremble, and either we cry, strike, or tremble because we are sorry, angry, or fearful, as the case may be."[70]

An example of this theory in action would be as follows: An emotion-evoking stimulus (snake) triggers a pattern of physiological response (increased heart rate, faster breathing, etc.), which is interpreted as a particular emotion (fear). This theory is supported by experiments in which by manipulating the bodily state induces a desired emotional state.[72] Some people may believe that emotions give rise to emotion-specific actions, for example, "I'm crying because I'm sad," or "I ran away because I was scared." The issue with the James–Lange theory is that of causation (bodily states causing emotions and being a priori), not that of the bodily influences on emotional experience (which can be argued and is still quite prevalent today in biofeedback studies and embodiment theory).[73]

Although mostly abandoned in its original form, Tim Dalgleish argues that most contemporary neuroscientists have embraced the components of the James-Lange theory of emotions.[74]

The James–Lange theory has remained influential. Its main contribution is the emphasis it places on the embodiment of emotions, especially the argument that changes in the bodily concomitants of emotions can alter their experienced intensity. Most contemporary neuroscientists would endorse a modified James–Lange view in which bodily feedback modulates the experience of emotion. (p. 583)

Cannon–Bard theory
Main article: Cannon–Bard theory
Walter Bradford Cannon agreed that physiological responses played a crucial role in emotions, but did not believe that physiological responses alone could explain subjective emotional experiences. He argued that physiological responses were too slow and often imperceptible and this could not account for the relatively rapid and intense subjective awareness of emotion.[75] He also believed that the richness, variety, and temporal course of emotional experiences could not stem from physiological reactions, that reflected fairly undifferentiated fight or flight responses.[76][77] An example of this theory in action is as follows: An emotion-evoking event (snake) triggers simultaneously both a physiological response and a conscious experience of an emotion.

Phillip Bard contributed to the theory with his work on animals. Bard found that sensory, motor, and physiological information all had to pass through the diencephalon (particularly the thalamus), before being subjected to any further processing. Therefore, Cannon also argued that it was not anatomically possible for sensory events to trigger a physiological response prior to triggering conscious awareness and emotional stimuli had to trigger both physiological and experiential aspects of emotion simultaneously.[76]

Two-factor theory
Main article: Two-factor theory of emotion
Stanley Schachter formulated his theory on the earlier work of a Spanish physician, Gregorio Marañón, who injected patients with epinephrine and subsequently asked them how they felt. Marañón found that most of these patients felt something but in the absence of an actual emotion-evoking stimulus, the patients were unable to interpret their physiological arousal as an experienced emotion. Schachter did agree that physiological reactions played a big role in emotions. He suggested that physiological reactions contributed to emotional experience by facilitating a focused cognitive appraisal of a given physiologically arousing event and that this appraisal was what defined the subjective emotional experience. Emotions were thus a result of two-stage process: general physiological arousal, and experience of emotion. For example, the physiological arousal, heart pounding, in a response to an evoking stimulus, the sight of a bear in the kitchen. The brain then quickly scans the area, to explain the pounding, and notices the bear. Consequently, the brain interprets the pounding heart as being the result of fearing the bear.[78] With his student, Jerome Singer, Schachter demonstrated that subjects can have different emotional reactions despite being placed into the same physiological state with an injection of epinephrine. Subjects were observed to express either anger or amusement depending on whether another person in the situation (a confederate) displayed that emotion. Hence, the combination of the appraisal of the situation (cognitive) and the participants' reception of adrenaline or a placebo together determined the response. This experiment has been criticized in Jesse Prinz's (2004) Gut Reactions.[79]

Cognitive theories
With the two-factor theory now incorporating cognition, several theories began to argue that cognitive activity in the form of judgments, evaluations, or thoughts were entirely necessary for an emotion to occur. One of the main proponents of this view was Richard Lazarus who argued that emotions must have some cognitive intentionality. The cognitive activity involved in the interpretation of an emotional context may be conscious or unconscious and may or may not take the form of conceptual processing.

Lazarus' theory is very influential; emotion is a disturbance that occurs in the following order:

Cognitive appraisal – The individual assesses the event cognitively, which cues the emotion.
Physiological changes – The cognitive reaction starts biological changes such as increased heart rate or pituitary adrenal response.
Action – The individual feels the emotion and chooses how to react.
For example: Jenny sees a snake.

Jenny cognitively assesses the snake in her presence. Cognition allows her to understand it as a danger.
Her brain activates the adrenal glands which pump adrenaline through her blood stream, resulting in increased heartbeat.
Jenny screams and runs away.
Lazarus stressed that the quality and intensity of emotions are controlled through cognitive processes. These processes underline coping strategies that form the emotional reaction by altering the relationship between the person and the environment.

George Mandler provided an extensive theoretical and empirical discussion of emotion as influenced by cognition, consciousness, and the autonomic nervous system in two books (Mind and Emotion, 1975,[80] and Mind and Body: Psychology of Emotion and Stress, 1984[81])

There are some theories on emotions arguing that cognitive activity in the form of judgments, evaluations, or thoughts are necessary in order for an emotion to occur. A prominent philosophical exponent is Robert C. Solomon (for example, The Passions, Emotions and the Meaning of Life, 1993[82]). Solomon claims that emotions are judgments. He has put forward a more nuanced view which responds to what he has called the 'standard objection' to cognitivism, the idea that a judgment that something is fearsome can occur with or without emotion, so judgment cannot be identified with emotion. The theory proposed by Nico Frijda where appraisal leads to action tendencies is another example.

It has also been suggested that emotions (affect heuristics, feelings and gut-feeling reactions) are often used as shortcuts to process information and influence behavior.[83] The affect infusion model (AIM) is a theoretical model developed by Joseph Forgas in the early 1990s that attempts to explain how emotion and mood interact with one's ability to process information.

Perceptual theory
Theories dealing with perception either use one or multiples perceptions in order to find an emotion.[84] A recent hybrid of the somatic and cognitive theories of emotion is the perceptual theory. This theory is neo-Jamesian in arguing that bodily responses are central to emotions, yet it emphasizes the meaningfulness of emotions or the idea that emotions are about something, as is recognized by cognitive theories. The novel claim of this theory is that conceptually-based cognition is unnecessary for such meaning. Rather the bodily changes themselves perceive the meaningful content of the emotion because of being causally triggered by certain situations. In this respect, emotions are held to be analogous to faculties such as vision or touch, which provide information about the relation between the subject and the world in various ways. A sophisticated defense of this view is found in philosopher Jesse Prinz's book Gut Reactions,[79] and psychologist James Laird's book Feelings.[72]

Affective events theory
Affective events theory is a communication-based theory developed by Howard M. Weiss and Russell Cropanzano (1996),[85] that looks at the causes, structures, and consequences of emotional experience (especially in work contexts). This theory suggests that emotions are influenced and caused by events which in turn influence attitudes and behaviors. This theoretical frame also emphasizes time in that human beings experience what they call emotion episodes –\ a "series of emotional states extended over time and organized around an underlying theme." This theory has been utilized by numerous researchers to better understand emotion from a communicative lens, and was reviewed further by Howard M. Weiss and Daniel J. Beal in their article, "Reflections on Affective Events Theory", published in Research on Emotion in Organizations in 2005.[86]

Situated perspective on emotion
A situated perspective on emotion, developed by Paul E. Griffiths and Andrea Scarantino, emphasizes the importance of external factors in the development and communication of emotion, drawing upon the situationism approach in psychology.[87] This theory is markedly different from both cognitivist and neo-Jamesian theories of emotion, both of which see emotion as a purely internal process, with the environment only acting as a stimulus to the emotion. In contrast, a situationist perspective on emotion views emotion as the product of an organism investigating its environment, and observing the responses of other organisms. Emotion stimulates the evolution of social relationships, acting as a signal to mediate the behavior of other organisms. In some contexts, the expression of emotion (both voluntary and involuntary) could be seen as strategic moves in the transactions between different organisms. The situated perspective on emotion states that conceptual thought is not an inherent part of emotion, since emotion is an action-oriented form of skillful engagement with the world. Griffiths and Scarantino suggested that this perspective on emotion could be helpful in understanding phobias, as well as the emotions of infants and animals.

Genetics
Emotions can motivate social interactions and relationships and therefore are directly related with basic physiology, particularly with the stress systems. This is important because emotions are related to the anti-stress complex, with an oxytocin-attachment system, which plays a major role in bonding. Emotional phenotype temperaments affect social connectedness and fitness in complex social systems.[88] These characteristics are shared with other species and taxa and are due to the effects of genes and their continuous transmission. Information that is encoded in the DNA sequences provides the blueprint for assembling proteins that make up our cells. Zygotes require genetic information from their parental germ cells, and at every speciation event, heritable traits that have enabled its ancestor to survive and reproduce successfully are passed down along with new traits that could be potentially beneficial to the offspring.

In the five million years since the lineages leading to modern humans and chimpanzees split, only about 1.2% of their genetic material has been modified. This suggests that everything that separates us from chimpanzees must be encoded in that very small amount of DNA, including our behaviors. Students that study animal behaviors have only identified intraspecific examples of gene-dependent behavioral phenotypes. In voles (Microtus spp.) minor genetic differences have been identified in a vasopressin receptor gene that corresponds to major species differences in social organization and the mating system.[89] Another potential example with behavioral differences is the FOCP2 gene, which is involved in neural circuitry handling speech and language.[90] Its present form in humans differed from that of the chimpanzees by only a few mutations and has been present for about 200,000 years, coinciding with the beginning of modern humans.[91] Speech, language, and social organization are all part of the basis for emotions.

Formation

Timeline of some of the most prominent brain models of emotion in affective neuroscience.
Neurobiological explanation
Based on discoveries made through neural mapping of the limbic system, the neurobiological explanation of human emotion is that emotion is a pleasant or unpleasant mental state organized in the limbic system of the mammalian brain. If distinguished from reactive responses of reptiles, emotions would then be mammalian elaborations of general vertebrate arousal patterns, in which neurochemicals (for example, dopamine, noradrenaline, and serotonin) step-up or step-down the brain's activity level, as visible in body movements, gestures and postures. Emotions can likely be mediated by pheromones (see fear).[35]

For example, the emotion of love is proposed to be the expression of Paleocircuits of the mammalian brain (specifically, modules of the cingulate gyrus) which facilitate the care, feeding, and grooming of offspring. Paleocircuits are neural platforms for bodily expression configured before the advent of cortical circuits for speech. They consist of pre-configured pathways or networks of nerve cells in the forebrain, brain stem and spinal cord.

Other emotions like fear and anxiety long thought to be exclusively generated by the most primitive parts of the brain (stem) and more associated to the fight-or-flight responses of behavior, have also been associated as adaptive expressions of defensive behavior whenever a threat is encountered. Although defensive behaviors have been present in a wide variety of species, Blanchard et al. (2001) discovered a correlation of given stimuli and situation that resulted in a similar pattern of defensive behavior towards a threat in human and non-human mammals.[92]

Whenever, potentially dangerous stimuli is presented additional brain structures activate that previously thought (hippocampus, thalamus, etc). Thus, giving the amygdala an important role on coordinating the following behavioral input based on the presented neurotransmitters that respond to threat stimuli. These biological functions of the amygdala are not only limited to the "fear-conditioning" and "processing of aversive stimuli", but also are present on other components of the amygdala. Therefore, it can referred the amygdala as a key structure to understand the potential responses of behavior in danger like situations in human and non-human mammals.[93]

The motor centers of reptiles react to sensory cues of vision, sound, touch, chemical, gravity, and motion with pre-set body movements and programmed postures. With the arrival of night-active mammals, smell replaced vision as the dominant sense, and a different way of responding arose from the olfactory sense, which is proposed to have developed into mammalian emotion and emotional memory. The mammalian brain invested heavily in olfaction to succeed at night as reptiles slept – one explanation for why olfactory lobes in mammalian brains are proportionally larger than in the reptiles. These odor pathways gradually formed the neural blueprint for what was later to become our limbic brain.[35]

Emotions are thought to be related to certain activities in brain areas that direct our attention, motivate our behavior, and determine the significance of what is going on around us. Pioneering work by Paul Broca (1878),[94] James Papez (1937),[95] and Paul D. MacLean (1952)[96] suggested that emotion is related to a group of structures in the center of the brain called the limbic system, which includes the hypothalamus, cingulate cortex, hippocampi, and other structures. More recent research has shown that some of these limbic structures are not as directly related to emotion as others are while some non-limbic structures have been found to be of greater emotional relevance.

Prefrontal cortex
There is ample evidence that the left prefrontal cortex is activated by stimuli that cause positive approach.[97] If attractive stimuli can selectively activate a region of the brain, then logically the converse should hold, that selective activation of that region of the brain should cause a stimulus to be judged more positively. This was demonstrated for moderately attractive visual stimuli[98] and replicated and extended to include negative stimuli.[99]

Two neurobiological models of emotion in the prefrontal cortex made opposing predictions. The valence model predicted that anger, a negative emotion, would activate the right prefrontal cortex. The direction model predicted that anger, an approach emotion, would activate the left prefrontal cortex. The second model was supported.[100]

This still left open the question of whether the opposite of approach in the prefrontal cortex is better described as moving away (direction model), as unmoving but with strength and resistance (movement model), or as unmoving with passive yielding (action tendency model). Support for the action tendency model (passivity related to right prefrontal activity) comes from research on shyness[101] and research on behavioral inhibition.[102] Research that tested the competing hypotheses generated by all four models also supported the action tendency model.[103][104]


Homeostatic/primordial emotion
Another neurological approach proposed by Bud Craig in 2003 distinguishes two classes of emotion: "classical" emotions such as love, anger and fear that are evoked by environmental stimuli, and "homeostatic emotions" – attention-demanding feelings evoked by body states, such as pain, hunger and fatigue, that motivate behavior (withdrawal, eating or resting in these examples) aimed at maintaining the body's internal milieu at its ideal state.[105]

Derek Denton calls the latter "primordial emotions" and defines them as "the subjective element of the instincts, which are the genetically programmed behavior patterns which contrive homeostasis. They include thirst, hunger for air, hunger for food, pain and hunger for specific minerals etc. There are two constituents of a primordial emotion--the specific sensation which when severe may be imperious, and the compelling intention for gratification by a consummatory act."[106]

Emergent explanation
Joseph LeDoux differentiates between the human's defense system, which has evolved over time, and emotions such as fear and anxiety. He has said that the amygdala may release hormones due to a trigger (such as an innate reaction to seeing a snake), but "then we elaborate it through cognitive and conscious processes".[33]

Lisa Feldman Barrett highlights differences in emotions between different cultures,[107] and says that emotions (such as anxiety) "are not triggered; you create them. They emerge as a combination of the physical properties of your body, a flexible brain that wires itself to whatever environment it develops in, and your culture and upbringing, which provide that environment."[108] She has termed this approach the theory of constructed emotion.

Disciplinary approaches
Many different disciplines have produced work on the emotions. Human sciences study the role of emotions in mental processes, disorders, and neural mechanisms. In psychiatry, emotions are examined as part of the discipline's study and treatment of mental disorders in humans. Nursing studies emotions as part of its approach to the provision of holistic health care to humans. Psychology examines emotions from a scientific perspective by treating them as mental processes and behavior and they explore the underlying physiological and neurological processes. In neuroscience sub-fields such as social neuroscience and affective neuroscience, scientists study the neural mechanisms of emotion by combining neuroscience with the psychological study of personality, emotion, and mood. In linguistics, the expression of emotion may change to the meaning of sounds. In education, the role of emotions in relation to learning is examined.

Social sciences often examine emotion for the role that it plays in human culture and social interactions. In sociology, emotions are examined for the role they play in human society, social patterns and interactions, and culture. In anthropology, the study of humanity, scholars use ethnography to undertake contextual analyses and cross-cultural comparisons of a range of human activities. Some anthropology studies examine the role of emotions in human activities. In the field of communication sciences, critical organizational scholars have examined the role of emotions in organizations, from the perspectives of managers, employees, and even customers. A focus on emotions in organizations can be credited to Arlie Russell Hochschild's concept of emotional labor. The University of Queensland hosts EmoNet,[109] an e-mail distribution list representing a network of academics that facilitates scholarly discussion of all matters relating to the study of emotion in organizational settings. The list was established in January 1997 and has over 700 members from across the globe.

In economics, the social science that studies the production, distribution, and consumption of goods and services, emotions are analyzed in some sub-fields of microeconomics, in order to assess the role of emotions on purchase decision-making and risk perception. In criminology, a social science approach to the study of crime, scholars often draw on behavioral sciences, sociology, and psychology; emotions are examined in criminology issues such as anomie theory and studies of "toughness," aggressive behavior, and hooliganism. In law, which underpins civil obedience, politics, economics and society, evidence about people's emotions is often raised in tort law claims for compensation and in criminal law prosecutions against alleged lawbreakers (as evidence of the defendant's state of mind during trials, sentencing, and parole hearings). In political science, emotions are examined in a number of sub-fields, such as the analysis of voter decision-making.

In philosophy, emotions are studied in sub-fields such as ethics, the philosophy of art (for example, sensory–emotional values, and matters of taste and sentimentality), and the philosophy of music (see also music and emotion). In history, scholars examine documents and other sources to interpret and analyze past activities; speculation on the emotional state of the authors of historical documents is one of the tools of interpretation. In literature and film-making, the expression of emotion is the cornerstone of genres such as drama, melodrama, and romance. In communication studies, scholars study the role that emotion plays in the dissemination of ideas and messages. Emotion is also studied in non-human animals in ethology, a branch of zoology which focuses on the scientific study of animal behavior. Ethology is a combination of laboratory and field science, with strong ties to ecology and evolution. Ethologists often study one type of behavior (for example, aggression) in a number of unrelated animals.

History
The history of emotions has become an increasingly popular topic recently, with some scholars[who?] arguing that it is an essential category of analysis, not unlike class, race, or gender. Historians, like other social scientists, assume that emotions, feelings and their expressions are regulated in different ways by both different cultures and different historical times, and the constructivist school of history claims even that some sentiments and meta-emotions, for example schadenfreude, are learnt and not only regulated by culture. Historians of emotion trace and analyze the changing norms and rules of feeling, while examining emotional regimes, codes, and lexicons from social, cultural, or political history perspectives. Others focus on the history of medicine, science, or psychology. What somebody can and may feel (and show) in a given situation, towards certain people or things, depends on social norms and rules; thus historically variable and open to change.[110] Several research centers have opened in the past few years in Germany, England, Spain,[111] Sweden, and Australia.

Furthermore, research in historical trauma suggests that some traumatic emotions can be passed on from parents to offspring to second and even third generation, presented as examples of transgenerational trauma.

Sociology
Main article: Sociology of emotions
A common way in which emotions are conceptualized in sociology is in terms of the multidimensional characteristics including cultural or emotional labels (for example, anger, pride, fear, happiness), physiological changes (for example, increased perspiration, changes in pulse rate), expressive facial and body movements (for example, smiling, frowning, baring teeth), and appraisals of situational cues.[15] One comprehensive theory of emotional arousal in humans has been developed by Jonathan Turner (2007: 2009).[112][113] Two of the key eliciting factors for the arousal of emotions within this theory are expectations states and sanctions. When people enter a situation or encounter with certain expectations for how the encounter should unfold, they will experience different emotions depending on the extent to which expectations for Self, other and situation are met or not met. People can also provide positive or negative sanctions directed at Self or other which also trigger different emotional experiences in individuals. Turner analyzed a wide range of emotion theories across different fields of research including sociology, psychology, evolutionary science, and neuroscience. Based on this analysis, he identified four emotions that all researchers consider being founded on human neurology including assertive-anger, aversion-fear, satisfaction-happiness, and disappointment-sadness. These four categories are called primary emotions and there is some agreement amongst researchers that these primary emotions become combined to produce more elaborate and complex emotional experiences. These more elaborate emotions are called first-order elaborations in Turner's theory and they include sentiments such as pride, triumph, and awe. Emotions can also be experienced at different levels of intensity so that feelings of concern are a low-intensity variation of the primary emotion aversion-fear whereas depression is a higher intensity variant.

Attempts are frequently made to regulate emotion according to the conventions of the society and the situation based on many (sometimes conflicting) demands and expectations which originate from various entities. The expression of anger is in many cultures discouraged in girls and women to a greater extent than in boys and men (the notion being that an angry man has a valid complaint that needs to be rectified, while an angry women is hysterical or oversensitive, and her anger is somehow invalid), while the expression of sadness or fear is discouraged in boys and men relative to girls and women (attitudes implicit in phrases like "man up" or "don't be a sissy").[114][115] Expectations attached to social roles, such as "acting as man" and not as a woman, and the accompanying "feeling rules" contribute to the differences in expression of certain emotions. Some cultures encourage or discourage happiness, sadness, or jealousy, and the free expression of the emotion of disgust is considered socially unacceptable in most cultures. Some social institutions are seen as based on certain emotion, such as love in the case of contemporary institution of marriage. In advertising, such as health campaigns and political messages, emotional appeals are commonly found. Recent examples include no-smoking health campaigns and political campaigns emphasizing the fear of terrorism.[116]

Sociological attention to emotion has varied over time. Émile Durkheim (1915/1965)[117] wrote about the collective effervescence or emotional energy that was experienced by members of totemic rituals in Australian aborigine society. He explained how the heightened state of emotional energy achieved during totemic rituals transported individuals above themselves giving them the sense that they were in the presence of a higher power, a force, that was embedded in the sacred objects that were worshipped. These feelings of exaltation, he argued, ultimately lead people to believe that there were forces that governed sacred objects.

In the 1990s, sociologists focused on different aspects of specific emotions and how these emotions were socially relevant. For Cooley (1992),[118] pride and shame were the most important emotions that drive people to take various social actions. During every encounter, he proposed that we monitor ourselves through the "looking glass" that the gestures and reactions of others provide. Depending on these reactions, we either experience pride or shame and this results in particular paths of action. Retzinger (1991)[119] conducted studies of married couples who experienced cycles of rage and shame. Drawing predominantly on Goffman and Cooley's work, Scheff (1990)[120] developed a micro sociological theory of the social bond. The formation or disruption of social bonds is dependent on the emotions that people experience during interactions.

Subsequent to these developments, Randall Collins (2004)[121] formulated his interaction ritual theory by drawing on Durkheim's work on totemic rituals that was extended by Goffman (1964/2013; 1967)[122][123] into everyday focused encounters. Based on interaction ritual theory, we experience different levels or intensities of emotional energy during face-to-face interactions. Emotional energy is considered to be a feeling of confidence to take action and a boldness that one experiences when they are charged up from the collective effervescence generated during group gatherings that reach high levels of intensity.

There is a growing body of research applying the sociology of emotion to understanding the learning experiences of students during classroom interactions with teachers and other students (for example, Milne & Otieno, 2007;[124] Olitsky, 2007;[125] Tobin, et al., 2013;[126] Zembylas, 2002[127]). These studies show that learning subjects like science can be understood in terms of classroom interaction rituals that generate emotional energy and collective states of emotional arousal like emotional climate.

Apart from interaction ritual traditions of the sociology of emotion, other approaches have been classed into one of six other categories:[113]

evolutionary/biological theories
symbolic interactionist theories
dramaturgical theories
ritual theories
power and status theories
stratification theories
exchange theories
This list provides a general overview of different traditions in the sociology of emotion that sometimes conceptualise emotion in different ways and at other times in complementary ways. Many of these different approaches were synthesized by Turner (2007) in his sociological theory of human emotions in an attempt to produce one comprehensive sociological account that draws on developments from many of the above traditions.[112]

[90] [91] [89]

Psychotherapy and regulation
Emotion regulation refers to the cognitive and behavioral strategies people use to influence their own emotional experience.[128] For example, a behavioral strategy in which one avoids a situation to avoid unwanted emotions (trying not to think about the situation, doing distracting activities, etc.).[129] Depending on the particular school's general emphasis on either cognitive components of emotion, physical energy discharging, or on symbolic movement and facial expression components of emotion different schools of psychotherapy approach the regulation of emotion differently. Cognitively oriented schools approach them via their cognitive components, such as rational emotive behavior therapy. Yet others approach emotions via symbolic movement and facial expression components (like in contemporary Gestalt therapy).[130]

Cross-cultural research
Research on emotions reveals the strong presence of cross-cultural differences in emotional reactions and that emotional reactions are likely to be culture-specific.[131] In strategic settings, cross-cultural research on emotions is required for understanding the psychological situation of a given population or specific actors. This implies the need to comprehend the current emotional state, mental disposition or other behavioral motivation of a target audience located in a different culture, basically founded on its national political, social, economic, and psychological peculiarities but also subject to the influence of circumstances and events.[132]

Computer science
Main article: Affective computing
In the 2000s, research in computer science, engineering, psychology and neuroscience has been aimed at developing devices that recognize human affect display and model emotions.[133] In computer science, affective computing is a branch of the study and development of artificial intelligence that deals with the design of systems and devices that can recognize, interpret, and process human emotions. It is an interdisciplinary field spanning computer sciences, psychology, and cognitive science.[134] While the origins of the field may be traced as far back as to early philosophical enquiries into emotion,[70] the more modern branch of computer science originated with Rosalind Picard's 1995 paper[135] on affective computing.[136][137] Detecting emotional information begins with passive sensors which capture data about the user's physical state or behavior without interpreting the input. The data gathered is analogous to the cues humans use to perceive emotions in others. Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions. Emotional speech processing recognizes the user's emotional state by analyzing speech patterns. The detection and processing of facial expression or body gestures is achieved through detectors and sensors.

The effects on memory
Emotion affects the way autobiographical memories are encoded and retrieved. Emotional memories are reactivated more, they are remembered better and have more attention devoted to them.[138] Through remembering our past achievements and failures, autobiographical memories affect how we perceive and feel about ourselves.[139]

Notable theorists

William James
In the late 19th century, the most influential theorists were William James (1842–1910) and Carl Lange (1834–1900). James was an American psychologist and philosopher who wrote about educational psychology, psychology of religious experience/mysticism, and the philosophy of pragmatism. Lange was a Danish physician and psychologist. Working independently, they developed the James–Lange theory, a hypothesis on the origin and nature of emotions. The theory states that within human beings, as a response to experiences in the world, the autonomic nervous system creates physiological events such as muscular tension, a rise in heart rate, perspiration, and dryness of the mouth. Emotions, then, are feelings which come about as a result of these physiological changes, rather than being their cause.[140]

Silvan Tomkins (1911–1991) developed the affect theory and script theory. The affect theory introduced the concept of basic emotions, and was based on the idea that the dominance of the emotion, which he called the affected system, was the motivating force in human life.[141]

Artificial intelligence (AI), is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals, which involves consciousness and emotionality. The distinction between the former and the latter categories is often revealed by the acronym chosen. 'Strong' AI is usually labelled as AGI (Artificial General Intelligence) while attempts to emulate 'natural' intelligence have been called ABI (Artificial Biological Intelligence). Leading AI textbooks define the field as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[3] Colloquially, the term "artificial intelligence" is often used to describe machines (or computers) that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving".[4]

As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect.[5] A quip in Tesler's Theorem says "AI is whatever hasn't been done yet."[6] For instance, optical character recognition is frequently excluded from things considered to be AI,[7] having become a routine technology.[8] Modern machine capabilities generally classified as AI include successfully understanding human speech,[9] competing at the highest level in strategic game systems (such as chess and Go),[10] autonomously operating cars, intelligent routing in content delivery networks, and military simulations.[11]

Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism,[12][13] followed by disappointment and the loss of funding (known as an "AI winter"),[14][15] followed by new approaches, success and renewed funding.[13][16] After AlphaGo successfully defeated a professional Go player in 2015, artificial intelligence once again attracted widespread global attention.[17] For most of its history, AI research has been divided into sub-fields that often fail to communicate with each other.[18] These sub-fields are based on technical considerations, such as particular goals (e.g. "robotics" or "machine learning"),[19] the use of particular tools ("logic" or artificial neural networks), or deep philosophical differences.[22][23][24] Sub-fields have also been based on social factors (particular institutions or the work of particular researchers).[18]

The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.[19] General intelligence is among the field's long-term goals.[25] Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.

The field was founded on the assumption that human intelligence "can be so precisely described that a machine can be made to simulate it".[26] This raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity.[31] Some people also consider AI to be a danger to humanity if it progresses unabated.[32][33] Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.[34]

In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.[35][16]

Silver didrachma from Crete depicting Talos, an ancient mythical automaton with artificial intelligence
Thought-capable artificial beings appeared as storytelling devices in antiquity,[36] and have been common in fiction, as in Mary Shelley's Frankenstein or Karel Čapek's R.U.R.[37] These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.[31]

The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis.[38] Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed changing the question from whether a machine was intelligent, to "whether or not it is possible for machinery to show intelligent behaviour".[39] The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".[40]

The field of AI research was born at a workshop at Dartmouth College in 1956,[41] where the term "Artificial Intelligence" was coined by John McCarthy to distinguish the field from cybernetics and escape the influence of the cyberneticist Norbert Wiener.[42] Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research.[43] They and their students produced programs that the press described as "astonishing":[44] computers were learning checkers strategies (c. 1954)[45] (and by 1959 were reportedly playing better than the average human),[46] solving word problems in algebra, proving logical theorems (Logic Theorist, first run c. 1956) and speaking English.[47] By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[48] and laboratories had been established around the world.[49] AI's founders were optimistic about the future: Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do". Marvin Minsky agreed, writing, "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".[12]

They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill[50] and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an "AI winter",[14] a period when obtaining funding for AI projects was difficult.

In the early 1980s, AI research was revived by the commercial success of expert systems,[51] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research.[13] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began.[15]

The development of metal–oxide–semiconductor (MOS) very-large-scale integration (VLSI), in the form of complementary MOS (CMOS) transistor technology, enabled the development of practical artificial neural network (ANN) technology in the 1980s. A landmark publication in the field was the 1989 book Analog VLSI Implementation of Neural Systems by Carver A. Mead and Mohammed Ismail.[52]

In the late 1990s and early 21st century, AI began to be used for logistics, data mining, medical diagnosis and other areas.[35] The success was due to increasing computational power (see Moore's law and transistor count), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards.[53] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[54]

In 2011, a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[55] Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.[56] The Kinect, which provides a 3D body–motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from lengthy AI research[57] as do intelligent personal assistants in smartphones.[58] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[10][59] In the 2017 Future of Go Summit, AlphaGo won a three-game match with Ke Jie,[60] who at the time continuously held the world No. 1 ranking for two years.[61][62] This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is a relatively complex game, more so than Chess.

According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a "sporadic usage" in 2012 to more than 2,700 projects. Clark also presents factual data indicating the improvements of AI since 2012 supported by lower error rates in image processing tasks.[63] He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets.[16] Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people.[63] In a 2017 survey, one in five companies reported they had "incorporated AI in some offerings or processes".[64][65] Around 2016, China greatly accelerated its government funding; given its large supply of data and its rapidly increasing research output, some observers believe it may be on track to becoming an "AI superpower".[66][67] However, it has been acknowledged that reports regarding artificial intelligence have tended to be exaggerated.[68][69][70]

Basics
Computer science defines AI research as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[3] A more elaborate definition characterizes AI as "a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation."[71]

A typical AI analyzes its environment and takes actions that maximize its chance of success.[3] An AI's intended utility function (or goal) can be simple ("1 if the AI wins a game of Go, 0 otherwise") or complex ("Perform actions mathematically similar to ones that succeeded in the past"). Goals can be explicitly defined or induced. If the AI is programmed for "reinforcement learning", goals can be implicitly induced by rewarding some types of behavior or punishing others.[a] Alternatively, an evolutionary system can induce goals by using a "fitness function" to mutate and preferentially replicate high-scoring AI systems, similar to how animals evolved to innately desire certain goals such as finding food.[72] Some AI systems, such as nearest-neighbor, instead of reason by analogy, these systems are not generally given goals, except to the degree that goals are implicit in their training data.[73] Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task.[74]

AI often revolves around the use of algorithms. An algorithm is a set of unambiguous instructions that a mechanical computer can execute.[b] A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following (optimal for first player) recipe for play at tic-tac-toe:[75]

If someone has a "threat" (that is, two in a row), take the remaining square. Otherwise,
if a move "forks" to create two threats at once, play that move. Otherwise,
take the center square if it is free. Otherwise,
if your opponent has played in a corner, take the opposite corner. Otherwise,
take an empty corner if one exists. Otherwise,
take any empty square.
Many AI algorithms are capable of learning from data; they can enhance themselves by learning new heuristics (strategies, or "rules of thumb", that have worked well in the past), or can themselves write other algorithms. Some of the "learners" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, (given infinite data, time, and memory) learn to approximate any function, including which combination of mathematical functions would best describe the world.[citation needed] These learners could therefore derive all possible knowledge, by considering every possible hypothesis and matching them against the data. In practice, it is seldom possible to consider every possibility, because of the phenomenon of "combinatorial explosion", where the time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering a broad range of possibilities unlikely to be beneficial.[76][77] For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding a pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered.[78]

The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): "If an otherwise healthy adult has a fever, then they may have influenza". A second, more general, approach is Bayesian inference: "If the current patient has a fever, adjust the probability they have influenza in such-and-such way". The third major approach, extremely popular in routine business AI applications, are analogizers such as SVM and nearest-neighbor: "After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial "neurons" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to "reinforce" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms; the best approach is often different depending on the problem.[79][80]

Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". They can be nuanced, such as "X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist". Learners also work on the basis of "Occam's razor": The simplest theory that explains the data is the likeliest. Therefore, according to Occam's razor principle, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better.


The blue line could be an example of overfitting a linear function due to random noise.
Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is.[81] Besides classic overfitting, learners can also disappoint by "learning the wrong lesson". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[82] A real-world example is that, unlike humans, current image classifiers often don't primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in "adversarial" images that the system misclassifies.[c][83][84]


A self-driving car system may use a neural network to determine which parts of the picture seem to match previous training images of pedestrians, and then model those areas as slow-moving but somewhat unpredictable rectangular prisms that must be avoided.
Compared with humans, existing AI lacks several features of human "commonsense reasoning"; most notably, humans have powerful mechanisms for reasoning about "naïve physics" such as space, time, and physical interactions. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". Humans also have a powerful mechanism of "folk psychology" that helps them to interpret natural-language sentences such as "The city councilmen refused the demonstrators a permit because they advocated violence" (A generic AI has difficulty discerning whether the ones alleged to be advocating violence are the councilmen or the demonstrators[85][86][87]). This lack of "common knowledge" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents.[88][89][90]

Challenges
The cognitive capabilities of current architectures are very limited, using only a simplified version of what intelligence is really capable of. For instance, the human mind has come up with ways to reason beyond measure and logical explanations to different occurrences in life. What would have been otherwise straightforward, an equivalently difficult problem may be challenging to solve computationally as opposed to using the human mind. This gives rise to two classes of models: structuralist and functionalist. The structural models aim to loosely mimic the basic intelligence operations of the mind such as reasoning and logic. The functional model refers to the correlating data to its computed counterpart.[91]

The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.[19]

Reasoning, problem solving
Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[92] By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.[93]

These algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger.[76] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[94]

Knowledge representation

An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.
Main articles: Knowledge representation and Commonsense knowledge
Knowledge representation[95] and knowledge engineering[96] are central to classical AI research. Some "expert systems" attempt to gather explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects;[97] situations, events, states and time;[98] causes and effects;[99] knowledge about knowledge (what we know about what other people know);[100] and many other, less well researched domains. A representation of "what exists" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The semantics of these are captured as description logic concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the Web Ontology Language.[101] The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge[102] by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval,[103] scene interpretation,[104] clinical decision support,[105] knowledge discovery (mining "interesting" and actionable inferences from large databases),[106] and other areas.[107]

Among the most difficult problems in knowledge representation are:

Default reasoning and the qualification problem
Many of the things people know take the form of "working assumptions". For example, if a bird comes up in conversation, people typically picture a fist-sized animal that sings and flies. None of these things are true about all birds. John McCarthy identified this problem in 1969[108] as the qualification problem: for any commonsense rule that AI researchers care to represent, there tend to be a huge number of exceptions. Almost nothing is simply true or false in the way that abstract logic requires. AI research has explored a number of solutions to this problem.[109]
Breadth of commonsense knowledge
The number of atomic facts that the average person knows is very large. Research projects that attempt to build a complete knowledge base of commonsense knowledge (e.g., Cyc) require enormous amounts of laborious ontological engineering—they must be built, by hand, one complicated concept at a time.[110]
Subsymbolic form of some commonsense knowledge
Much of what people know is not represented as "facts" or "statements" that they could express verbally. For example, a chess master will avoid a particular chess position because it "feels too exposed"[111] or an art critic can take one look at a statue and realize that it is a fake.[112] These are non-conscious and sub-symbolic intuitions or tendencies in the human brain.[113] Knowledge like this informs, supports and provides a context for symbolic, conscious knowledge. As with the related problem of sub-symbolic reasoning, it is hoped that situated AI, computational intelligence, or statistical AI will provide ways to represent this knowledge.[113]
Planning

A hierarchical control system is a form of control system in which a set of devices and governing software is arranged in a hierarchy.
Main article: Automated planning and scheduling
Intelligent agents must be able to set goals and achieve them.[114] They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.[115]

In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.[116] However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment.[117]

Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.[118]

Learning
Main article: Machine learning

For this project the AI had to find the typical patterns in the colors and brushstrokes of Renaissance painter Raphael. The portrait shows the face of the actress Ornella Muti, "painted" by AI in the style of Raphael.
Machine learning (ML), a fundamental concept of AI research since the field's inception,[d] is the study of computer algorithms that improve automatically through experience.[e][121]

Unsupervised learning is the ability to find patterns in a stream of input, without requiring a human to label the inputs first. Supervised learning includes both classification and numerical regression, which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change.[121] Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[122] In reinforcement learning[123] the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.

Natural language processing

A parse tree represents the syntactic structure of a sentence according to some formal grammar.
Main article: Natural language processing
Natural language processing[124] (NLP) allows machines to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, question answering[125] and machine translation.[126] Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to assess the sentiment of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning.[127] By 2019, transformer-based deep learning architectures could generate coherent text.[128]

Perception
Main articles: Machine perception, Computer vision, and Speech recognition

Feature detection (pictured: edge detection) helps AI compose informative abstract structures out of raw data.
Machine perception[129] is the ability to use input from sensors (such as cameras (visible spectrum or infrared), microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition,[130] facial recognition, and object recognition.[131] Computer vision is the ability to analyze visual input. Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its "object model" to assess that fifty-meter pedestrians do not exist.[132]

Motion and manipulation
Main article: Robotics
AI is heavily used in robotics.[133] Advanced robotic arms and other industrial robots, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage.[134] A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge. Motion planning is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object.[135][136][137] Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that "it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility".[138][139] This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of natural selection for millions of years.[140]

Social intelligence
Main article: Affective computing

Kismet, a robot with rudimentary social skills[141]
Moravec's paradox can be extended to many forms of social intelligence.[142][143] Distributed multi-agent coordination of autonomous vehicles remains a difficult problem.[144] Affective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human affects.[145][146][147] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal affect analysis (see multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.[148]

In the long run, social skills and an understanding of human emotion and game theory would be valuable to a social agent. The ability to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.[149] Similarly, some virtual assistants are programmed to speak conversationally or even to banter humorously; this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[150]

General intelligence
Main articles: Artificial general intelligence and AI-complete
Historically, projects such as the Cyc knowledge base (1984–) and the massive Japanese Fifth Generation Computer Systems initiative (1982–1992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, most current AI researchers work instead on tractable "narrow AI" applications (such as medical diagnosis or automobile navigation).[151] Many researchers predict that such "narrow AI" work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas.[25][152] Many advances have general, cross-domain significance. One high-profile example is that DeepMind in the 2010s developed a "generalized artificial intelligence" that could learn many diverse Atari games on its own, and later developed a variant of the system which succeeds at sequential learning.[153][154][155] Besides transfer learning,[156] hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to "slurp up" a comprehensive knowledge base from the entire unstructured Web.[9] Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, "Master Algorithm" could lead to AGI.[157] Finally, a few "emergent" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.[158][159]

Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence). A problem like machine translation is considered "AI-complete", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.

Approaches
No established unifying theory or paradigm guides AI research. Researchers disagree about many issues.[f] A few of the most long-standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering?[22] Can intelligent behavior be described using simple, elegant principles (such as logic or optimization)? Or does it necessarily require solving a large number of unrelated problems?[23]

Cybernetics and brain simulation
Main articles: Cybernetics and Computational neuroscience
In the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as W. Grey Walter's turtles and the Johns Hopkins Beast. Many of these researchers gathered for meetings of the Teleological Society at Princeton University and the Ratio Club in England.[161] By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.

Symbolic
Main article: Symbolic AI
When access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: Carnegie Mellon University, Stanford, and MIT, and as described below, each one developed its own style of research. John Haugeland named these symbolic approaches to AI "good old fashioned AI" or "GOFAI".[162] During the 1960s, symbolic approaches had achieved great success at simulating high-level "thinking" in small demonstration programs. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.[g] Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.

Cognitive simulation
Economist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science. Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s.[163][164]

Logic-based
Unlike Simon and Newell, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless of whether people used the same algorithms.[22] His laboratory at Stanford (SAIL) focused on using formal logic to solve a wide variety of problems, including knowledge representation, planning and learning.[165] Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming.[166]

Anti-logic or scruffy
Researchers at MIT (such as Marvin Minsky and Seymour Papert)[167] found that solving difficult problems in vision and natural language processing required ad hoc solutions—they argued that no simple and general principle (like logic) would capture all the aspects of intelligent behavior. Roger Schank described their "anti-logic" approaches as "scruffy" (as opposed to the "neat" paradigms at CMU and Stanford).[23] Commonsense knowledge bases (such as Doug Lenat's Cyc) are an example of "scruffy" AI, since they must be built by hand, one complicated concept at a time.[168]

Knowledge-based
When computers with large memories became available around 1970, researchers from all three traditions began to build knowledge into AI applications.[169] This "knowledge revolution" led to the development and deployment of expert systems (introduced by Edward Feigenbaum), the first truly successful form of AI software.[51] A key component of the system architecture for all expert systems is the knowledge base, which stores facts and rules that illustrate AI.[170] The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.

Sub-symbolic
By the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems.[24] Sub-symbolic methods manage to approach intelligence without specific representations of knowledge.

Embodied intelligence
This includes embodied, situated, behavior-based, and nouvelle AI. Researchers from the related field of robotics, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive.[171] Their work revived the non-symbolic point of view of the early cybernetics researchers of the 1950s and reintroduced the use of control theory in AI. This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.

Within developmental robotics, developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.).[172][173][174][175]

Computational intelligence and soft computing
Interest in neural networks and "connectionism" was revived by David Rumelhart and others in the middle of the 1980s.[176] Artificial neural networks are an example of soft computing—they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other soft computing approaches to AI include fuzzy systems, Grey system theory, evolutionary computation and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of computational intelligence.[177]

Statistical
Much of traditional GOFAI got bogged down on ad hoc patches to symbolic computation that worked on their own toy models but failed to generalize to real-world results. However, around the 1990s, AI researchers adopted sophisticated mathematical tools, such as hidden Markov models (HMM), information theory, and normative Bayesian decision theory to compare or to unify competing architectures. The shared mathematical language permitted a high level of collaboration with more established fields (like mathematics, economics or operations research).[h] Compared with GOFAI, new "statistical learning" techniques such as HMM and neural networks were gaining higher levels of accuracy in many practical domains such as data mining, without necessarily acquiring a semantic understanding of the datasets. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible.[53][178] Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language.[179] Critics note that the shift from GOFAI to statistical learning is often also a shift away from explainable AI. In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general intelligence.[180][181]

Integrating the approaches
Intelligent agent paradigm
An intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success. The simplest intelligent agents are programs that solve specific problems. More complicated agents include human beings and organizations of human beings (such as firms). The paradigm allows researchers to directly compare or even combine different approaches to isolated problems, by asking which agent is best at maximizing a given "goal function". An agent that solves a specific problem can use any approach that works—some agents are symbolic and logical, some are sub-symbolic artificial neural networks and others may use new approaches. The paradigm also gives researchers a common language to communicate with other fields—such as decision theory and economics—that also use concepts of abstract agents. Building a complete agent requires researchers to address realistic problems of integration; for example, because sensory systems give uncertain information about the environment, planning systems must be able to function in the presence of uncertainty. The intelligent agent paradigm became widely accepted during the 1990s.[182]
Agent architectures and cognitive architectures
Researchers have designed systems to build intelligent systems out of interacting intelligent agents in a multi-agent system.[183] A hierarchical control system provides a bridge between sub-symbolic AI at its lowest, reactive levels and traditional symbolic AI at its highest levels, where relaxed time constraints permit planning and world modeling.[184] Some cognitive architectures are custom-built to solve a narrow problem; others, such as Soar, are designed to mimic human cognition and to provide insight into general intelligence. Modern extensions of Soar are hybrid intelligent systems that include both symbolic and sub-symbolic components.[91][185]
Tools
Main article: Computational tools for artificial intelligence
Applications
Main article: Applications of artificial intelligence
AI is relevant to any intellectual task.[186] Modern artificial intelligence techniques are pervasive[187] and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.[188]

High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google Search), online assistants (such as Siri), image recognition in photographs, spam filtering, predicting flight delays,[189] prediction of judicial decisions,[190] targeting online advertisements, [186][191][192] and energy storage[193]

With social media sites overtaking TV as a source for news for young people and news organizations increasingly reliant on social media platforms for generating distribution,[194] major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.[195]

AI can also produce Deepfakes, a content-altering technology. ZDNet reports, "It presents something that did not actually occur," Though 88% of Americans believe Deepfakes can cause more harm than good, only 47% of them believe they can be targeted. The boom of election year also opens public discourse to threats of videos of falsified politician media.[196]

Philosophy and ethics

This section should include only a brief summary of another article. See Wikipedia:Summary style for information on how to properly incorporate it into this article's main text. (August 2020)
Main articles: Philosophy of artificial intelligence and Ethics of artificial intelligence
There are three philosophical questions related to AI [197]

Whether artificial general intelligence is possible; whether a machine can solve any problem that a human being can solve using intelligence, or if there are hard limits to what a machine can accomplish.
Whether intelligent machines are dangerous; how humans can ensure that machines behave ethically and that they are used ethically.
Whether a machine can have a mind, consciousness and mental states in the same sense that human beings do; if a machine can be sentient, and thus deserve certain rights − and if a machine can intentionally cause harm.
The limits of artificial general intelligence
Main articles: Philosophy of artificial intelligence, Turing test, Physical symbol systems hypothesis, Dreyfus' critique of artificial intelligence, The Emperor's New Mind, and AI effect
Alan Turing's "polite convention"
One need not decide if a machine can "think"; one need only decide if a machine can act as intelligently as a human being. This approach to the philosophical problems associated with artificial intelligence forms the basis of the Turing test.[198]
The Dartmouth proposal
"Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it." This conjecture was printed in the proposal for the Dartmouth Conference of 1956.[199]
Newell and Simon's physical symbol system hypothesis
"A physical symbol system has the necessary and sufficient means of general intelligent action." Newell and Simon argue that intelligence consists of formal operations on symbols.[200] Hubert Dreyfus argues that, on the contrary, human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the situation, rather than explicit symbolic knowledge. (See Dreyfus' critique of AI.)[i][202]
Gödelian arguments
Gödel himself,[203] John Lucas (in 1961) and Roger Penrose (in a more detailed argument from 1989 onwards) made highly technical arguments that human mathematicians can consistently see the truth of their own "Gödel statements" and therefore have computational abilities beyond that of mechanical Turing machines.[204] However, some people do not agree with the "Gödelian arguments".[205][206][207]
The artificial brain argument
An argument asserting that the brain can be simulated by machines and, because brains exhibit intelligence, these simulated brains must also exhibit intelligence − ergo, machines can be intelligent. Hans Moravec, Ray Kurzweil and others have argued that it is technologically feasible to copy the brain directly into hardware and software, and that such a simulation will be essentially identical to the original.[158]
The AI effect
A hypothesis claiming that machines are already intelligent, but observers have failed to recognize it. For example, when Deep Blue beat Garry Kasparov in chess, the machine could be described as exhibiting intelligence. However, onlookers commonly discount the behavior of an artificial intelligence program by arguing that it is not "real" intelligence, with "real" intelligence being in effect defined as whatever behavior machines cannot do.
Ethical machines
Machines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; they may have the ability to use ethical reasoning to better choose their actions in the world. As such, there is a need for policy making to devise policies for and regulate artificial intelligence and robotics.[208] Research in this area includes machine ethics, artificial moral agents, friendly AI and discussion towards building a human rights framework is also in talks.[209]

Joseph Weizenbaum in Computer Power and Human Reason wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as customer service or psychotherapy[j] was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as computationalism). To Weizenbaum these points suggest that AI research devalues human life.[211]

Artificial moral agents
Wendell Wallach introduced the concept of artificial moral agents (AMA) in his book Moral Machines[212] For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as "Does Humanity Want Computers Making Moral Decisions"[213] and "Can (Ro)bots Really Be Moral".[214] For Wallach, the question is not centered on the issue of whether machines can demonstrate the equivalent of moral behavior, unlike the constraints which society may place on the development of AMAs.[215]

Machine ethics
Main article: Machine ethics
The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making.[216] The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: "Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics."[217] Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition "Machine Ethics"[216] that stems from the AAAI Fall 2005 Symposium on Machine Ethics.[217]

Malevolent and friendly AI
Main article: Friendly AI
Political scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent.[218] He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.

One proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI' and will be able to control subsequently developed AIs. Some question whether this kind of check could actually remain in place.

Leading AI researcher Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence."[219]

Lethal autonomous weapons are of concern. Currently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers and drones.[220]

Machine consciousness, sentience and mind
Main article: Artificial consciousness
If an AI system replicates all key aspects of human intelligence, will that system also be sentient—will it have a mind which has conscious experiences? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness.

Consciousness
Main articles: Hard problem of consciousness and Theory of mind
David Chalmers identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness.[221] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all. Human information processing is easy to explain, however human subjective experience is difficult to explain.

For example, consider what happens when a person is shown a color swatch and identifies it, saying "it's red". The easy problem only requires understanding the machinery in the brain that makes it possible for a person to know that the color swatch is red. The hard problem is that people also know something else—they also know what red looks like. (Consider that a person born blind can know that something is red without knowing what red looks like.)[k] Everyone knows subjective experience exists, because they do it every day (e.g., all sighted people know what red looks like). The hard problem is explaining how the brain creates it, why it exists, and how it is different from knowledge and other aspects of the brain.

Computationalism and functionalism
Main articles: Computationalism and Functionalism (philosophy of mind)
Computationalism is the position in the philosophy of mind that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing.[222] Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.

Strong AI hypothesis
Main article: Chinese room
The philosophical position that John Searle has named "strong AI" states: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."[l] Searle counters this assertion with his Chinese room argument, which asks us to look inside the computer and try to find where the "mind" might be.[224]

Robot rights
Main article: Robot rights
If a machine can be created that has intelligence, could it also feel? If it can feel, does it have the same rights as a human? This issue, now known as "robot rights", is currently being considered by, for example, California's Institute for the Future, although many critics believe that the discussion is premature.[225][226] Some critics of transhumanism argue that any hypothetical robot rights would lie on a spectrum with animal rights and human rights.[227] The subject is profoundly discussed in the 2010 documentary film Plug & Pray,[228] and many sci fi media such as Star Trek Next Generation, with the character of Commander Data, who fought being disassembled for research, and wanted to "become human", and the robotic holograms in Voyager.

Superintelligence
Main article: Superintelligence
Are there limits to how intelligent machines—or human-machine hybrids—can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. Superintelligence may also refer to the form or degree of intelligence possessed by such an agent.[152]

Technological singularity
Main articles: Technological singularity and Moore's law
If research into Strong AI produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement.[229] The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario "singularity".[230] Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.[230][152]

Ray Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029 and predicts that the singularity will occur in 2045.[230]

Transhumanism
Main article: Transhumanism
Robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either.[231] This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.

Edward Fredkin argues that "artificial intelligence is the next stage in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[232]

Impact
The long-term economic effects of AI are uncertain. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit, if productivity gains are redistributed.[233] A 2017 study by PricewaterhouseCoopers sees the People’s Republic of China gaining economically the most out of AI with 26,1% of GDP until 2030.[234] A February 2020 European Union white paper on artificial intelligence advocated for artificial intelligence for economic benefits, including "improving healthcare (e.g. making diagnosis more precise, enabling better prevention of diseases), increasing the efficiency of farming, contributing to climate change mitigation and adaptation, [and] improving the efficiency of production systems through predictive maintenance", while acknowledging potential risks.[187]

The relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects.[235] Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously".[236] Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk".[237][238][239] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[240] Author Martin Ford and others go further and argue that many jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be "accessible to people with average capability", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that "we're in uncharted territory" with AI.[34]

The potential negative effects of AI and automation were a major issue for Andrew Yang's 2020 presidential campaign in the United States.[241] Irakli Beridze, Head of the Centre for Artificial Intelligence and Robotics at UNICRI, United Nations, has expressed that "I think the dangerous applications for AI, from my point of view, would be criminals or large terrorist organizations using it to disrupt large processes or simply do pure harm. [Terrorists could cause harm] via digital warfare, or it could be a combination of robotics, drones, with AI and other things as well that could be really dangerous. And, of course, other risks come from things like job losses. If we have massive numbers of people losing jobs and don't find a solution, it will be extremely dangerous. Things like lethal autonomous weapons systems should be properly governed — otherwise there's massive potential of misuse."[242]

Risks of narrow AI
Main article: Workplace impact of artificial intelligence
Widespread use of artificial intelligence could have unintended consequences that are dangerous or undesirable. Scientists from the Future of Life Institute, among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.[243]

Some are concerned about algorithmic bias, that AI programs may unintentionally become biased after processing data that exhibits bias.[244] Algorithms already have numerous applications in legal systems. An example of this is COMPAS, a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than the average COMPAS-assigned risk level of white defendants.[245]

Risks of general AI
Main article: Existential risk from artificial general intelligence
Physicist Stephen Hawking, Microsoft founder Bill Gates, history professor Yuval Noah Harari, and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could "spell the end of the human race".[246][247][248][249]

The development of full artificial intelligence could spell the end of the human race. Once humans develop artificial intelligence, it will take off on its own and redesign itself at an ever-increasing rate. Humans, who are limited by slow biological evolution, couldn't compete and would be superseded.

— Stephen Hawking[250]
In his book Superintelligence, philosopher Nick Bostrom provides an argument that artificial intelligence will pose a threat to humankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not fully reflect humanity's—one example is an AI told to compute as many digits of pi as possible—it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal. Bostrom also emphasizes the difficulty of fully conveying humanity's values to an advanced AI. He uses the hypothetical example of giving an AI the goal to make humans smile to illustrate a misguided attempt. If the AI in that scenario were to become superintelligent, Bostrom argues, it may resort to methods that most humans would find horrifying, such as inserting "electrodes into the facial muscles of humans to cause constant, beaming grins" because that would be an efficient way to achieve its goal of making humans smile.[251] In his book Human Compatible, AI researcher Stuart J. Russell echoes some of Bostrom's concerns while also proposing an approach to developing provably beneficial machines focused on uncertainty and deference to humans,[252]:173 possibly involving inverse reinforcement learning.[252]:191–193

Concern over risk from artificial intelligence has led to some high-profile donations and investments. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1 billion to OpenAI, a nonprofit company aimed at championing responsible AI development.[253] The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.[254] Other technology industry leaders believe that artificial intelligence is helpful in its current form and will continue to assist humans. Oracle CEO Mark Hurd has stated that AI "will actually create more jobs, not less jobs" as humans will be needed to manage AI systems.[255] Facebook CEO Mark Zuckerberg believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars.[256] In January 2015, Musk donated $10 million to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing artificial intelligence such as DeepMind and Vicarious to "just keep an eye on what's going on with artificial intelligence.[257] I think there is potentially a dangerous outcome there."[258][259]

For the danger of uncontrolled advanced AI to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching.[260][261] Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.[262]

Regulation
Main articles: Regulation of artificial intelligence and Regulation of algorithms
The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI);[263][264] it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally, including in the European Union.[265] Regulation is considered necessary to both encourage AI and manage associated risks.[266][267] Regulation of AI through mechanisms such as review boards can also be seen as social means to approach the AI control problem.[268]

In fiction
Main article: Artificial intelligence in fiction

The word "robot" itself was coined by Karel Čapek in his 1921 play R.U.R., the title standing for "Rossum's Universal Robots"
Thought-capable artificial beings appeared as storytelling devices since antiquity,[36] and have been a persistent theme in science fiction.

A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[269]

Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;[270] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[271]

Transhumanism (the merging of humans and machines) is explored in the manga Ghost in the Shell and the science-fiction series Dune. In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but always an unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.

Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[272]
Consciousness, at its simplest, is "sentience or awareness of internal or external existence."[1] Despite millennia of analyses, definitions, explanations and debates by philosophers and scientists, consciousness remains puzzling and controversial,[2] being "at once the most familiar and most mysterious aspect of our lives."[3] Perhaps the only widely agreed notion about the topic is the intuition that it exists.[4] Opinions differ about what exactly needs to be studied and explained as consciousness. Sometimes, it is synonymous with the mind, and at other times, an aspect of it. In the past, it was one's "inner life," the world of introspection, of private thought, imagination and volition.[5] Today, it often includes some kind of experience, cognition, feeling or perception. It may be awareness, awareness of awareness, or self-awareness.[6] There might be different levels or orders of consciousness,[7] or different kinds of consciousness, or just one kind with different features.[8] Other questions include whether only humans are conscious, all animals, or even the whole universe. The disparate range of research, notions and speculations raises doubts about whether the right questions are being asked.[9]

Examples of the range of descriptions, definitions or explanations are: simple wakefulness, one's sense of selfhood or soul explored by "looking within"; being a metaphorical "stream" of contents, or being a mental state, mental event or mental process of the brain; having phanera or qualia and subjectivity; being the 'something that it is like' to 'have' or 'be' it; being the "inner theatre" or the executive control system of the mind.[10]

Inter-disciplinary perspectives
Western philosophers since the time of Descartes and Locke have struggled to comprehend the nature of consciousness and how it fits into a larger picture of the world. These issues remain central to both continental and analytic philosophy, in phenomenology and the philosophy of mind, respectively. Some basic questions include: whether consciousness is the same kind of thing as matter; whether it may ever be possible for computing machines like computers or robots to be conscious; how consciousness relates to language; how consciousness as Being relates to the world of experience; the role of the self in experience; whether individual thought is possible at all; and whether the concept is fundamentally coherent.

Recently, consciousness has also become a significant topic of interdisciplinary research in cognitive science, involving fields such as psychology, linguistics, anthropology,[11] neuropsychology and neuroscience. The primary focus is on understanding what it means biologically and psychologically for information to be present in consciousness—that is, on determining the neural and psychological correlates of consciousness. The majority of experimental studies assess consciousness in humans by asking subjects for a verbal report of their experiences (e.g., "tell me if you notice anything when I do this"). Issues of interest include phenomena such as subliminal perception, blindsight, denial of impairment, and altered states of consciousness produced by alcohol and other drugs, or spiritual or meditative techniques.

In medicine, consciousness is assessed by observing a patient's arousal and responsiveness, and can be seen as a continuum of states ranging from full alertness and comprehension, through disorientation, delirium, loss of meaningful communication, and finally loss of movement in response to painful stimuli.[12] Issues of practical concern include how the presence of consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat conditions in which consciousness is impaired or disrupted.[13] The degree of consciousness is measured by standardized behavior observation scales such as the Glasgow Coma Scale.

Etymology

John Locke, British Enlightenment philosopher from the 17th century
In the late 20th century, philosophers like Hamlyn, Rorty, and Wilkes have disagreed with Kahn, Hardie and Modrak as to whether Aristotle even had a concept of consciousness. Aristotle does not use any single word or terminology to name the phenomena; it is used only much later, especially by John Locke. Caston contends that for Aristotle, perceptual awareness was somewhat the same as what modern philosophers call consciousness.[14]

The origin of the modern concept of consciousness is often attributed to Locke's Essay Concerning Human Understanding, published in 1690.[15] Locke defined consciousness as "the perception of what passes in a man's own mind".[16] His essay influenced the 18th-century view of consciousness, and his definition appeared in Samuel Johnson's celebrated Dictionary (1755).[17] "Consciousness" (French: conscience) is also defined in the 1753 volume of Diderot and d'Alembert's Encyclopédie, as "the opinion or internal feeling that we ourselves have from what we do".[18]

The earliest English language uses of "conscious" and "consciousness" date back, however, to the 1500s. The English word "conscious" originally derived from the Latin conscius (con- "together" and scio "to know"), but the Latin word did not have the same meaning as the English word—it meant "knowing with", in other words, "having joint or common knowledge with another".[19] There were, however, many occurrences in Latin writings of the phrase conscius sibi, which translates literally as "knowing with oneself", or in other words "sharing knowledge with oneself about something". This phrase had the figurative meaning of "knowing that one knows", as the modern English word "conscious" does. In its earliest uses in the 1500s, the English word "conscious" retained the meaning of the Latin conscius. For example, Thomas Hobbes in Leviathan wrote: "Where two, or more men, know of one and the same fact, they are said to be Conscious of it one to another."[20] The Latin phrase conscius sibi, whose meaning was more closely related to the current concept of consciousness, was rendered in English as "conscious to oneself" or "conscious unto oneself". For example, Archbishop Ussher wrote in 1613 of "being so conscious unto myself of my great weakness".[21] Locke's definition from 1690 illustrates that a gradual shift in meaning had taken place.

A related word was conscientia, which primarily means moral conscience. In the literal sense, "conscientia" means knowledge-with, that is, shared knowledge. The word first appears in Latin juridical texts by writers such as Cicero.[22] Here, conscientia is the knowledge that a witness has of the deed of someone else.[23] René Descartes (1596–1650) is generally taken to be the first philosopher to use conscientia in a way that does not fit this traditional meaning.[24] Descartes used conscientia the way modern speakers would use "conscience". In Search after Truth (Regulæ ad directionem ingenii ut et inquisitio veritatis per lumen naturale, Amsterdam 1701) he says "conscience or internal testimony" (conscientiâ, vel interno testimonio).[25][26]

Definitions
The dictionary definitions of the word consciousness extend through several centuries and reflect a range of seemingly related meanings, with some differences that have been controversial, such as the distinction between 'inward awareness' and 'perception' of the physical world, or the distinction between 'conscious' and 'unconscious', or the notion of a "mental entity" or "mental activity" that is not physical.

The common usage definitions of consciousness in Webster's Third New International Dictionary (1966 edition, Volume 1, page 482) are as follows:

awareness or perception of an inward psychological or spiritual fact; intuitively perceived knowledge of something in one's inner self
inward awareness of an external object, state, or fact
concerned awareness; INTEREST, CONCERN—often used with an attributive noun [e.g. class consciousness]
the state or activity that is characterized by sensation, emotion, volition, or thought; mind in the broadest possible sense; something in nature that is distinguished from the physical
the totality in psychology of sensations, perceptions, ideas, attitudes, and feelings of which an individual or a group is aware at any given time or within a particular time span—compare STREAM OF CONSCIOUSNESS
waking life (as that to which one returns after sleep, trance, fever) wherein all one’s mental powers have returned . . .
the part of mental life or psychic content in psychoanalysis that is immediately available to the ego—compare PRECONSCIOUS, UNCONSCIOUS

The Cambridge Dictionary defines consciousness as "the state of understanding and realizing something."[27] The Oxford Living Dictionary defines consciousness as "The state of being aware of and responsive to one's surroundings.", "A person's awareness or perception of something." and "The fact of awareness by the mind of itself and the world."[28]

Philosophers have attempted to clarify technical distinctions by using a jargon of their own. The Routledge Encyclopedia of Philosophy in 1998 defines consciousness as follows:

Consciousness—Philosophers have used the term 'consciousness' for four main topics: knowledge in general, intentionality, introspection (and the knowledge it specifically generates) and phenomenal experience... Something within one's mind is 'introspectively conscious' just in case one introspects it (or is poised to do so). Introspection is often thought to deliver one's primary knowledge of one's mental life. An experience or other mental entity is 'phenomenally conscious' just in case there is 'something it is like' for one to have it. The clearest examples are: perceptual experience, such as tastings and seeings; bodily-sensational experiences, such as those of pains, tickles and itches; imaginative experiences, such as those of one's own actions or perceptions; and streams of thought, as in the experience of thinking 'in words' or 'in images'. Introspection and phenomenality seem independent, or dissociable, although this is controversial.[29]

Many philosophers and scientists have been unhappy about the difficulty of producing a definition that does not involve circularity or fuzziness.[30] In The Macmillan Dictionary of Psychology (1989 edition), Stuart Sutherland expressed a skeptical attitude more than a definition:

Consciousness—The having of perceptions, thoughts, and feelings; awareness. The term is impossible to define except in terms that are unintelligible without a grasp of what consciousness means. Many fall into the trap of equating consciousness with self-consciousness—to be conscious it is only necessary to be aware of the external world. Consciousness is a fascinating but elusive phenomenon: it is impossible to specify what it is, what it does, or why it has evolved. Nothing worth reading has been written on it.[30]

A partisan definition such as Sutherland's can hugely affect researchers' assumptions and the direction of their work:

If awareness of the environment . . . is the criterion of consciousness, then even the protozoans are conscious. If awareness of awareness is required, then it is doubtful whether the great apes and human infants are conscious.[31]

Philosophy of mind
Most writers on the philosophy of consciousness have been concerned with defending a particular point of view, and have organized their material accordingly. For surveys, the most common approach is to follow a historical path by associating stances with the philosophers who are most strongly associated with them, for example, Descartes, Locke, Kant, etc. An alternative is to organize philosophical stances according to basic issues.

The coherence of the concept
Many philosophers have argued that consciousness is a unitary concept that is understood intuitively by the majority of people in spite of the difficulty in defining it.[8] Others, though, have argued that the level of disagreement about the meaning of the word indicates that it either means different things to different people (for instance, the objective versus subjective aspects of consciousness), or else it encompasses a variety of distinct meanings with no simple element in common.[32]

Philosophers differ from non-philosophers in their intuitions about what consciousness is.[33] While most people have a strong intuition for the existence of what they refer to as consciousness,[8] skeptics argue that this intuition is false, either because the concept of consciousness is intrinsically incoherent, or because our intuitions about it are based in illusions. Gilbert Ryle, for example, argued that traditional understanding of consciousness depends on a Cartesian dualist outlook that improperly distinguishes between mind and body, or between mind and world. He proposed that we speak not of minds, bodies, and the world, but of individuals, or persons, acting in the world. Thus, by speaking of "consciousness" we end up misleading ourselves by thinking that there is any sort of thing as consciousness separated from behavioral and linguistic understandings.[34]

Types of consciousness
Ned Block argued that discussions on consciousness often failed to properly distinguish phenomenal (P-consciousness) from access (A-consciousness), though these terms had been used before Block.[35] P-consciousness, according to Block, is simply raw experience: it is moving, colored forms, sounds, sensations, emotions and feelings with our bodies and responses at the center. These experiences, considered independently of any impact on behavior, are called qualia. A-consciousness, on the other hand, is the phenomenon whereby information in our minds is accessible for verbal report, reasoning, and the control of behavior. So, when we perceive, information about what we perceive is access conscious; when we introspect, information about our thoughts is access conscious; when we remember, information about the past is access conscious, and so on. Although some philosophers, such as Daniel Dennett, have disputed the validity of this distinction,[36] others have broadly accepted it. David Chalmers has argued that A-consciousness can in principle be understood in mechanistic terms, but that understanding P-consciousness is much more challenging: he calls this the hard problem of consciousness.[37] Kong Derick has also stated that there are two types of consciousness: high level consciousness, which he attributes to the mind, and low level consciousness, which he attributes to the submind.[38]

Some philosophers believe that Block's two types of consciousness are not the end of the story. William Lycan, for example, argued in his book Consciousness and Experience that at least eight clearly distinct types of consciousness can be identified (organism consciousness; control consciousness; consciousness of; state/event consciousness; reportability; introspective consciousness; subjective consciousness; self-consciousness)—and that even this list omits several more obscure forms.[39]

There is also debate over whether or not A-consciousness and P-consciousness always coexist or if they can exist separately. Although P-consciousness without A-consciousness is more widely accepted, there have been some hypothetical examples of A without P. Block, for instance, suggests the case of a "zombie" that is computationally identical to a person but without any subjectivity. However, he remains somewhat skeptical concluding "I don't know whether there are any actual cases of A-consciousness without P-consciousness, but I hope I have illustrated their conceptual possibility." [40]

Mind–body problem
Main article: Mind–body problem

Illustration of dualism by René Descartes. Inputs are passed by the sensory organs to the pineal gland and from there to the immaterial spirit.
Mental processes (such as consciousness) and physical processes (such as brain events) seem to be correlated, however the specific nature of the connection is unknown.

The first influential philosopher to discuss this question specifically was Descartes, and the answer he gave is known as Cartesian dualism. Descartes proposed that consciousness resides within an immaterial domain he called res cogitans (the realm of thought), in contrast to the domain of material things, which he called res extensa (the realm of extension).[41] He suggested that the interaction between these two domains occurs inside the brain, perhaps in a small midline structure called the pineal gland.[42]

Although it is widely accepted that Descartes explained the problem cogently, few later philosophers have been happy with his solution, and his ideas about the pineal gland have especially been ridiculed.[43] However, no alternative solution has gained general acceptance. Proposed solutions can be divided broadly into two categories: dualist solutions that maintain Descartes' rigid distinction between the realm of consciousness and the realm of matter but give different answers for how the two realms relate to each other; and monist solutions that maintain that there is really only one realm of being, of which consciousness and matter are both aspects. Each of these categories itself contains numerous variants. The two main types of dualism are substance dualism (which holds that the mind is formed of a distinct type of substance not governed by the laws of physics) and property dualism (which holds that the laws of physics are universally valid but cannot be used to explain the mind). The three main types of monism are physicalism (which holds that the mind consists of matter organized in a particular way), idealism (which holds that only thought or experience truly exists, and matter is merely an illusion), and neutral monism (which holds that both mind and matter are aspects of a distinct essence that is itself identical to neither of them). There are also, however, a large number of idiosyncratic theories that cannot cleanly be assigned to any of these schools of thought.[44]

Since the dawn of Newtonian science with its vision of simple mechanical principles governing the entire universe, some philosophers have been tempted by the idea that consciousness could be explained in purely physical terms. The first influential writer to propose such an idea explicitly was Julien Offray de La Mettrie, in his book Man a Machine (L'homme machine). His arguments, however, were very abstract.[45] The most influential modern physical theories of consciousness are based on psychology and neuroscience. Theories proposed by neuroscientists such as Gerald Edelman[46] and Antonio Damasio,[47] and by philosophers such as Daniel Dennett,[48] seek to explain consciousness in terms of neural events occurring within the brain. Many other neuroscientists, such as Christof Koch,[49] have explored the neural basis of consciousness without attempting to frame all-encompassing global theories. At the same time, computer scientists working in the field of artificial intelligence have pursued the goal of creating digital computer programs that can simulate or embody consciousness.[50]

A few theoretical physicists have argued that classical physics is intrinsically incapable of explaining the holistic aspects of consciousness, but that quantum theory may provide the missing ingredients. Several theorists have therefore proposed quantum mind (QM) theories of consciousness.[51] Notable theories falling into this category include the holonomic brain theory of Karl Pribram and David Bohm, and the Orch-OR theory formulated by Stuart Hameroff and Roger Penrose. Some of these QM theories offer descriptions of phenomenal consciousness, as well as QM interpretations of access consciousness. None of the quantum mechanical theories have been confirmed by experiment. Recent publications by G. Guerreshi, J. Cia, S. Popescu, and H. Briegel[52] could falsify proposals such as those of Hameroff, which rely on quantum entanglement in protein. At the present time many scientists and philosophers consider the arguments for an important role of quantum phenomena to be unconvincing.[53]

Apart from the general question of the "hard problem" of consciousness, roughly speaking, the question of how mental experience arises from a physical basis.[54] a more specialized question is how to square the subjective notion that we are in control of our decisions (at least in some small measure) with the customary view of causality that subsequent events are caused by prior events. The topic of free will is the philosophical and scientific examination of this conundrum.

Problem of other minds
Main article: Problem of other minds
Many philosophers consider experience to be the essence of consciousness, and believe that experience can only fully be known from the inside, subjectively. But if consciousness is subjective and not visible from the outside, why do the vast majority of people believe that other people are conscious, but rocks and trees are not?[55] This is called the problem of other minds.[56] It is particularly acute for people who believe in the possibility of philosophical zombies, that is, people who think it is possible in principle to have an entity that is physically indistinguishable from a human being and behaves like a human being in every way but nevertheless lacks consciousness.[57] Related issues have also been studied extensively by Greg Littmann of the University of Illinois,[58] and Colin Allen a professor at Indiana University regarding the literature and research studying artificial intelligence in androids.[59]

The most commonly given answer is that we attribute consciousness to other people because we see that they resemble us in appearance and behavior; we reason that if they look like us and act like us, they must be like us in other ways, including having experiences of the sort that we do.[60] There are, however, a variety of problems with that explanation. For one thing, it seems to violate the principle of parsimony, by postulating an invisible entity that is not necessary to explain what we observe.[60] Some philosophers, such as Daniel Dennett in an essay titled The Unimagined Preposterousness of Zombies, argue that people who give this explanation do not really understand what they are saying.[61] More broadly, philosophers who do not accept the possibility of zombies generally believe that consciousness is reflected in behavior (including verbal behavior), and that we attribute consciousness on the basis of behavior. A more straightforward way of saying this is that we attribute experiences to people because of what they can do, including the fact that they can tell us about their experiences.[62]

Animal consciousness
See also: Animal consciousness
The topic of animal consciousness is beset by a number of difficulties. It poses the problem of other minds in an especially severe form, because non-human animals, lacking the ability to express human language, cannot tell humans about their experiences.[63] Also, it is difficult to reason objectively about the question, because a denial that an animal is conscious is often taken to imply that it does not feel, its life has no value, and that harming it is not morally wrong. Descartes, for example, has sometimes been blamed for mistreatment of animals due to the fact that he believed only humans have a non-physical mind.[64] Most people have a strong intuition that some animals, such as cats and dogs, are conscious, while others, such as insects, are not; but the sources of this intuition are not obvious, and are often based on personal interactions with pets and other animals they have observed.[63]

Philosophers who consider subjective experience the essence of consciousness also generally believe, as a correlate, that the existence and nature of animal consciousness can never rigorously be known. Thomas Nagel spelled out this point of view in an influential essay titled What Is it Like to Be a Bat?. He said that an organism is conscious "if and only if there is something that it is like to be that organism—something it is like for the organism"; and he argued that no matter how much we know about an animal's brain and behavior, we can never really put ourselves into the mind of the animal and experience its world in the way it does itself.[65] Other thinkers, such as Douglas Hofstadter, dismiss this argument as incoherent.[66] Several psychologists and ethologists have argued for the existence of animal consciousness by describing a range of behaviors that appear to show animals holding beliefs about things they cannot directly perceive—Donald Griffin's 2001 book Animal Minds reviews a substantial portion of the evidence.[67]

On July 7, 2012, eminent scientists from different branches of neuroscience gathered at the University of Cambridge to celebrate the Francis Crick Memorial Conference, which deals with consciousness in humans and pre-linguistic consciousness in nonhuman animals. After the conference, they signed in the presence of Stephen Hawking, the 'Cambridge Declaration on Consciousness', which summarizes the most important findings of the survey:

"We decided to reach a consensus and make a statement directed to the public that is not scientific. It's obvious to everyone in this room that animals have consciousness, but it is not obvious to the rest of the world. It is not obvious to the rest of the Western world or the Far East. It is not obvious to the society."[68]

"Convergent evidence indicates that non-human animals [...], including all mammals and birds, and other creatures, [...] have the necessary neural substrates of consciousness and the capacity to exhibit intentional behaviors."[69]

Artifact consciousness
See also: Artificial consciousness
The idea of an artifact made conscious is an ancient theme of mythology, appearing for example in the Greek myth of Pygmalion, who carved a statue that was magically brought to life, and in medieval Jewish stories of the Golem, a magically animated homunculus built of clay.[70] However, the possibility of actually constructing a conscious machine was probably first discussed by Ada Lovelace, in a set of notes written in 1842 about the Analytical Engine invented by Charles Babbage, a precursor (never built) to modern electronic computers. Lovelace was essentially dismissive of the idea that a machine such as the Analytical Engine could think in a humanlike way. She wrote:

It is desirable to guard against the possibility of exaggerated ideas that might arise as to the powers of the Analytical Engine. ... The Analytical Engine has no pretensions whatever to originate anything. It can do whatever we know how to order it to perform. It can follow analysis; but it has no power of anticipating any analytical relations or truths. Its province is to assist us in making available what we are already acquainted with.[71]

One of the most influential contributions to this question was an essay written in 1950 by pioneering computer scientist Alan Turing, titled Computing Machinery and Intelligence. Turing disavowed any interest in terminology, saying that even "Can machines think?" is too loaded with spurious connotations to be meaningful; but he proposed to replace all such questions with a specific operational test, which has become known as the Turing test.[72] To pass the test, a computer must be able to imitate a human well enough to fool interrogators. In his essay Turing discussed a variety of possible objections, and presented a counterargument to each of them. The Turing test is commonly cited in discussions of artificial intelligence as a proposed criterion for machine consciousness; it has provoked a great deal of philosophical debate. For example, Daniel Dennett and Douglas Hofstadter argue that anything capable of passing the Turing test is necessarily conscious,[73] while David Chalmers argues that a philosophical zombie could pass the test, yet fail to be conscious.[74] A third group of scholars have argued that with technological growth once machines begin to display any substantial signs of human-like behavior then the dichotomy (of human consciousness compared to human-like consciousness) becomes passé and issues of machine autonomy begin to prevail even as observed in its nascent form within contemporary industry and technology.[58][59] Jürgen Schmidhuber argues that consciousness is simply the result of compression.[75] As an agent sees representation of itself recurring in the environment, the compression of this representation can be called consciousness.


John Searle in December 2005
In a lively exchange over what has come to be referred to as "the Chinese room argument", John Searle sought to refute the claim of proponents of what he calls "strong artificial intelligence (AI)" that a computer program can be conscious, though he does agree with advocates of "weak AI" that computer programs can be formatted to "simulate" conscious states. His own view is that consciousness has subjective, first-person causal powers by being essentially intentional due simply to the way human brains function biologically; conscious persons can perform computations, but consciousness is not inherently computational the way computer programs are. To make a Turing machine that speaks Chinese, Searle imagines a room with one monolingual English speaker (Searle himself, in fact), a book that designates a combination of Chinese symbols to be output paired with Chinese symbol input, and boxes filled with Chinese symbols. In this case, the English speaker is acting as a computer and the rulebook as a program. Searle argues that with such a machine, he would be able to process the inputs to outputs perfectly without having any understanding of Chinese, nor having any idea what the questions and answers could possibly mean. If the experiment were done in English, since Searle knows English, he would be able to take questions and give answers without any algorithms for English questions, and he would be effectively aware of what was being said and the purposes it might serve. Searle would pass the Turing test of answering the questions in both languages, but he is only conscious of what he is doing when he speaks English. Another way of putting the argument is to say that computer programs can pass the Turing test for processing the syntax of a language, but that the syntax cannot lead to semantic meaning in the way strong AI advocates hoped.[76][77]

In the literature concerning artificial intelligence, Searle's essay has been second only to Turing's in the volume of debate it has generated.[78] Searle himself was vague about what extra ingredients it would take to make a machine conscious: all he proposed was that what was needed was "causal powers" of the sort that the brain has and that computers lack. But other thinkers sympathetic to his basic argument have suggested that the necessary (though perhaps still not sufficient) extra conditions may include the ability to pass not just the verbal version of the Turing test, but the robotic version,[79] which requires grounding the robot's words in the robot's sensorimotor capacity to categorize and interact with the things in the world that its words are about, Turing-indistinguishably from a real person. Turing-scale robotics is an empirical branch of research on embodied cognition and situated cognition.[80]

In 2014, Victor Argonov has suggested a non-Turing test for machine consciousness based on machine's ability to produce philosophical judgments.[81] He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures' consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine's intellect, not by absence of consciousness.

Scientific study
For many decades, consciousness as a research topic was avoided by the majority of mainstream scientists, because of a general feeling that a phenomenon defined in subjective terms could not properly be studied using objective experimental methods.[82] In 1975 George Mandler published an influential psychological study which distinguished between slow, serial, and limited conscious processes and fast, parallel and extensive unconscious ones.[83] Starting in the 1980s, an expanding community of neuroscientists and psychologists have associated themselves with a field called Consciousness Studies, giving rise to a stream of experimental work published in books,[84] journals such as Consciousness and Cognition, Frontiers in Consciousness Research, Psyche, and the Journal of Consciousness Studies, along with regular conferences organized by groups such as the Association for the Scientific Study of Consciousness[85] and the Society for Consciousness Studies.

Modern medical and psychological investigations into consciousness are based on psychological experiments (including, for example, the investigation of priming effects using subliminal stimuli), and on case studies of alterations in consciousness produced by trauma, illness, or drugs. Broadly viewed, scientific approaches are based on two core concepts. The first identifies the content of consciousness with the experiences that are reported by human subjects; the second makes use of the concept of consciousness that has been developed by neurologists and other medical professionals who deal with patients whose behavior is impaired. In either case, the ultimate goals are to develop techniques for assessing consciousness objectively in humans as well as other animals, and to understand the neural and psychological mechanisms that underlie it.[49]

Measurement

The Necker cube, an ambiguous image
Experimental research on consciousness presents special difficulties, due to the lack of a universally accepted operational definition. In the majority of experiments that are specifically about consciousness, the subjects are human, and the criterion used is verbal report: in other words, subjects are asked to describe their experiences, and their descriptions are treated as observations of the contents of consciousness.[86] For example, subjects who stare continuously at a Necker cube usually report that they experience it "flipping" between two 3D configurations, even though the stimulus itself remains the same.[87] The objective is to understand the relationship between the conscious awareness of stimuli (as indicated by verbal report) and the effects the stimuli have on brain activity and behavior. In several paradigms, such as the technique of response priming, the behavior of subjects is clearly influenced by stimuli for which they report no awareness, and suitable experimental manipulations can lead to increasing priming effects despite decreasing prime identification (double dissociation).[88]

Verbal report is widely considered to be the most reliable indicator of consciousness, but it raises a number of issues.[89] For one thing, if verbal reports are treated as observations, akin to observations in other branches of science, then the possibility arises that they may contain errors—but it is difficult to make sense of the idea that subjects could be wrong about their own experiences, and even more difficult to see how such an error could be detected.[90] Daniel Dennett has argued for an approach he calls heterophenomenology, which means treating verbal reports as stories that may or may not be true, but his ideas about how to do this have not been widely adopted.[91] Another issue with verbal report as a criterion is that it restricts the field of study to humans who have language: this approach cannot be used to study consciousness in other species, pre-linguistic children, or people with types of brain damage that impair language. As a third issue, philosophers who dispute the validity of the Turing test may feel that it is possible, at least in principle, for verbal report to be dissociated from consciousness entirely: a philosophical zombie may give detailed verbal reports of awareness in the absence of any genuine awareness.[92]

Although verbal report is in practice the "gold standard" for ascribing consciousness, it is not the only possible criterion.[89] In medicine, consciousness is assessed as a combination of verbal behavior, arousal, brain activity and purposeful movement. The last three of these can be used as indicators of consciousness when verbal behavior is absent.[93] The scientific literature regarding the neural bases of arousal and purposeful movement is very extensive. Their reliability as indicators of consciousness is disputed, however, due to numerous studies showing that alert human subjects can be induced to behave purposefully in a variety of ways in spite of reporting a complete lack of awareness.[88] Studies of the neuroscience of free will have also shown that the experiences that people report when they behave purposefully sometimes do not correspond to their actual behaviors or to the patterns of electrical activity recorded from their brains.[94]

Another approach applies specifically to the study of self-awareness, that is, the ability to distinguish oneself from others. In the 1970s Gordon Gallup developed an operational test for self-awareness, known as the mirror test. The test examines whether animals are able to differentiate between seeing themselves in a mirror versus seeing other animals. The classic example involves placing a spot of coloring on the skin or fur near the individual's forehead and seeing if they attempt to remove it or at least touch the spot, thus indicating that they recognize that the individual they are seeing in the mirror is themselves.[95] Humans (older than 18 months) and other great apes, bottlenose dolphins, killer whales, pigeons, European magpies and elephants have all been observed to pass this test.[96]

Neural correlates

Schema of the neural processes underlying consciousness, from Christof Koch
A major part of the scientific literature on consciousness consists of studies that examine the relationship between the experiences reported by subjects and the activity that simultaneously takes place in their brains—that is, studies of the neural correlates of consciousness. The hope is to find that activity in a particular part of the brain, or a particular pattern of global brain activity, which will be strongly predictive of conscious awareness. Several brain imaging techniques, such as EEG and fMRI, have been used for physical measures of brain activity in these studies.[97]

Another idea that has drawn attention for several decades is that consciousness is associated with high-frequency (gamma band) oscillations in brain activity. This idea arose from proposals in the 1980s, by Christof von der Malsburg and Wolf Singer, that gamma oscillations could solve the so-called binding problem, by linking information represented in different parts of the brain into a unified experience.[98] Rodolfo Llinás, for example, proposed that consciousness results from recurrent thalamo-cortical resonance where the specific thalamocortical systems (content) and the non-specific (centromedial thalamus) thalamocortical systems (context) interact in the gamma band frequency via synchronous oscillations.[99]

A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus.[100] Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a "top-down" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a "bottom-up" flow of activity.[101] The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).[102]

Modulation of neural responses may correlate with phenomenal experiences. In contrast to the raw electrical responses that do not correlate with consciousness, the modulation of these responses by other stimuli correlates surprisingly well with an important aspect of consciousness: namely with the phenomenal experience of stimulus intensity (brightness, contrast). In the research group of Danko Nikolić it has been shown that some of the changes in the subjectively perceived brightness correlated with the modulation of firing rates while others correlated with the modulation of neural synchrony.[103] An fMRI investigation suggested that these findings were strictly limited to the primary visual areas.[104] This indicates that, in the primary visual areas, changes in firing rates and synchrony can be considered as neural correlates of qualia—at least for some type of qualia.

In 2011, Graziano and Kastner[105] proposed the "attention schema" theory of awareness. In that theory, specific cortical areas, notably in the superior temporal sulcus and the temporo-parietal junction, are used to build the construct of awareness and attribute it to other people. The same cortical machinery is also used to attribute awareness to oneself. Damage to these cortical regions can lead to deficits in consciousness such as hemispatial neglect. In the attention schema theory, the value of explaining the feature of awareness and attributing it to a person is to gain a useful predictive model of that person's attentional processing. Attention is a style of information processing in which a brain focuses its resources on a limited set of interrelated signals. Awareness, in this theory, is a useful, simplified schema that represents attentional states. To be aware of X is explained by constructing a model of one's attentional focus on X.

In 2013, the perturbational complexity index (PCI) was proposed, a measure of the algorithmic complexity of the electrophysiological response of the cortex to transcranial magnetic stimulation. This measure was shown to be higher in individuals that are awake, in REM sleep or in a locked-in state than in those who are in deep sleep or in a vegetative state,[106] making it potentially useful as a quantitative assessment of consciousness states.

Assuming that not only humans but even some non-mammalian species are conscious, a number of evolutionary approaches to the problem of neural correlates of consciousness open up. For example, assuming that birds are conscious—a common assumption among neuroscientists and ethologists due to the extensive cognitive repertoire of birds—there are comparative neuroanatomical ways to validate some of the principal, currently competing, mammalian consciousness–brain theories. The rationale for such a comparative study is that the avian brain deviates structurally from the mammalian brain. So how similar are they? What homologues can be identified? The general conclusion from the study by Butler, et al.,[107] is that some of the major theories for the mammalian brain [108][109][110] also appear to be valid for the avian brain. The structures assumed to be critical for consciousness in mammalian brains have homologous counterparts in avian brains. Thus the main portions of the theories of Crick and Koch,[108] Edelman and Tononi,[109] and Cotterill [110] seem to be compatible with the assumption that birds are conscious. Edelman also differentiates between what he calls primary consciousness (which is a trait shared by humans and non-human animals) and higher-order consciousness as it appears in humans alone along with human language capacity.[109] Certain aspects of the three theories, however, seem less easy to apply to the hypothesis of avian consciousness. For instance, the suggestion by Crick and Koch that layer 5 neurons of the mammalian brain have a special role, seems difficult to apply to the avian brain, since the avian homologues have a different morphology. Likewise, the theory of Eccles[111][112] seems incompatible, since a structural homologue/analogue to the dendron has not been found in avian brains. The assumption of an avian consciousness also brings the reptilian brain into focus. The reason is the structural continuity between avian and reptilian brains, meaning that the phylogenetic origin of consciousness may be earlier than suggested by many leading neuroscientists.

Joaquin Fuster of UCLA has advocated the position of the importance of the prefrontal cortex in humans, along with the areas of Wernicke and Broca, as being of particular importance to the development of human language capacities neuro-anatomically necessary for the emergence of higher-order consciousness in humans.[113]

Biological function and evolution
Opinions are divided as to where in biological evolution consciousness emerged and about whether or not consciousness has any survival value. Some argue that consciousness is a byproduct of evolution. It has been argued that consciousness emerged (i) exclusively with the first humans, (ii) exclusively with the first mammals, (iii) independently in mammals and birds, or (iv) with the first reptiles.[114] Other authors date the origins of consciousness to the first animals with nervous systems or early vertebrates in the Cambrian over 500 million years ago.[115] Donald Griffin suggests in his book Animal Minds a gradual evolution of consciousness.[67] Each of these scenarios raises the question of the possible survival value of consciousness.

Thomas Henry Huxley defends in an essay titled On the Hypothesis that Animals are Automata, and its History an epiphenomenalist theory of consciousness according to which consciousness is a causally inert effect of neural activity—"as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery".[116] To this William James objects in his essay Are We Automata? by stating an evolutionary argument for mind-brain interaction implying that if the preservation and development of consciousness in the biological evolution is a result of natural selection, it is plausible that consciousness has not only been influenced by neural processes, but has had a survival value itself; and it could only have had this if it had been efficacious.[117][118] Karl Popper develops in the book The Self and Its Brain a similar evolutionary argument.[119]

Regarding the primary function of conscious processing, a recurring idea in recent theories is that phenomenal states somehow integrate neural activities and information-processing that would otherwise be independent.[120] This has been called the integration consensus. Another example has been proposed by Gerald Edelman called dynamic core hypothesis which puts emphasis on reentrant connections that reciprocally link areas of the brain in a massively parallel manner.[121] Edelman also stresses the importance of the evolutionary emergence of higher-order consciousness in humans from the historically older trait of primary consciousness which humans share with non-human animals (see Neural correlates section above). These theories of integrative function present solutions to two classic problems associated with consciousness: differentiation and unity. They show how our conscious experience can discriminate between a virtually unlimited number of different possible scenes and details (differentiation) because it integrates those details from our sensory systems, while the integrative nature of consciousness in this view easily explains how our experience can seem unified as one whole despite all of these individual parts. However, it remains unspecified which kinds of information are integrated in a conscious manner and which kinds can be integrated without consciousness. Nor is it explained what specific causal role conscious integration plays, nor why the same functionality cannot be achieved without consciousness. Obviously not all kinds of information are capable of being disseminated consciously (e.g., neural activity related to vegetative functions, reflexes, unconscious motor programs, low-level perceptual analyses, etc.) and many kinds of information can be disseminated and combined with other kinds without consciousness, as in intersensory interactions such as the ventriloquism effect.[122] Hence it remains unclear why any of it is conscious. For a review of the differences between conscious and unconscious integrations, see the article of E. Morsella.[122]

As noted earlier, even among writers who consider consciousness to be a well-defined thing, there is widespread dispute about which animals other than humans can be said to possess it.[123] Edelman has described this distinction as that of humans possessing higher-order consciousness while sharing the trait of primary consciousness with non-human animals (see previous paragraph). Thus, any examination of the evolution of consciousness is faced with great difficulties. Nevertheless, some writers have argued that consciousness can be viewed from the standpoint of evolutionary biology as an adaptation in the sense of a trait that increases fitness.[124] In his article "Evolution of consciousness", John Eccles argued that special anatomical and physical properties of the mammalian cerebral cortex gave rise to consciousness ("[a] psychon ... linked to [a] dendron through quantum physics").[125] Bernard Baars proposed that once in place, this "recursive" circuitry may have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms.[126] Peter Carruthers has put forth one such potential adaptive advantage gained by conscious creatures by suggesting that consciousness allows an individual to make distinctions between appearance and reality.[127] This ability would enable a creature to recognize the likelihood that their perceptions are deceiving them (e.g. that water in the distance may be a mirage) and behave accordingly, and it could also facilitate the manipulation of others by recognizing how things appear to them for both cooperative and devious ends.

Other philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes.[128][129] No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a philosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between function F being performed by conscious organism O and non-conscious organism O*, it is unclear what adaptive advantage consciousness could provide.[130] As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was an exaptation arising as a consequence of other developments such as increases in brain size or cortical rearrangement.[115] Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired.[131] Several scholars including Pinker, Chomsky, Edelman, and Luria have indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness (see Neural correlates section above).

States of consciousness

A Buddhist monk meditating
There are some brain states in which consciousness seems to be absent, including dreamless sleep, coma, and death. There are also a variety of circumstances that can change the relationship between the mind and the world in less drastic ways, producing what are known as altered states of consciousness. Some altered states occur naturally; others can be produced by drugs or brain damage.[132] Altered states can be accompanied by changes in thinking, disturbances in the sense of time, feelings of loss of control, changes in emotional expression, alternations in body image and changes in meaning or significance.[133]

The two most widely accepted altered states are sleep and dreaming. Although dream sleep and non-dream sleep appear very similar to an outside observer, each is associated with a distinct pattern of brain activity, metabolic activity, and eye movement; each is also associated with a distinct pattern of experience and cognition. During ordinary non-dream sleep, people who are awakened report only vague and sketchy thoughts, and their experiences do not cohere into a continuous narrative. During dream sleep, in contrast, people who are awakened report rich and detailed experiences in which events form a continuous progression, which may however be interrupted by bizarre or fantastic intrusions.[134] Thought processes during the dream state frequently show a high level of irrationality. Both dream and non-dream states are associated with severe disruption of memory: it usually disappears in seconds during the non-dream state, and in minutes after awakening from a dream unless actively refreshed.[135]

Research conducted on the effects of partial epileptic seizures on consciousness found that patients who suffer from partial epileptic seizures experience altered states of consciousness.[136][137] In partial epileptic seizures, consciousness is impaired or lost while some aspects of consciousness, often automated behaviors, remain intact. Studies found that when measuring the qualitative features during partial epileptic seizures, patients exhibited an increase in arousal and became absorbed in the experience of the seizure, followed by difficulty in focusing and shifting attention.

A variety of psychoactive drugs, including alcohol, have notable effects on consciousness.[138] These range from a simple dulling of awareness produced by sedatives, to increases in the intensity of sensory qualities produced by stimulants, cannabis, empathogens–entactogens such as MDMA ("Ecstasy"), or most notably by the class of drugs known as psychedelics.[132] LSD, mescaline, psilocybin, dimethyltryptamine, and others in this group can produce major distortions of perception, including hallucinations; some users even describe their drug-induced experiences as mystical or spiritual in quality. The brain mechanisms underlying these effects are not as well understood as those induced by use of alcohol,[138] but there is substantial evidence that alterations in the brain system that uses the chemical neurotransmitter serotonin play an essential role.[139]

There has been some research into physiological changes in yogis and people who practise various techniques of meditation. Some research with brain waves during meditation has reported differences between those corresponding to ordinary relaxation and those corresponding to meditation. It has been disputed, however, whether there is enough evidence to count these as physiologically distinct states of consciousness.[140]

The most extensive study of the characteristics of altered states of consciousness was made by psychologist Charles Tart in the 1960s and 1970s. Tart analyzed a state of consciousness as made up of a number of component processes, including exteroception (sensing the external world); interoception (sensing the body); input-processing (seeing meaning); emotions; memory; time sense; sense of identity; evaluation and cognitive processing; motor output; and interaction with the environment.[141] Each of these, in his view, could be altered in multiple ways by drugs or other manipulations. The components that Tart identified have not, however, been validated by empirical studies. Research in this area has not yet reached firm conclusions, but a recent questionnaire-based study identified eleven significant factors contributing to drug-induced states of consciousness: experience of unity; spiritual experience; blissful state; insightfulness; disembodiment; impaired control and cognition; anxiety; complex imagery; elementary imagery; audio-visual synesthesia; and changed meaning of percepts.[142]

Phenomenology
Phenomenology is a method of inquiry that attempts to examine the structure of consciousness in its own right, putting aside problems regarding the relationship of consciousness to the physical world. This approach was first proposed by the philosopher Edmund Husserl, and later elaborated by other philosophers and scientists.[143] Husserl's original concept gave rise to two distinct lines of inquiry, in philosophy and psychology. In philosophy, phenomenology has largely been devoted to fundamental metaphysical questions, such as the nature of intentionality ("aboutness"). In psychology, phenomenology largely has meant attempting to investigate consciousness using the method of introspection, which means looking into one's own mind and reporting what one observes. This method fell into disrepute in the early twentieth century because of grave doubts about its reliability, but has been rehabilitated to some degree, especially when used in combination with techniques for examining brain activity.[144]


Neon color spreading effect. The apparent bluish tinge of the white areas inside the circle is an illusion.

Square version of the neon spread illusion
Introspectively, the world of conscious experience seems to have considerable structure. Immanuel Kant asserted that the world as we perceive it is organized according to a set of fundamental "intuitions", which include 'object' (we perceive the world as a set of distinct things); 'shape'; 'quality' (color, warmth, etc.); 'space' (distance, direction, and location); and 'time'.[145] Some of these constructs, such as space and time, correspond to the way the world is structured by the laws of physics; for others, the correspondence is not as clear. Understanding the physical basis of qualities, such as redness or pain, has been particularly challenging. David Chalmers has called this the hard problem of consciousness.[37] Some philosophers have argued that it is intrinsically unsolvable, because qualities ("qualia") are ineffable; that is, they are "raw feels", incapable of being analyzed into component processes.[146] Other psychologists and neuroscientists reject these arguments. For example, research on ideasthesia shows that qualia are organised into a semantic-like network. Nevertheless, it is clear that the relationship between a physical entity such as light and a perceptual quality such as color is extraordinarily complex and indirect, as demonstrated by a variety of optical illusions such as neon color spreading.[147]

In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion.[148] Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world—Gerald Edelman expressed this point vividly by titling one of his books about consciousness The Remembered Present.[149] In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.[150][151][152]

Despite the large amount of information available, many important aspects of perception remain mysterious. A great deal is known about low-level signal processing in sensory systems. However, how sensory systems, action systems, and language systems interact are poorly understood. At a deeper level, there are still basic conceptual issues that remain unresolved.[148] Many scientists have found it difficult to reconcile the fact that information is distributed across multiple brain areas with the apparent unity of consciousness: this is one aspect of the so-called binding problem.[153] There are also some scientists who have expressed grave reservations about the idea that the brain forms representations of the outside world at all: influential members of this group include psychologist J. J. Gibson and roboticist Rodney Brooks, who both argued in favor of "intelligence without representation".[154]

Entropic brain
The entropic brain is a theory of conscious states informed by neuroimaging research with psychedelic drugs. The theory suggests that the brain in primary states such as rapid eye movement (REM) sleep, early psychosis and under the influence of psychedelic drugs, is in a disordered state; normal waking consciousness constrains some of this freedom and makes possible metacognitive functions such as internal self-administered reality testing and self-awareness.[155][156][157][158] Criticism has included questioning whether the theory has been adequately tested.[159]

Medical aspects
The medical approach to consciousness is practically oriented. It derives from a need to treat people whose brain function has been impaired as a result of disease, brain damage, toxins, or drugs. In medicine, conceptual distinctions are considered useful to the degree that they can help to guide treatments. Whereas the philosophical approach to consciousness focuses on its fundamental nature and its contents, the medical approach focuses on the amount of consciousness a person has: in medicine, consciousness is assessed as a "level" ranging from coma and brain death at the low end, to full alertness and purposeful responsiveness at the high end.[160]

Consciousness is of concern to patients and physicians, especially neurologists and anesthesiologists. Patients may suffer from disorders of consciousness or may need to be anesthetized for a surgical procedure. Physicians may perform consciousness-related interventions such as instructing the patient to sleep, administering general anesthesia, or inducing medical coma.[160] Also, bioethicists may be concerned with the ethical implications of consciousness in medical cases of patients such as the Karen Ann Quinlan case,[161] while neuroscientists may study patients with impaired consciousness in hopes of gaining information about how the brain works.[162]

Assessment
In medicine, consciousness is examined using a set of procedures known as neuropsychological assessment.[93] There are two commonly used methods for assessing the level of consciousness of a patient: a simple procedure that requires minimal training, and a more complex procedure that requires substantial expertise. The simple procedure begins by asking whether the patient is able to move and react to physical stimuli. If so, the next question is whether the patient can respond in a meaningful way to questions and commands. If so, the patient is asked for name, current location, and current day and time. A patient who can answer all of these questions is said to be "alert and oriented times four" (sometimes denoted "A&Ox4" on a medical chart), and is usually considered fully conscious.[163]

The more complex procedure is known as a neurological examination, and is usually carried out by a neurologist in a hospital setting. A formal neurological examination runs through a precisely delineated series of tests, beginning with tests for basic sensorimotor reflexes, and culminating with tests for sophisticated use of language. The outcome may be summarized using the Glasgow Coma Scale, which yields a number in the range 3–15, with a score of 3 to 8 indicating coma, and 15 indicating full consciousness. The Glasgow Coma Scale has three subscales, measuring the best motor response (ranging from "no motor response" to "obeys commands"), the best eye response (ranging from "no eye opening" to "eyes opening spontaneously") and the best verbal response (ranging from "no verbal response" to "fully oriented"). There is also a simpler pediatric version of the scale, for children too young to be able to use language.[160]

In 2013, an experimental procedure was developed to measure degrees of consciousness, the procedure involving stimulating the brain with a magnetic pulse, measuring resulting waves of electrical activity, and developing a consciousness score based on the complexity of the brain activity.[164]

Disorders of consciousness
Medical conditions that inhibit consciousness are considered disorders of consciousness.[165] This category generally includes minimally conscious state and persistent vegetative state, but sometimes also includes the less severe locked-in syndrome and more severe chronic coma.[165][166] Differential diagnosis of these disorders is an active area of biomedical research.[167][168][169] Finally, brain death results in an irreversible disruption of consciousness.[165] While other conditions may cause a moderate deterioration (e.g., dementia and delirium) or transient interruption (e.g., grand mal and petit mal seizures) of consciousness, they are not included in this category.

Disorder	Description
Locked-in syndrome	The patient has awareness, sleep-wake cycles, and meaningful behavior (viz., eye-movement), but is isolated due to quadriplegia and pseudobulbar palsy.
Minimally conscious state	The patient has intermittent periods of awareness and wakefulness and displays some meaningful behavior.
Persistent vegetative state	The patient has sleep-wake cycles, but lacks awareness and only displays reflexive and non-purposeful behavior.
Chronic coma	The patient lacks awareness and sleep-wake cycles and only displays reflexive behavior.
Brain death	The patient lacks awareness, sleep-wake cycles, and brain-mediated reflexive behavior.
Anosognosia
Main article: Anosognosia
One of the most striking disorders of consciousness goes by the name anosognosia, a Greek-derived term meaning 'unawareness of disease'. This is a condition in which patients are disabled in some way, most commonly as a result of a stroke, but either misunderstand the nature of the problem or deny that there is anything wrong with them.[170] The most frequently occurring form is seen in people who have experienced a stroke damaging the parietal lobe in the right hemisphere of the brain, giving rise to a syndrome known as hemispatial neglect, characterized by an inability to direct action or attention toward objects located to the left with respect to their bodies. Patients with hemispatial neglect are often paralyzed on the right side of the body, but sometimes deny being unable to move. When questioned about the obvious problem, the patient may avoid giving a direct answer, or may give an explanation that doesn't make sense. Patients with hemispatial neglect may also fail to recognize paralyzed parts of their bodies: one frequently mentioned case is of a man who repeatedly tried to throw his own paralyzed right leg out of the bed he was lying in, and when asked what he was doing, complained that somebody had put a dead leg into the bed with him. An even more striking type of anosognosia is Anton–Babinski syndrome, a rarely occurring condition in which patients become blind but claim to be able to see normally, and persist in this claim in spite of all evidence to the contrary.[171]

Stream of consciousness
Main article: Stream of consciousness (psychology)
William James is usually credited with popularizing the idea that human consciousness flows like a stream, in his Principles of Psychology of 1890. According to James, the "stream of thought" is governed by five characteristics: "(1) Every thought tends to be part of a personal consciousness. (2) Within each personal consciousness thought is always changing. (3) Within each personal consciousness thought is sensibly continuous. (4) It always appears to deal with objects independent of itself. (5) It is interested in some parts of these objects to the exclusion of others".[172] A similar concept appears in Buddhist philosophy, expressed by the Sanskrit term Citta-saṃtāna, which is usually translated as mindstream or "mental continuum". Buddhist teachings describe that consciousness manifests moment to moment as sense impressions and mental phenomena that are continuously changing.[173] The teachings list six triggers that can result in the generation of different mental events.[173] These triggers are input from the five senses (seeing, hearing, smelling, tasting or touch sensations), or a thought (relating to the past, present or the future) that happen to arise in the mind. The mental events generated as a result of these triggers are: feelings, perceptions and intentions/behaviour. The moment-by-moment manifestation of the mind-stream is said to happen in every person all the time. It even happens in a scientist who analyses various phenomena in the world, or analyses the material body including the organ brain.[173] The manifestation of the mindstream is also described as being influenced by physical laws, biological laws, psychological laws, volitional laws, and universal laws.[173] The purpose of the Buddhist practice of mindfulness is to understand the inherent nature of the consciousness and its characteristics.[174]

Narrative form
In the west, the primary impact of the idea has been on literature rather than science: stream of consciousness as a narrative mode means writing in a way that attempts to portray the moment-to-moment thoughts and experiences of a character. This technique perhaps had its beginnings in the monologues of Shakespeare's plays and reached its fullest development in the novels of James Joyce and Virginia Woolf, although it has also been used by many other noted writers.[175]

Here, for example, is a passage from Joyce's Ulysses about the thoughts of Molly Bloom:

Yes because he never did a thing like that before as ask to get his breakfast in bed with a couple of eggs since the City Arms hotel when he used to be pretending to be laid up with a sick voice doing his highness to make himself interesting for that old faggot Mrs Riordan that he thought he had a great leg of and she never left us a farthing all for masses for herself and her soul greatest miser ever was actually afraid to lay out 4d for her methylated spirit telling me all her ailments she had too much old chat in her about politics and earthquakes and the end of the world let us have a bit of fun first God help the world if all the women were her sort down on bathingsuits and lownecks of course nobody wanted her to wear them I suppose she was pious because no man would look at her twice I hope Ill never be like her a wonder she didnt want us to cover our faces but she was a welleducated woman certainly and her gabby talk about Mr Riordan here and Mr Riordan there I suppose he was glad to get shut of her.[176]

Spiritual approaches
Further information: Level of consciousness (esotericism) and Higher consciousness
To most philosophers, the word "consciousness" connotes the relationship between the mind and the world. To writers on spiritual or religious topics, it frequently connotes the relationship between the mind and God, or the relationship between the mind and deeper truths that are thought to be more fundamental than the physical world. The mystical psychiatrist Richard Maurice Bucke, author of the 1901 book Cosmic Consciousness: A Study in the Evolution of the Human Mind, distinguished between three types of consciousness: 'Simple Consciousness', awareness of the body, possessed by many animals; 'Self Consciousness', awareness of being aware, possessed only by humans; and 'Cosmic Consciousness', awareness of the life and order of the universe, possessed only by humans who are enlightened.[177] Many more examples could be given, such as the various levels of spiritual consciousness presented by Prem Saran Satsangi and Stuart Hameroff.[178]

Another thorough account of the spiritual approach is Ken Wilber's 1977 book The Spectrum of Consciousness, a comparison of western and eastern ways of thinking about the mind. Wilber described consciousness as a spectrum with ordinary awareness at one end, and more profound types of awareness at higher levels.[179]

Intelligence has been defined in many ways: the capacity for logic, understanding, self-awareness, learning, emotional knowledge, reasoning, planning, creativity, critical thinking, and problem-solving. More generally, it can be described as the ability to perceive or infer information, and to retain it as knowledge to be applied towards adaptive behaviors within an environment or context. There are conflicting ideas about how intelligence is measured, ranging from the idea that intelligence is fixed upon birth, or that it is malleable and can change depending on an individual’s mindset and efforts.[1] Several subcategories of intelligence, such as emotional intelligence or social intelligence, are heavily debated as to whether they are traditional forms of intelligence.[2][3] They are generally thought to be distinct processes that occur, though there is speculation that they tie into traditional intelligence more than previously suspected.[2][3] Despite their use of the word ‘Intelligence,’ some terms may have little or nothing to do with the mentioned cognitive processes.

Intelligence is most often studied in humans but has also been observed in both non-human animals and in plants despite controversy as to whether some forms of life exhibit intelligence.[4][5] Intelligence in machines is called artificial intelligence, which is commonly implemented in computer systems using programs and, sometimes, specialized hardware.

The word intelligence derives from the Latin nouns intelligentia or intellēctus, which in turn stem from the verb intelligere, to comprehend or perceive. In the Middle Ages, the word intellectus became the scholarly technical term for understanding, and a translation for the Greek philosophical term nous. This term, however, was strongly linked to the metaphysical and cosmological theories of teleological scholasticism, including theories of the immortality of the soul, and the concept of the active intellect (also known as the active intelligence). This approach to the study of nature was strongly rejected by the early modern philosophers such as Francis Bacon, Thomas Hobbes, John Locke, and David Hume, all of whom preferred "understanding" (in place of "intellectus" or "intelligence") in their English philosophical works.[6][7] Hobbes for example, in his Latin De Corpore, used "intellectus intelligit", translated in the English version as "the understanding understandeth", as a typical example of a logical absurdity.[8] "Intelligence" has therefore become less common in English language philosophy, but it has later been taken up (with the scholastic theories which it now implies) in more contemporary psychology.[9]

Definitions
The definition of intelligence is controversial, varying in what its abilities are and whether or not it is quantifiable.[10] Some groups of psychologists have suggested the following definitions:

From "Mainstream Science on Intelligence" (1994), an op-ed statement in the Wall Street Journal signed by fifty-two researchers (out of 131 total invited to sign):[11]

A very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings—"catching on," "making sense" of things, or "figuring out" what to do.[12]

From Intelligence: Knowns and Unknowns (1995), a report published by the Board of Scientific Affairs of the American Psychological Association:

Individuals differ from one another in their ability to understand complex ideas, to adapt effectively to the environment, to learn from experience, to engage in various forms of reasoning, to overcome obstacles by taking thought. Although these individual differences can be substantial, they are never entirely consistent: a given person's intellectual performance will vary on different occasions, in different domains, as judged by different criteria. Concepts of "intelligence" are attempts to clarify and organize this complex set of phenomena. Although considerable clarity has been achieved in some areas, no such conceptualization has yet answered all the important questions, and none commands universal assent. Indeed, when two dozen prominent theorists were recently asked to define intelligence, they gave two dozen, somewhat different, definitions.[13]

Besides those definitions, psychology and learning researchers also have suggested definitions of intelligence such as the following:

Researcher	Quotation
Alfred Binet	Judgment, otherwise called "good sense", "practical sense", "initiative", the faculty of adapting one's self to circumstances ... auto-critique.[14]
David Wechsler	The aggregate or global capacity of the individual to act purposefully, to think rationally, and to deal effectively with his environment.[15]
Lloyd Humphreys	"...the resultant of the process of acquiring, storing in memory, retrieving, combining, comparing, and using in new contexts information and conceptual skills".[16]
Howard Gardner	To my mind, a human intellectual competence must entail a set of skills of problem solving — enabling the individual to resolve genuine problems or difficulties that he or she encounters and, when appropriate, to create an effective product — and must also entail the potential for finding or creating problems — and thereby laying the groundwork for the acquisition of new knowledge.[17]
Linda Gottfredson	The ability to deal with cognitive complexity.[18]
Robert Sternberg & William Salter	Goal-directed adaptive behavior.[19]
Reuven Feuerstein	The theory of Structural Cognitive Modifiability describes intelligence as "the unique propensity of human beings to change or modify the structure of their cognitive functioning to adapt to the changing demands of a life situation".[20]
Shane Legg & Marcus Hutter	A synthesis of 70+ definitions from psychology, philosophy, and AI researchers: "Intelligence measures an agent's ability to achieve goals in a wide range of environments",[10] which has been mathematically formalized.[21]
Alexander Wissner-Gross	F = T ∇ S{\displaystyle _{\tau }}{\displaystyle _{\tau }}[22]
"Intelligence is a force, F, that acts so as to maximize future freedom of action. It acts to maximize future freedom of action, or keep options open, with some strength T, with the diversity of possible accessible futures, S, up to some future time horizon, τ. In short, intelligence doesn't like to get trapped".

Human intelligence
Main article: Human intelligence
Human intelligence is the intellectual power of humans, which is marked by complex cognitive feats and high levels of motivation and self-awareness.[23] Intelligence enables humans to remember descriptions of things and use those descriptions in future behaviors. It is a cognitive process. It gives humans the cognitive abilities to learn, form concepts, understand, and reason, including the capacities to recognize patterns, innovate, plan, solve problems, and employ language to communicate. Intelligence enables humans to experience and think.

Intelligence is different from learning. Learning refers to the act of retaining facts and information or abilities and being able to recall them for future use, while intelligence is the cognitive ability of someone to perform these and other processes. There have been various attempts to quantify intelligence via testing, such as the Intelligence Quotient (IQ) test. However, many people disagree with the validity of IQ tests, stating that they cannot accurately measure intelligence.[24]

There is debate about if human intelligence is based on hereditary factors or if it is based on environmental factors. Hereditary intelligence is the theory that intelligence is fixed upon birth and not able to grow. Environmental intelligence is the theory that intelligence is developed throughout life depending on the environment around the person. An environment that cultivates intelligence is one that challenges the person’s cognitive abilities.[24]

Much of the above definition applies also to the intelligence of non-human animals.

Emotional Intelligence
Main article: Emotional intelligence
Emotional intelligence is thought to be the ability to convey emotion to others in an understandable way as well as to read the emotions of others accurately.[2] Some theories imply that a heightened emotional intelligence could also lead to faster generating and processing of emotions in addition to the accuracy.[25] In addition, higher emotional intelligence is thought to help us manage emotions, which is beneficial for our problem-solving skills. Emotional intelligence is important to our mental health and has ties into social intelligence.[2]

Social Intelligence
Main article: Social intelligence
Social intelligence is the ability to understand the social cues and motivations of others and oneself in social situations. It is thought to be distinct to other types of intelligence, but has relations to emotional intelligence. Social intelligence has coincided with other studies that focus on how we make judgements of others, the accuracy with which we do so, and why people would be viewed as having positive or negative social character. There is debate as to whether or not these studies and social intelligence come from the same theories or if there is a distinction between them, and they are generally thought to be of two different schools of thought.[3]

Nonhuman animal intelligence
Main article: Animal cognition

The common chimpanzee can use tools. This chimpanzee is using a stick to get food.
Although humans have been the primary focus of intelligence researchers, scientists have also attempted to investigate animal intelligence, or more broadly, animal cognition. These researchers are interested in studying both mental ability in a particular species, and comparing abilities between species. They study various measures of problem solving, as well as numerical and verbal reasoning abilities. Some challenges in this area are defining intelligence so that it has the same meaning across species (e.g. comparing intelligence between literate humans and illiterate animals), and also operationalizing a measure that accurately compares mental ability across different species and contexts.

Wolfgang Köhler's research on the intelligence of apes is an example of research in this area. Stanley Coren's book, The Intelligence of Dogs is a notable book on the topic of dog intelligence.[26] (See also: Dog intelligence.) Non-human animals particularly noted and studied for their intelligence include chimpanzees, bonobos (notably the language-using Kanzi) and other great apes, dolphins, elephants and to some extent parrots, rats and ravens.

Cephalopod intelligence also provides an important comparative study. Cephalopods appear to exhibit characteristics of significant intelligence, yet their nervous systems differ radically from those of backboned animals. Vertebrates such as mammals, birds, reptiles and fish have shown a fairly high degree of intellect that varies according to each species. The same is true with arthropods.

g factor in non-humans
Main article: g Factor in Non-Humans
Evidence of a general factor of intelligence has been observed in non-human animals. The general factor of intelligence, or g factor, is a psychometric construct that summarizes the correlations observed between an individual's scores on a wide range of cognitive abilities. First described in humans, the g factor has since been identified in a number of non-human species.[27]

Cognitive ability and intelligence cannot be measured using the same, largely verbally dependent, scales developed for humans. Instead, intelligence is measured using a variety of interactive and observational tools focusing on innovation, habit reversal, social learning, and responses to novelty. Studies have shown that g is responsible for 47% of the individual variance in cognitive ability measures in primates[27] and between 55% and 60% of the variance in mice (Locurto, Locurto). These values are similar to the accepted variance in IQ explained by g in humans (40–50%).[28]

Plant intelligence
Main articles: Plant perception (physiology) § Plant cognition, and Plant cognition
It has been argued that plants should also be classified as intelligent based on their ability to sense and model external and internal environments and adjust their morphology, physiology and phenotype accordingly to ensure self-preservation and reproduction.[29][30]

A counter argument is that intelligence is commonly understood to involve the creation and use of persistent memories as opposed to computation that does not involve learning. If this is accepted as definitive of intelligence, then it includes the artificial intelligence of robots capable of "machine learning", but excludes those purely autonomic sense-reaction responses that can be observed in many plants. Plants are not limited to automated sensory-motor responses, however, they are capable of discriminating positive and negative experiences and of "learning" (registering memories) from their past experiences. They are also capable of communication, accurately computing their circumstances, using sophisticated cost–benefit analysis and taking tightly controlled actions to mitigate and control the diverse environmental stressors.[4][5][31]

Artificial intelligence
Main article: Artificial intelligence
Artificial intelligence (or AI) is both the intelligence that is demonstrated by machines and the branch of computer science which aims to create it, through "the study and design of intelligent agents"[32] or "rational agents", where an intelligent agent is a system that perceives its environment and takes actions which maximize its chances of success.[33] Kaplan and Haenlein define artificial intelligence as “a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation”.[34] Achievements in artificial intelligence include constrained and well-defined problems such as games, crossword-solving and optical character recognition and a few more general problems such as autonomous cars.[35] General intelligence or strong AI has not yet been achieved and is a long-term goal of AI research.

Among the traits that researchers hope machines will exhibit are reasoning, knowledge, planning, learning, communication, perception, and the ability to move and to manipulate objects.[32][33] In the field of artificial intelligence there is no consensus on how closely the brain should be simulated.